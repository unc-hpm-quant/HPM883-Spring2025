{
  "hash": "5cd9d41d22222d75da0c3536b9cc98ac",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Lab 3\nsubtitle: Optimizing HBV Vaccination Strategies\nauthor: Sean Sylvia\ndate: \"2025-03-03\"\nslug: lab-3\ncategories: \n    - Lab\n    - Optimal Design\n    - Randomization\ndescription: \"Optimal experimental design and randomization techniques for vaccine interventions\"\nformat: \n  html:\n    toc: true\n    toc-depth: 2\n    code-tools: true\neditor: visual\nexecute:\n  eval: false\n---\n\n\n\n\n## Overview and Learning Objectives\n\nIn this lab, you will apply concepts of **optimal experimental design** and **randomization techniques** to a real-world public health challenge: increasing Hepatitis B virus (HBV) vaccination rates. Specifically, you will:\n\n1.  Design an experiment to test different subsidy strategies for HBV vaccination\n2.  Determine the **optimal allocation** of resources given budget constraints\n3.  Create a **simulated dataset** for your experiment\n4.  Implement and compare different **randomization approaches**\n5.  Test for **covariate balance** across treatment groups\n6.  Document your randomization procedure thoroughly\n\nBy the end of this lab, you will have practical experience with:\n\n-   Calculating **Minimum Detectable Effects (MDEs)** for different experimental designs\n-   Making informed design trade-offs based on **budget constraints**\n-   Implementing various **randomization techniques** including simple, stratified, and matched-pair randomization\n-   Using specialized R packages (`fabricatr` and `randomizr`) for efficient experimental design\n\n------------------------------------------------------------------------\n\n## The HBV Crisis at St. Null's Community\n\n### Scene 1: The Foundation's Dilemma\n\nThe corridors of St. Null's Memorial Hospital buzz with unusual energy as the hospital's charitable foundation prepares to announce a major public health initiative. **CEO Barnaby Beta**, dressed in his finest suit with a Hepatitis B awareness pin prominently displayed, stands at the head of the conference room.\n\n\"People, we have a crisis on our hands!\" he announces dramatically. \"Only 26% of adults in our region have received *any* dose of the Hepatitis B vaccine. With 1.1 million global deaths annually, we simply must act!\"\n\n**Dr. P-Hacker** nods vigorously. \"I've already run some numbers,\" he interjects, pulling out a colorful chart. \"If we offer free vaccines to everyone who walks through our doors, we'll save exactly 371.5 lives per year.\"\n\n**Nurse Random** raises an eyebrow. \"That seems... suspiciously precise. And completely ignoring the fact that people need three doses for full protection. The completion rate in similar programs is only 13%.\"\n\n\"Also,\" adds **Dr. Doub R. Obust**, who until now had been quietly examining his coffee cup, \"our foundation's budget is finite. Simply offering everyone a free first dose might not optimize our impact. We need a carefully designed experiment to determine the most effective subsidy strategy.\"\n\nCEO Beta brightens. \"An experiment! Perfect! I was just reading about those in my 'Management Buzzwords Monthly' magazine.\"\n\nDr. P-Hacker frowns. \"But I've already made the charts for the press release...\"\n\n\"What we need,\" says Nurse Random firmly, \"is to bring in those methodology consultants from the university again. They'll help us design a proper randomized trial to test different subsidy approaches.\"\n\nAnd that's where you come in. The foundation has a fixed budget and needs to determine the optimal strategy: Should they subsidize the first, second, or third dose? Or perhaps distribute subsidies differently? Your task is to design an experiment that will provide clear answers within their budget constraints.\n\n------------------------------------------------------------------------\n\n## Part 1: Setting Up the Problem\n\nFirst, let's establish some key parameters about HBV vaccination in this community:\n\n-   **Current first-dose uptake rate**: 26% of eligible adults\n-   **Series completion rate without intervention**: 13% of those who start\n-   **Protection rates**: 30-55% after one dose, 75% after two doses, \\>90% after three doses\n-   **Dose costs**: \\$25 per dose (same for all three doses)\n-   **Follow-up costs**: \\$5 per person for reminder/tracking\n-   **Foundation budget**: \\$100,000 for the pilot program\n\nThe foundation is considering several possible intervention strategies:\n\n1.  **First Dose Free**: Provide the first dose free to everyone\n2.  **Last Dose Free**: Provide the third dose free to those who complete two doses\n3.  **Graduated Subsidy**: Provide increasing subsidies (\\$10, \\$15, \\$25) for each subsequent dose\n4.  **Full Series Free**: Provide all three doses free, but to a smaller population\n\nBefore diving into randomization, let's install the required packages:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Install required packages if not already installed\nrequired_packages <- c(\"data.table\", \"ggplot2\", \"fabricatr\", \"randomizr\", \"multiwayvcov\", \"lmtest\")\n\nfor (pkg in required_packages) {\n  if (!require(pkg, character.only = TRUE)) {\n    install.packages(pkg)\n  }\n}\n\n# Load libraries\nlibrary(data.table)\nlibrary(ggplot2)\n```\n:::\n\n\n\n\n## Part 2: Optimal Allocation of Resources\n\n### Step 1: Define the parameters\n\nLet's start by defining the variables needed for our power calculations and optimal design:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Cost parameters\ndose_cost <- 25  # Cost per vaccine dose ($)\nfollowup_cost <- 5  # Cost of follow-up per person ($)\ntotal_budget <- 100000  # Total budget ($)\n\n# Expected outcomes for each strategy (completion rates)\nbaseline_completion <- 0.13  # Baseline completion rate\nexpected_effects <- c(\n  first_dose_free = 0.08,   # Expected increase if first dose is free\n  last_dose_free = 0.12,    # Expected increase if third dose is free\n  graduated = 0.15,         # Expected increase if graduated subsidies\n  full_series = 0.20        # Expected increase if all doses free\n)\n\n# Variance parameters (assume equal for now)\noutcome_variance <- 0.2  # Variance of binary outcome (completion)\n\n# Statistical parameters\nalpha <- 0.05  # Significance level\npower <- 0.80  # Desired power\n```\n:::\n\n\n\n\n### Step 2: Calculate total cost per person for each strategy\n\nNext, we'll calculate the cost per person for each intervention strategy:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate cost per person for each strategy\ncost_per_person <- c(\n  # First dose free: 1 dose cost + followup\n  first_dose_free = dose_cost + followup_cost,\n  \n  # Last dose free: Those who reach third dose (baseline + effect) get subsidy\n  # Everyone gets followup cost\n  last_dose_free = (baseline_completion + expected_effects[\"last_dose_free\"]) * \n                   dose_cost + followup_cost,\n  \n  # Graduated subsidy: $10 + $15 + $25 for completers\n  # Partial subsidy costs for non-completers + followup for all\n  graduated = 10 + \n              0.50 * 15 + # Assume 50% reach second dose\n              (baseline_completion + expected_effects[\"graduated\"]) * 25 + \n              followup_cost,\n  \n  # Full series free: 3 doses for completers, partial for others + followup\n  full_series = 3 * dose_cost + followup_cost\n)\n\n# Display costs\nprint(cost_per_person)\n```\n:::\n\n\n\n\n### Step 3: Calculate sample size for each arm with equal allocation\n\nFirst, let's determine how many people we could include if we divide our budget equally among the strategies:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Determine total sample size with equal allocation (4 arms)\nn_per_arm_equal <- floor(total_budget / (sum(cost_per_person)))\ntotal_n_equal <- 4 * n_per_arm_equal\n\ncat(\"With equal allocation:\\n\")\ncat(\"Sample size per arm:\", n_per_arm_equal, \"\\n\")\ncat(\"Total sample size:\", total_n_equal, \"\\n\")\n```\n:::\n\n\n\n\n### Step 4: Calculate the Minimum Detectable Effect (MDE) with equal allocation\n\nNow, let's calculate the MDE for each strategy under equal allocation:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Minimum Detectable Effect calculation\ncalculate_mde <- function(n1, n0, sigma_sq, alpha = 0.05, power = 0.80) {\n  # Critical values\n  z_alpha <- qnorm(1 - alpha/2)\n  z_power <- qnorm(power)\n  \n  # Standard error\n  se <- sqrt(sigma_sq * (1/n1 + 1/n0))\n  \n  # MDE\n  mde <- (z_alpha + z_power) * se\n  \n  return(mde)\n}\n\n# Calculate MDE for each arm vs. control with equal allocation\nmde_equal <- numeric(length(cost_per_person))\nnames(mde_equal) <- names(cost_per_person)\n\nfor (i in seq_along(cost_per_person)) {\n  mde_equal[i] <- calculate_mde(\n    n1 = n_per_arm_equal,\n    n0 = n_per_arm_equal,\n    sigma_sq = outcome_variance\n  )\n}\n\n# Display MDEs\nprint(mde_equal)\n```\n:::\n\n\n\n\n### Step 5: Calculate optimal allocation based on costs\n\nNow, let's determine the optimal allocation of resources based on the cost per person and the expected effect of each strategy:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Optimal allocation when costs differ\noptimal_allocation <- function(costs, budget, sigma_sq = NULL) {\n  if (is.null(sigma_sq)) {\n    # If no variance provided, assume equal variance\n    sigma_sq <- rep(outcome_variance, length(costs))\n  }\n  \n  # Calculate the optimal proportions\n  proportions <- sqrt(sigma_sq) / sqrt(costs)\n  proportions <- proportions / sum(proportions)\n  \n  # Calculate sample sizes\n  n_per_arm <- floor(budget * proportions / costs)\n  \n  return(n_per_arm)\n}\n\n# Calculate optimal allocation\nn_per_arm_optimal <- optimal_allocation(\n  costs = cost_per_person,\n  budget = total_budget\n)\n\ntotal_n_optimal <- sum(n_per_arm_optimal)\n\ncat(\"With optimal allocation:\\n\")\nfor (i in seq_along(n_per_arm_optimal)) {\n  cat(names(n_per_arm_optimal)[i], \":\", n_per_arm_optimal[i], \"participants\\n\")\n}\ncat(\"Total sample size:\", total_n_optimal, \"\\n\")\n```\n:::\n\n\n\n\n### Step 6: Calculate the MDE with optimal allocation\n\nLet's calculate the MDEs we can expect with the optimal allocation:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate MDE for each arm vs. control with optimal allocation\nmde_optimal <- numeric(length(cost_per_person))\nnames(mde_optimal) <- names(cost_per_person)\n\n# Control group size (we'll use the smallest treatment group as reference)\nn0 <- min(n_per_arm_optimal)\n\nfor (i in seq_along(cost_per_person)) {\n  mde_optimal[i] <- calculate_mde(\n    n1 = n_per_arm_optimal[i],\n    n0 = n0,\n    sigma_sq = outcome_variance\n  )\n}\n\n# Display MDEs\nprint(mde_optimal)\n\n# Compare to expected effects\nresults_table <- data.frame(\n  Strategy = names(expected_effects),\n  Expected_Effect = expected_effects,\n  MDE_Equal = mde_equal,\n  MDE_Optimal = mde_optimal,\n  Detectable_Equal = expected_effects > mde_equal,\n  Detectable_Optimal = expected_effects > mde_optimal\n)\n\nprint(results_table)\n```\n:::\n\n\n\n\n### Discussion Questions\n\n1.  Which allocation strategy (equal or optimal) allows you to detect more of the expected effects?\n2.  What trade-offs are involved in choosing between these allocation strategies?\n3.  Based on the MDEs, which intervention strategies should the foundation prioritize testing?\n\n------------------------------------------------------------------------\n\n## Part 3: Creating a Simulated Dataset\n\n### Scene 2: The Dataset Debate\n\nBack at St. Null's, **Dr. P-Hacker** is pacing the room impatiently.\n\n\"I still don't understand why we need to wait for an experiment,\" he complains. \"I can just use our electronic health records to prove whichever strategy you prefer, CEO Beta.\"\n\n**Nurse Random** crosses her arms. \"And that's exactly the problem. We need a properly randomized prospective study, not a fishing expedition through historical data.\"\n\n\"But we have hundreds of thousands of patient records!\" Dr. P-Hacker protests.\n\n**Dr. Doub R. Obust** clears his throat. \"Ah, but what we don't have is the counterfactual. We don't know what would have happened if Patient X had been offered a different subsidy scheme.\"\n\nCEO Beta looks confused. \"Counter... what now?\"\n\n\"What people would have done under different circumstances,\" Nurse Random explains. \"That's why we need a clean experiment with proper randomization.\"\n\n\"Fine,\" huffs Dr. P-Hacker. \"But how do we even create a dataset for this yet-to-happen experiment?\"\n\nDr. Doub R. Obust smiles. \"That's where our university consultants come in. They'll simulate the data based on our best knowledge of the population characteristics. Then they'll help us implement a proper randomization strategy.\"\n\n### Step 1: Manual dataset creation\n\nLet's create a simulated dataset of potential participants for our HBV vaccination study. We'll include baseline characteristics that might affect vaccine uptake:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set seed for reproducibility\nset.seed(072111)\n\n# Define sample size (from our optimal allocation calculation)\nn_total <- sum(n_per_arm_optimal)\n\n# Create baseline dataset manually\ncreate_baseline_data <- function(n) {\n  # Initialize data table\n  dt <- data.table(\n    id = 1:n,\n    \n    # Demographics\n    age = sample(18:65, n, replace = TRUE),\n    female = rbinom(n, 1, 0.55),\n    education = sample(1:4, n, replace = TRUE, \n                      prob = c(0.15, 0.3, 0.4, 0.15)),\n    \n    # Health factors\n    insurance = rbinom(n, 1, 0.7),\n    prior_vaccines = rbinom(n, 1, 0.4),\n    health_conscious = rbinom(n, 1, 0.3),\n    \n    # Access factors\n    distance_to_clinic = runif(n, 0, 30),\n    works_weekdays = rbinom(n, 1, 0.8)\n  )\n  \n  # Convert categorical variables to factors\n  dt[, education := factor(education, \n                          levels = 1:4, \n                          labels = c(\"Less than HS\", \"HS\", \"Some college\", \"College+\"))]\n  \n  return(dt)\n}\n\n# Create the baseline dataset\nsim_data <- create_baseline_data(n_total)\n\n# View the first few rows\nhead(sim_data)\n\n# Summary statistics\nsummary(sim_data)\n```\n:::\n\n\n\n\n### Step 2: Using fabricatr for more efficient data generation\n\nThe `fabricatr` package provides a more efficient way to generate simulated data:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(fabricatr)\n\n# Create the same dataset using fabricatr\nsim_data_fab <- fabricate(\n  N = n_total,\n  id = 1:n_total,\n  age = sample(18:65, N, replace = TRUE),\n  female = draw_binary(prob = 0.55),\n  education = draw_categorical(\n    prob = c(0.15, 0.3, 0.4, 0.15),\n    N = N,\n    category_labels = c(\"Less than HS\", \"HS\", \"Some college\", \"College+\")\n  ),\n  insurance = draw_binary(prob = 0.7),\n  prior_vaccines = draw_binary(prob = 0.4),\n  health_conscious = draw_binary(prob = 0.3),\n  distance_to_clinic = runif(N, 0, 30),\n  works_weekdays = draw_binary(prob = 0.8)\n)\n\n# Convert to data.table for consistency\nsim_data_fab <- as.data.table(sim_data_fab)\n\n# View the first few rows\nhead(sim_data_fab)\n\n# Summary statistics\nsummary(sim_data_fab)\n```\n:::\n\n\n\n\n### Step 3: Add a predicted baseline completion probability\n\nTo model the heterogeneity in participants' likelihood of completing the vaccine series, let's add a baseline predicted probability based on their characteristics:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add predicted baseline probability\nsim_data[, baseline_prob := 0.13 +  # Base rate\n         0.05 * (age > 40) +         # Older people more likely\n         0.08 * (insurance == 1) +    # Insurance increases likelihood\n         0.10 * (prior_vaccines == 1) + # Prior vaccination behavior\n         0.07 * (health_conscious == 1) - # Health consciousness\n         0.005 * distance_to_clinic +    # Distance (negative effect)\n         0.03 * (education %in% c(\"Some college\", \"College+\")) # Education effect\n]\n\n# Constrain probabilities between 0 and 1\nsim_data[baseline_prob < 0, baseline_prob := 0]\nsim_data[baseline_prob > 1, baseline_prob := 1]\n\n# Display distribution of baseline probabilities\nhist(sim_data$baseline_prob, \n     main = \"Distribution of Baseline Completion Probabilities\",\n     xlab = \"Probability of Completing Vaccine Series\",\n     col = \"lightblue\",\n     breaks = 20)\n```\n:::\n\n\n\n\n## Part 4: Implementing Different Randomization Approaches\n\n### Scene 3: The Randomization Revelation\n\nIn the hospital's data center, **Dr. P-Hacker** is gesturing at his computer screen, where a crude Excel sheet displays his \"randomization\" plan.\n\n\"I've already assigned participants to groups,\" he announces proudly. \"I just alternated down the list: A, B, C, D, A, B, C, D...\"\n\n**Nurse Random** looks horrified. \"That's not randomization at all! It's completely predictable, and it doesn't account for any baseline characteristics.\"\n\n\"But it's so... neat,\" Dr. P-Hacker protests.\n\n**Dr. Doub R. Obust** shakes his head sadly. \"A cardinal sin in experimental design. We need proper randomization that gives each participant a known, non-zero probability of assignment to each treatment condition, and that's independent of potential outcomes.\"\n\n\"Exactly,\" Nurse Random agrees. \"And ideally, we should stratify by key characteristics to ensure balance across treatment arms.\"\n\n\"Strati-what now?\" CEO Beta asks, glancing up from his phone where he's been browsing luxury yacht websites.\n\nDr. Doub R. Obust sighs. \"This is why we need the university consultants.\"\n\n### Step 1: Simple Randomization\n\nLet's implement the simplest form of randomization - Bernoulli trials:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define treatment conditions\ntreatment_conditions <- c(\"Control\", \"FirstDoseFree\", \"LastDoseFree\", \"Graduated\")\n\n# Simple randomization (Bernoulli trials)\nsimple_randomize <- function(data, conditions, probabilities = NULL) {\n  n <- nrow(data)\n  k <- length(conditions)\n  \n  # If no probabilities provided, use equal probabilities\n  if (is.null(probabilities)) {\n    probabilities <- rep(1/k, k)\n  }\n  \n  # Generate random assignments\n  assignments <- sample(conditions, n, replace = TRUE, prob = probabilities)\n  \n  return(assignments)\n}\n\n# Apply simple randomization\nset.seed(072111)\nsim_data[, treatment_simple := simple_randomize(sim_data, treatment_conditions)]\n\n# Check distribution\ntable(sim_data$treatment_simple)\n```\n:::\n\n\n\n\n### Step 2: Complete Randomization\n\nNow let's use complete randomization to ensure exact numbers in each group:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Complete randomization\ncomplete_randomize <- function(data, conditions, ns = NULL) {\n  n <- nrow(data)\n  k <- length(conditions)\n  \n  # If no specific counts provided, divide equally\n  if (is.null(ns)) {\n    ns <- rep(floor(n / k), k)\n    # Distribute any remainder\n    remainder <- n - sum(ns)\n    if (remainder > 0) {\n      ns[1:remainder] <- ns[1:remainder] + 1\n    }\n  }\n  \n  # Check for NA values in ns\n  if (any(is.na(ns))) {\n    stop(\"Group sizes (ns) contain NA values\")\n  }\n  \n  # Ensure all ns are positive integers\n  if (any(ns <= 0) || any(ns != floor(ns))) {\n    stop(\"All group sizes must be positive integers\")\n  }\n  \n  # Ensure sum of ns equals total sample size\n  sum_ns <- sum(ns)\n  if (sum_ns != n) {\n    stop(paste(\"Sum of group sizes (\", sum_ns, \") does not equal total sample size (\", n, \")\", sep = \"\"))\n  }\n  \n  # Create vector of assignments\n  assignments <- rep(conditions, ns)\n  \n  # Randomly shuffle\n  assignments <- sample(assignments, n)\n  \n  return(assignments)\n}\n\n# Calculate desired sample sizes from optimal allocation\n# Adjust to ensure the sum matches the total sample size\nn_total_current <- nrow(sim_data)\n\n# Debug n_per_arm_optimal\nprint(\"n_per_arm_optimal values:\")\nprint(n_per_arm_optimal)\n\n# Check for NA values\nif (any(is.na(n_per_arm_optimal))) {\n  warning(\"n_per_arm_optimal contains NA values, using equal allocation instead\")\n  # Fall back to equal allocation\n  treatment_counts <- rep(floor(n_total_current / 4), 4)\n  names(treatment_counts) <- c(\"Control\", \"FirstDoseFree\", \"LastDoseFree\", \"Graduated\")\n  \n  # Handle remainder\n  remainder <- n_total_current - sum(treatment_counts)\n  if (remainder > 0) {\n    treatment_counts[1:remainder] <- treatment_counts[1:remainder] + 1\n  }\n} else {\n  # Original calculation, but with more robust error handling\n  # Set control size to a reasonable value\n  control_size <- min(n_per_arm_optimal)\n  if (is.na(control_size) || control_size <= 0) {\n    control_size <- floor(n_total_current / 8) # Default to 1/8 of total\n  }\n  \n  # Get treatment arm sizes, replacing any NA values with reasonable defaults\n  get_arm_size <- function(arm_name, default_proportion = 0.25) {\n    size <- n_per_arm_optimal[arm_name]\n    if (is.na(size) || size <= 0) {\n      # Default to 1/4 of what's left after control\n      size <- floor((n_total_current - control_size) * default_proportion)\n    }\n    return(size)\n  }\n  \n  # Total from optimal allocation\n  arms <- c(\n    Control = control_size,\n    FirstDoseFree = get_arm_size(\"first_dose_free\", 1/3),\n    LastDoseFree = get_arm_size(\"last_dose_free\", 1/3),\n    Graduated = get_arm_size(\"graduated\", 1/3)\n  )\n  \n  total_optimal <- sum(arms)\n  \n  # Calculate proportions\n  proportions <- arms / total_optimal\n  \n  # Recalculate group counts based on current sample size\n  treatment_counts <- floor(proportions * n_total_current)\n  \n  # Handle remainder to ensure sum matches exactly\n  remainder <- n_total_current - sum(treatment_counts)\n  if (remainder > 0) {\n    # Add the remainder to groups in order until it's all distributed\n    for (i in 1:remainder) {\n      idx <- (i - 1) %% length(treatment_counts) + 1\n      treatment_counts[idx] <- treatment_counts[idx] + 1\n    }\n  }\n}\n\n# Verify the sum equals the total\ncat(\"Treatment counts:\")\nprint(treatment_counts)\ncat(\"Sum of treatment counts:\", sum(treatment_counts), \"\\n\")\ncat(\"Total sample size:\", n_total_current, \"\\n\")\n\n# Apply complete randomization with adjusted allocation\nset.seed(072111)\ntryCatch({\n  # Verify one more time that counts sum to the correct number\n  if (sum(treatment_counts) != nrow(sim_data)) {\n    stop(\"Treatment counts must sum to the total number of rows in sim_data\")\n  }\n  \n  sim_data[, treatment_complete := complete_randomize(\n    sim_data, \n    names(treatment_counts),\n    ns = treatment_counts\n  )]\n  \n  # Show results of randomization\n  cat(\"\\nTreatment assignment counts:\\n\")\n  print(table(sim_data$treatment_complete))\n}, error = function(e) {\n  # Fall back to simple equal allocation as a last resort\n  message(\"Error in randomization: \", e$message)\n  message(\"Falling back to simple equal allocation\")\n  \n  n <- nrow(sim_data)\n  k <- 4  # Number of treatment groups\n  equal_counts <- rep(floor(n / k), k)\n  remainder <- n - sum(equal_counts)\n  if (remainder > 0) {\n    equal_counts[1:remainder] <- equal_counts[1:remainder] + 1\n  }\n  \n  conditions <- c(\"Control\", \"FirstDoseFree\", \"LastDoseFree\", \"Graduated\")\n  \n  sim_data[, treatment_complete := complete_randomize(\n    sim_data, \n    conditions,\n    ns = equal_counts\n  )]\n})\n\n# Check distribution\ntable(sim_data$treatment_complete)\n```\n:::\n\n\n\n\n### Step 3: Stratified Randomization\n\nLet's stratify by key characteristics that might influence outcomes:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Stratified randomization\nstratified_randomize <- function(data, conditions, strata_vars, ns = NULL) {\n  # Create strata based on combinations of strata_vars\n  data$strata <- do.call(paste, c(data[, strata_vars, with = FALSE], sep = \"_\"))\n  \n  # Get unique strata\n  unique_strata <- unique(data$strata)\n  \n  # Initialize treatment assignment vector\n  n <- nrow(data)\n  assignments <- rep(NA, n)\n  \n  # Loop through strata\n  for (stratum in unique_strata) {\n    # Get indices for this stratum\n    stratum_indices <- which(data$strata == stratum)\n    stratum_size <- length(stratum_indices)\n    \n    # Determine counts for this stratum (proportional to overall)\n    if (is.null(ns)) {\n      # Equal allocation within stratum\n      stratum_ns <- rep(floor(stratum_size / length(conditions)), length(conditions))\n      remainder <- stratum_size - sum(stratum_ns)\n      if (remainder > 0) {\n        stratum_ns[1:remainder] <- stratum_ns[1:remainder] + 1\n      }\n    } else {\n      # Proportional allocation based on provided ns\n      stratum_props <- ns / sum(ns)\n      stratum_ns <- floor(stratum_size * stratum_props)\n      remainder <- stratum_size - sum(stratum_ns)\n      if (remainder > 0) {\n        # Distribute remainder to largest groups\n        for (i in order(stratum_ns, decreasing = TRUE)[1:remainder]) {\n          stratum_ns[i] <- stratum_ns[i] + 1\n        }\n      }\n    }\n    \n    # Generate assignments for this stratum\n    stratum_assignments <- rep(conditions, stratum_ns)\n    if (length(stratum_assignments) < stratum_size) {\n      # Handle edge case: add one more randomized assignment if needed\n      stratum_assignments <- c(stratum_assignments, \n                              sample(conditions, stratum_size - length(stratum_assignments)))\n    }\n    \n    # Randomly shuffle and assign\n    stratum_assignments <- sample(stratum_assignments, stratum_size)\n    assignments[stratum_indices] <- stratum_assignments\n  }\n  \n  return(assignments)\n}\n\n# Define stratification variables\nstrata_vars <- c(\"insurance\", \"prior_vaccines\")\n\n# Apply stratified randomization\nset.seed(072111)\nsim_data[, treatment_strat := stratified_randomize(\n  sim_data, \n  names(treatment_counts),\n  strata_vars = strata_vars,\n  ns = treatment_counts\n)]\n\n# Check distribution\ntable(sim_data$treatment_strat)\n\n# Check distribution within strata\nwith(sim_data, table(insurance, prior_vaccines, treatment_strat))\n```\n:::\n\n\n\n\n### Step 4: Using randomizr for efficient randomization\n\nThe `randomizr` package provides a more streamlined way to implement these randomization approaches:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(randomizr)\n\n# Simple randomization with randomizr\nsim_data[, treatment_randomizr_simple := complete_ra(\n  N = nrow(sim_data),\n  num_arms = length(treatment_conditions),\n  conditions = treatment_conditions\n)]\n\n# Complete randomization with randomizr\nsim_data[, treatment_randomizr_complete := complete_ra(\n  N = nrow(sim_data),\n  conditions = names(treatment_counts),\n  prob_each = treatment_counts / sum(treatment_counts)\n)]\n\n# Stratified randomization with randomizr\nsim_data[, strata_combined := paste(insurance, prior_vaccines, sep = \"_\")]\nsim_data[, treatment_randomizr_strat := block_ra(\n  blocks = strata_combined,\n  conditions = names(treatment_counts),\n  prob_each = treatment_counts / sum(treatment_counts)\n)]\n\n# Check distributions\ncat(\"Simple randomization with randomizr:\\n\")\ntable(sim_data$treatment_randomizr_simple)\n\ncat(\"\\nComplete randomization with randomizr:\\n\")\ntable(sim_data$treatment_randomizr_complete)\n\ncat(\"\\nStratified randomization with randomizr:\\n\")\ntable(sim_data$treatment_randomizr_strat)\n```\n:::\n\n\n\n\n## Part 5: Assessing Balance Across Treatment Groups\n\n### Scene 4: The Balance Inquiry\n\nWith the randomization complete, the team at St. Null's gathers to review the results.\n\n**Dr. P-Hacker** squints at the printout. \"It looks random to me. Can we start the intervention now?\"\n\n**Nurse Random** shakes her head firmly. \"Not until we check for balance. We need to make sure our randomization didn't produce any significant differences in baseline characteristics between groups.\"\n\n\"But it's randomized!\" protests Dr. P-Hacker. \"Doesn't that guarantee balance?\"\n\n**Dr. Doub R. Obust** adjusts his glasses. \"In expectation, yes. But any single realization of a randomization process can result in imbalances by chance. We need to verify that our treatment groups are comparable at baseline.\"\n\n\"Exactly,\" Nurse Random agrees. \"We should check for balance on key characteristics, especially those that might influence our outcomes.\"\n\n\"And if there's imbalance?\" asks CEO Beta, looking worried.\n\n\"Then we might need to re-randomize,\" Dr. Doub R. Obust says, \"or account for these differences in our analysis.\"\n\nDr. P-Hacker sighs dramatically. \"More delays!\"\n\n\"Better a delayed but valid study,\" Nurse Random counters, \"than a quick but meaningless one.\"\n\n### Step 1: Creating balance tables\n\nLet's assess balance across our treatment groups for key covariates:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to assess balance\nassess_balance <- function(data, treatment_var, covariates) {\n  # Check if treatment variable exists\n  if (!treatment_var %in% names(data)) {\n    stop(paste(\"Treatment variable\", treatment_var, \"not found in dataset\"))\n  }\n  \n  # Check if treatment variable has multiple levels\n  treatment_levels <- unique(data[[treatment_var]])\n  if (length(treatment_levels) < 2) {\n    stop(\"Treatment variable must have at least 2 levels for balance assessment\")\n  }\n  \n  # Initialize results table\n  results <- data.table(\n    Variable = character(),\n    Category = character(),\n    Overall = numeric()\n  )\n  \n  # Add columns for each treatment level\n  for (level in treatment_levels) {\n    results[[as.character(level)]] <- numeric()\n  }\n  \n  # Add columns for p-values\n  results[[\"p.value\"]] <- numeric()\n  \n  # Process each covariate\n  for (var in covariates) {\n    # Check if variable exists\n    if (!var %in% names(data)) {\n      warning(paste(\"Covariate\", var, \"not found in dataset - skipping\"))\n      next\n    }\n    \n    # Determine variable type and handle appropriately\n    if (is.factor(data[[var]]) || is.character(data[[var]]) || length(unique(na.omit(data[[var]]))) <= 5) {\n      # Categorical variable (factor, character, or numeric with few unique values)\n      var_data <- data[[var]]\n      \n      # Ensure factor type for table creation\n      if (!is.factor(var_data)) {\n        var_data <- as.factor(var_data)\n      }\n      \n      # Create contingency table safely\n      var_table <- tryCatch({\n        table(var_data, data[[treatment_var]])\n      }, error = function(e) {\n        warning(paste(\"Error creating table for\", var, \":\", e$message))\n        return(NULL)\n      })\n      \n      # Skip if table creation failed\n      if (is.null(var_table) || any(dim(var_table) == 0)) {\n        warning(paste(\"Could not create valid contingency table for\", var))\n        next\n      }\n      \n      # Calculate proportions\n      var_props <- tryCatch({\n        prop.table(var_table, margin = 2)\n      }, error = function(e) {\n        warning(paste(\"Error calculating proportions for\", var, \":\", e$message))\n        # Create a matrix of NAs with appropriate dimensions\n        props <- matrix(NA, nrow = nrow(var_table), ncol = ncol(var_table))\n        rownames(props) <- rownames(var_table)\n        colnames(props) <- colnames(var_table)\n        return(props)\n      })\n      \n      # Chi-square test (only if enough data)\n      chi_p_value <- tryCatch({\n        if (any(var_table < 5)) {\n          # Use Fisher's exact test for small counts\n          fisher.test(var_table, simulate.p.value = TRUE)$p.value\n        } else {\n          chisq.test(var_table)$p.value\n        }\n      }, error = function(e) {\n        warning(paste(\"Error in statistical test for\", var, \":\", e$message))\n        return(NA)\n      })\n      \n      # Add rows for each category\n      for (cat_idx in 1:nrow(var_props)) {\n        cat <- rownames(var_props)[cat_idx]\n        \n        row <- data.table(\n          Variable = var,\n          Category = as.character(cat),\n          Overall = sum(var_data == cat, na.rm = TRUE) / sum(!is.na(var_data))\n        )\n        \n        # Add proportions for each treatment level\n        for (level in treatment_levels) {\n          level_col <- which(colnames(var_props) == as.character(level))\n          if (length(level_col) > 0) {\n            row[[as.character(level)]] <- var_props[cat_idx, level_col]\n          } else {\n            row[[as.character(level)]] <- NA\n          }\n        }\n        \n        # Add p-value\n        row[[\"p.value\"]] <- chi_p_value\n        \n        # Add to results\n        results <- rbind(results, row)\n      }\n    } else {\n      # Continuous variable\n      # Overall mean\n      row <- data.table(\n        Variable = var,\n        Category = \"Mean\",\n        Overall = mean(data[[var]], na.rm = TRUE)\n      )\n      \n      # Means for each treatment level\n      for (level in treatment_levels) {\n        level_data <- data[data[[treatment_var]] == level, ][[var]]\n        if (length(level_data) > 0) {\n          row[[as.character(level)]] <- mean(level_data, na.rm = TRUE)\n        } else {\n          row[[as.character(level)]] <- NA\n        }\n      }\n      \n      # ANOVA test (catch errors)\n      row[[\"p.value\"]] <- tryCatch({\n        anova_model <- aov(as.formula(paste(var, \"~\", treatment_var)), data = data)\n        anova_summary <- summary(anova_model)\n        anova_summary[[1]]$`Pr(>F)`[1]\n      }, error = function(e) {\n        warning(paste(\"Error in ANOVA for\", var, \":\", e$message))\n        return(NA)\n      })\n      \n      # Add to results\n      results <- rbind(results, row)\n    }\n  }\n  \n  return(results)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select covariates to check for balance\nbalance_covariates <- c(\"age\", \"female\", \"education\", \"insurance\", \"prior_vaccines\", \"distance_to_clinic\")\n\n# Check balance for complete randomization\nbalance_complete <- assess_balance(\n  sim_data, \n  \"treatment_complete\", \n  balance_covariates\n)\n\n# Check balance for stratified randomization\nbalance_strat <- assess_balance(\n  sim_data, \n  \"treatment_strat\", \n  balance_covariates\n)\n\n# Print balance tables\ncat(\"Balance table for complete randomization:\\n\")\nprint(balance_complete)\n\ncat(\"\\nBalance table for stratified randomization:\\n\")\nprint(balance_strat)\n\n# Compare number of significant imbalances\nsig_complete <- sum(balance_complete$p.value < 0.05)\nsig_strat <- sum(balance_strat$p.value < 0.05)\n\ncat(\"\\nNumber of significant imbalances (p < 0.05):\\n\")\ncat(\"Complete randomization:\", sig_complete, \"\\n\")\ncat(\"Stratified randomization:\", sig_strat, \"\\n\")\n```\n:::\n\n\n\n\n### Step 2: Visual assessment of balance\n\nLet's create visual representations of balance across treatment groups:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\n# Function to plot standardized mean differences\nplot_balance <- function(data, treatment_var, covariates) {\n  # Initialize results\n  results <- data.frame(\n    Variable = character(),\n    Category = character(),\n    Std_Diff = numeric(),\n    Treatment = character()\n  )\n  \n  # Process each covariate\n  for (var in covariates) {\n    # Overall SD\n    var_sd <- sd(as.numeric(data[[var]]), na.rm = TRUE)\n    \n    # Reference level (Control)\n    ref_mean <- mean(as.numeric(data[data[[treatment_var]] == \"Control\", ][[var]]), na.rm = TRUE)\n    \n    # Other treatment levels\n    treatment_levels <- setdiff(unique(data[[treatment_var]]), \"Control\")\n    \n    for (level in treatment_levels) {\n      # Treatment mean\n      treat_mean <- mean(as.numeric(data[data[[treatment_var]] == level, ][[var]]), na.rm = TRUE)\n      \n      # Standardized difference\n      std_diff <- (treat_mean - ref_mean) / var_sd\n      \n      # Add to results\n      results <- rbind(results, data.frame(\n        Variable = var,\n        Std_Diff = std_diff,\n        Treatment = level\n      ))\n    }\n  }\n  \n  # Create plot\n  ggplot(results, aes(x = Variable, y = Std_Diff, fill = Treatment)) +\n    geom_bar(stat = \"identity\", position = \"dodge\") +\n    geom_hline(yintercept = 0, linetype = \"dashed\") +\n    geom_hline(yintercept = c(-0.1, 0.1), linetype = \"dotted\", color = \"red\") +\n    labs(\n      title = \"Standardized Mean Differences\",\n      subtitle = \"Treatment vs. Control\",\n      x = \"Variable\",\n      y = \"Standardized Difference\"\n    ) +\n    coord_flip() +\n    theme_minimal()\n}\n\n# Create balance plots\nbalance_plot_complete <- plot_balance(\n  sim_data, \n  \"treatment_complete\", \n  c(\"age\", \"female\", \"insurance\", \"prior_vaccines\", \"distance_to_clinic\")\n)\n\nbalance_plot_strat <- plot_balance(\n  sim_data, \n  \"treatment_strat\", \n  c(\"age\", \"female\", \"insurance\", \"prior_vaccines\", \"distance_to_clinic\")\n)\n\n# Display plots\nbalance_plot_complete\nbalance_plot_strat\n```\n:::\n\n\n\n\n## Part 6: Documenting the Randomization Procedure\n\n### Scene 5: Documentation Day\n\nAs the team finalizes their randomization approach, **Nurse Random** insists on proper documentation.\n\n\"We need to document every step of our randomization procedure,\" she explains. \"Not just for transparency, but for reproducibility.\"\n\n**Dr. P-Hacker** looks puzzled. \"Can't we just say 'we randomized participants' and leave it at that?\"\n\n**Dr. Doub R. Obust** chuckles. \"That's like saying 'we did surgery' without specifying the procedure, instruments, or technique. Details matter in science.\"\n\n\"Exactly,\" Nurse Random agrees. \"We need to record the randomization method, the seed used, the stratification variables, and verification of balance.\"\n\n\"But why?\" whines Dr. P-Hacker.\n\n\"Because,\" Dr. Doub R. Obust explains patiently, \"someday someone might need to replicate our study. Or we might need to defend our methods. Good documentation is good science.\"\n\nCEO Beta nods decisively. \"Makes sense to me. If I'm going to put the hospital's name on this project, I want it to be bulletproof.\"\n\n### Step 1: Creating a randomization log\n\nLet's create a comprehensive randomization log:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create randomization log\nrandomization_log <- data.table(\n  study_name = \"HBV Vaccination Subsidy Trial\",\n  randomization_date = Sys.Date(),\n  randomization_method = \"Stratified randomization\",\n  seed_value = 072111,\n  stratification_variables = paste(strata_vars, collapse = \", \"),\n  treatment_conditions = paste(names(treatment_counts), collapse = \", \"),\n  sample_size_total = nrow(sim_data),\n  sample_sizes_by_arm = paste(paste(names(treatment_counts), treatment_counts, sep = \": \"), \n                             collapse = \"; \"),\n  balance_assessment = paste0(sig_strat, \" significant imbalances out of \", \n                             length(balance_covariates), \" covariates\")\n)\n\n# Save randomization log\nwrite.csv(randomization_log, \"randomization_log.csv\", row.names = FALSE)\n\n# Save treatment assignments\ntreatment_assignments <- sim_data[, .(id, treatment = treatment_strat)]\nwrite.csv(treatment_assignments, \"treatment_assignments.csv\", row.names = FALSE)\n\n# Save balance assessment\nwrite.csv(balance_strat, \"balance_assessment.csv\", row.names = FALSE)\n\n# Display randomization log\nprint(randomization_log)\n```\n:::\n\n\n\n\n### Step 2: Finalizing the allocation approch\n\nBased on our analyses, let's make a final recommendation for the experimental design:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract key results\nfinal_allocation <- treatment_counts\nmdes <- mde_optimal\nexpected_completion <- baseline_completion + expected_effects\n\n# Create summary table\nfinal_summary <- data.table(\n  Strategy = names(final_allocation),\n  Sample_Size = final_allocation,\n  Proportion = final_allocation / sum(final_allocation),\n  Expected_Completion = c(baseline_completion, expected_completion[-4]),  # Exclude full_series\n  MDE = c(NA, mdes[-4]),  # NA for control, exclude full_series\n  Powered = c(NA, expected_effects[-4] > mdes[-4])  # NA for control, exclude full_series\n)\n\n# Display final recommendation\nprint(final_summary)\n```\n:::\n\n\n\n\n## Discussion and Conclusion\n\n### Final Questions to Consider\n\nAs you complete this lab, consider the following questions:\n\n1.  How does the optimal allocation differ from an equal allocation approach? What factors drive this difference?\n\n2.  Which randomization approach provided the best balance across treatment groups, and why?\n\n3.  What are the trade-offs between the different subsidy strategies in terms of:\n\n    -   Cost-effectiveness\n    -   Expected impact on vaccine completion rates\n    -   Statistical power to detect effects\n\n4.  If the foundation asked you to recommend just one subsidy strategy to test against a control group (rather than testing all three), which would you choose and why?\n\n5.  How might the results change if:\n\n    -   The ICC (intraclass correlation) between patients within clinics was high?\n    -   The baseline completion rate was much higher (e.g., 30% instead of 13%)?\n    -   The cost of one dose was much higher than the others?\n\n### Submission Instructions\n\n1.  Make sure your `.qmd` file knits successfully to HTML.\n2.  Include your answers to the discussion questions.\n3.  Submit your completed lab to Gradescope by the deadline.\n\nRemember that good experimental design balances statistical power, practical constraints, and the focus of inquiry. In the real world, there's rarely a perfect design—only thoughtful trade-offs guided by clear priorities.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}