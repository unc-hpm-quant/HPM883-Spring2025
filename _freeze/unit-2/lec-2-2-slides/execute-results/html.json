{
  "hash": "4bf48748f28213cf04c4d46fa184c9c4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Unit 2.2: Advanced Randomization Techniques\"\nauthor: \"Sean Sylvia, Ph.D.\"\ndate: February 25, 2025\nformat:\n  revealjs:\n    theme: default\n    slide-number: true\n    chalkboard: true\n    transition: fade\n    progress: true\n    incremental: false\n    toc: false\n    scrollable: false\n    smaller: false\n    footer: \"UNC HPM 883 - Advanced Quantitative Methods\"\n---\n\n\n\n## Randomization: The Foundation of Causal Inference\n\n::: {.incremental}\n* Last session: Maximizing power through optimal experimental design\n* Today: The art and science of randomization\n* Randomization enables causal claims by balancing **all** factors:\n  * Observable characteristics\n  * Unobservable characteristics\n  * Potential outcomes\n:::\n\n::: {.notes}\nEmphasize that randomization is what allows us to make causal claims - it's the key distinction between experimental and observational studies.\n:::\n\n## Why Does Randomization Work?\n\nBecause it ensures:\n\n::: {.incremental}\n1. **Non-zero probability condition**: Everyone has a chance of treatment\n2. **Individualism**: Independence across units\n3. **Unconfoundedness**: Balance on observed/unobserved covariates\n:::\n\n$$E[Y_i(0)|D_i=1] = E[Y_i(0)|D_i=0]$$\n\n::: {.fragment}\nThe untreated potential outcomes are the same in both groups!\n:::\n\n## What You Need for Randomization \n\n::: {.incremental}\n1. **Sample of units**: Who or what will be randomized\n2. **Allocation ratio**: How many units to each condition\n3. **Randomization device**: Physical or computational\n4. **Baseline covariates**: (for some approaches)\n:::\n\n## Random Sampling vs. Random Assignment\n\n\n\n```{mermaid}\n%%| fig-width: 10\n%%| fig-height: 8\n%%| fig-align: center\n\nflowchart TD\n    %% Nodes\n    A[Target Population]:::carolina_blue\n    B[Random Sampling]:::navy\n    C[Evaluation Sample]:::carolina_blue\n    D[Not in Evaluation]:::carolina_blue\n    E[Random Assignment]:::navy\n    F[Treatment Group]:::carolina_blue\n    G[Control Group]:::carolina_blue\n    \n    %% External and internal validity labels\n    EV[external validity]:::label\n    IV[internal validity]:::label\n    \n    %% Connections\n    A --> B\n    B --> C\n    B --> D\n    C --> E\n    E --> F\n    E --> G\n    \n    %% Arrows pointing to validity concepts\n    B -.-> EV\n    E -.-> IV\n    \n    %% Styling\n    classDef carolina_blue fill:#4B9CD3,stroke:#13294B,stroke-width:2px,color:#FFFFFF,font-size:14px\n    classDef navy fill:#13294B,stroke:#4B9CD3,stroke-width:2px,color:#FFFFFF,font-size:14px\n    classDef label fill:none,stroke:none,color:#4B9CD3,font-size:16px\n    \n    %% Make Random Sampling box dashed\n    style B stroke-dasharray: 5 5\n```\n\n\n\n## Classical Assignment Mechanisms Framework \n\n\n\n```{mermaid}\nflowchart TD\n    %% Top nodes - conditions\n    A[Non-zero probability condition]:::gold\n    B[Individualism condition]:::gold\n    C[Unconfoundedness condition]:::gold\n    \n    %% Middle node - mechanisms\n    D((Classical Random\\nAssignment\\nMechanisms)):::tarHeelRed\n    \n    %% Assignment types\n    E[Bernoulli Trial]:::carolinaBlue\n    F[Complete Randomized\\nExperiment (CRE)]:::carolinaBlue\n    G[Stratified\\nRandomization]:::carolinaBlue\n    H[Rerandomization]:::carolinaBlue\n    I[Matched Pairs]:::carolinaBlue\n    \n    %% Bottom node - inference\n    J((Design-conscious\\nInference)):::uncGreen\n    \n    %% Connections\n    A --> D\n    B --> D\n    C --> D\n    \n    D --> E\n    D --> F\n    D --> G\n    D --> H\n    D --> I\n    \n    E --> J\n    F --> J\n    G --> J\n    H --> J\n    I --> J\n    \n    %% UNC Brand Colors\n    classDef gold fill:#FFD100,stroke:#13294B,stroke-width:1px,color:#13294B\n    classDef tarHeelRed fill:#DC143C,stroke:#13294B,stroke-width:1px,color:#FFFFFF\n    classDef carolinaBlue fill:#4B9CD3,stroke:#13294B,stroke-width:1px,color:#FFFFFF\n    classDef uncGreen fill:#8DB434,stroke:#13294B,stroke-width:1px,color:#FFFFFF\n```\n\n\n\n## Classical Assignment Mechanisms\n\n1. Bernoulli Trials\n2. Complete Randomization\n3. Re-randomization\n4. Stratified Randomization\n5. Matched-Pair Designs\n\n## Bernoulli Trials\n\n* Simplest approach: independent coin flips\n* $P(Z_i = 1) = p$ for all units $i$\n\n::: {.fragment}\n**Advantages:**\n* Simple to implement\n* Can randomize as participants arrive\n* No baseline data needed\n:::\n\n::: {.fragment}\n**Disadvantages:**\n* Random group sizes\n* Potential imbalance on key covariates\n* Implementation vulnerability\n:::\n\n## Case Study: The Canadian National Breast Screening Study\n\n::: {.incremental}\n* Major randomized trial evaluating mammography screening effectiveness\n* Used alternating assignment (first to treatment, second to control)\n* Design flaw: clinical breast exams conducted *before* randomization\n* Nurses and physicians could (and did) influence group assignments\n:::\n\n::: {.fragment}\nThe randomization process was compromised in several ways\n:::\n\n## CNBSS: Randomization Failures\n\n::: {.incremental}\n* **Pre-randomization examination**: Detected suspicious lumps before group assignment\n* **Selection bias**: Women with palpable lumps disproportionately assigned to mammography group\n* **Inadequate concealment**: Study staff could influence group assignments\n* **Evidence of manipulation**: Names overwritten, identities reversed, lines skipped\n:::\n\n::: {.fragment}\nResult: Mammography group had 68% higher incidence of advanced cancers at baseline!\n:::\n\n## CNBSS: Impact on Study Validity\n\n::: {.incremental}\n* Study reported no mortality benefit from mammography screening\n* **However**: The randomization bias likely masked true benefits\n* Higher-risk patients concentrated in treatment group\n* Control group contamination: ~25% received mammograms outside the study\n:::\n\n::: {.fragment}\n**Broader lesson**: Compromise in randomization can fundamentally undermine study validity and lead to decades of scientific controversy\n:::\n\n## Complete Randomization\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(072311)  # Set seed for reproducibility\n\n# Parameters\nN <- 100          # Total number of units\np <- 0.5          # Proportion to assign to treatment\n\n# Generate random numbers and sort\nunits <- data.frame(\n  id = 1:N,\n  random_num = runif(N)\n)\nunits <- units[order(units$random_num),]\n\n# Assign first p% to treatment\nunits$treatment <- 0\nunits$treatment[1:(N*p)] <- 1\n\n# Check resulting allocation\ntable(units$treatment)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n 0  1 \n50 50 \n```\n\n\n:::\n:::\n\n\n\nEach participant has fixed probability of assignment, with total group sizes fixed in advance.\n\n## Chance Imbalance with Complete Randomization\n\n::: {.incremental}\n* Even with perfect implementation, covariates may be imbalanced\n* Example: In a study of 722 people (NLSY data):\n  * ~45% of randomizations had all covariates balanced\n  * ~30% had one imbalanced covariate\n  * Remaining had multiple imbalanced covariates\n:::\n\n::: {.fragment}\nThis raises two critical questions:\n1. How can we ensure better balance in design?\n2. What do we do if imbalance occurs?\n:::\n\n## Re-randomization\n\n::: {.incremental}\n* Generate multiple randomizations\n* Keep only those with good balance\n* Approach 1: All p-values > threshold (e.g., 0.05)\n* Approach 2: Choose iteration with best overall balance\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbalance_check <- function(data, treatment_var, balance_vars) {\n  # Initialize minimum p-value\n  min_pval <- 1\n  \n  # Check each covariate\n  for (var in balance_vars) {\n    # T-test for continuous variables\n    t_result <- t.test(data[[var]] ~ data[[treatment_var]])\n    min_pval <- min(min_pval, t_result$p.value)\n  }\n  \n  return(min_pval)\n}\n\n# Re-randomization function\nrerandomize <- function(data, p_threshold = 0.1, max_attempts = 1000) {\n  n <- nrow(data)\n  n_treat <- floor(n * 0.5)  # 50% to treatment\n  attempts <- 0\n  \n  repeat {\n    # Generate a new randomization\n    treatment <- rep(0, n)\n    treatment[sample(1:n, n_treat)] <- 1\n    data$treatment <- treatment\n    \n    # Check balance\n    pval <- balance_check(data, \"treatment\", c(\"age\", \"income\", \"education\"))\n    \n    attempts <- attempts + 1\n    \n    # Accept if p-value threshold met or max attempts reached\n    if (pval > p_threshold || attempts >= max_attempts) {\n      break\n    }\n  }\n  \n  return(list(treatment = data$treatment, attempts = attempts, min_pval = pval))\n}\n```\n:::\n\n\n\nThis function repeats randomization until finding one where all p-values exceed our threshold.\n\n## Drawbacks of Re-randomization\n\n::: {.incremental}\n* Opaque constraints: \"Black box\" process\n* Unusual handling of outliers\n* Computationally expensive\n* Could run forever if criteria too strict\n* Statistical inference must account for the procedure\n* Cannot balance on unobserved covariates\n:::\n\n## Stratified (Block) Randomization\n\n![Stratified Randomization](/unit-2/media/stratified-rand.png)\n\n::: {.incremental}\n1. Divide sample into strata based on covariates\n2. Randomize separately within each stratum\n3. Perfect balance on stratification variables\n:::\n\n## Implementing Stratified Randomization\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(072311)\n\n# Create example data with categorical covariates\ndata <- data.frame(\n  id = 1:100,\n  gender = sample(c(\"Male\", \"Female\"), 100, replace = TRUE),\n  age_group = sample(c(\"Under 30\", \"30-50\", \"Over 50\"), 100, replace = TRUE),\n  stringsAsFactors = FALSE\n)\n\n# Create strata based on combinations of covariates\ndata$stratum <- paste(data$gender, data$age_group, sep = \"_\")\n\n# Function for stratified randomization\nstratified_randomize <- function(data, strata_var, p = 0.5) {\n  # Initialize assignment vector\n  assignment <- rep(NA, nrow(data))\n  \n  # Get unique strata\n  strata <- unique(data[[strata_var]])\n  \n  # Randomize within each stratum\n  for (s in strata) {\n    # Get indices for this stratum\n    indices <- which(data[[strata_var]] == s)\n    n_stratum <- length(indices)\n    \n    # Calculate number to assign to treatment\n    n_treat <- round(n_stratum * p)\n    \n    # Ensure at least one in each group if possible\n    if (n_stratum > 1) {\n      n_treat <- min(max(n_treat, 1), n_stratum - 1)\n    } else {\n      n_treat <- sample(0:1, 1)  # Random for singletons\n    }\n    \n    # Perform randomization within stratum\n    treat_indices <- sample(indices, n_treat)\n    assignment[indices] <- 0\n    assignment[treat_indices] <- 1\n  }\n  \n  return(assignment)\n}\n\n# Apply stratified randomization\ndata$treatment <- stratified_randomize(data, \"stratum\")\n\n# Check balance by strata\ntable(data$stratum, data$treatment)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 \n                   0  1\n  Female_30-50    11 10\n  Female_Over 50   8  8\n  Female_Under 30  7  7\n  Male_30-50       9  9\n  Male_Over 50     7  8\n  Male_Under 30    8  8\n```\n\n\n:::\n:::\n\n\n\nThis code creates strata from combinations of gender and age group, then randomizes within each stratum.\n\n## Selecting Stratification Variables\n\n::: {.incremental}\n* **Discrete variables** are easier to implement\n* Prioritize variables that **strongly predict outcomes**\n* Include variables where **heterogeneous effects** are expected\n* Be careful of **too many strata** - causes \"small cell\" problems\n:::\n\n::: {.fragment}\n**Handling \"misfits\"** (when strata size not divisible by treatments):\n* Remove units randomly\n* Create separate strata for misfits\n* Use different randomization approach for misfits\n:::\n\n## Matched Pairs Randomization\n\n::: {.incremental}\n* Create pairs of similar units\n* Randomize one to treatment within each pair\n* Like stratification taken to the extreme\n* Perfect for continuous covariates\n:::\n\n## Implementing Matched Pairs\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(optmatch)  # For optimal matching\n\n# Generate example data\nset.seed(072311)\ndata <- data.frame(\n  id = 1:100,\n  age = rnorm(100, 45, 10),\n  income = rnorm(100, 50000, 15000),\n  health_score = rnorm(100, 70, 15)\n)\n\n# Create distance matrix based on covariates\nX <- as.matrix(data[, c(\"age\", \"income\", \"health_score\")])\nX_scaled <- scale(X)  # Standardize to have equal importance\ndist_matrix <- dist(X_scaled)\n\n# Create optimal matches\nmatches <- pairmatch(dist_matrix, data = data)\ndata$pair_id <- matches\n\n# Randomize within pairs\npair_randomize <- function(data, pair_var) {\n  # Initialize assignment vector\n  assignment <- rep(NA, nrow(data))\n  \n  # Get unique pairs\n  pairs <- unique(data[[pair_var]])\n  pairs <- pairs[!is.na(pairs)]  # Remove NA pairs\n  \n  # Randomize within each pair\n  for (p in pairs) {\n    # Get indices for this pair\n    indices <- which(data[[pair_var]] == p)\n    \n    # Skip if not exactly 2 units\n    if (length(indices) != 2) next\n    \n    # Randomly assign one to treatment\n    treat_index <- sample(indices, 1)\n    assignment[indices] <- 0\n    assignment[treat_index] <- 1\n  }\n  \n  return(assignment)\n}\n\n# Apply pair randomization\ndata$treatment <- pair_randomize(data, \"pair_id\")\n```\n:::\n\n\n\nThis code matches participants based on age, income, and health score, then randomizes one member of each pair to treatment.\n\n## Balance Tests: Approaches for Verification\n\n::: {.incremental}\n* **Individual covariate tests**: t-tests, Chi-square tests\n* **Joint omnibus tests**: F-tests testing multiple covariates simultaneously\n* **Regression-based tests**: Regress treatment on covariates\n* **Standardized differences**: Sample size-independent assessment\n:::\n\n## Standardized Differences for Large Samples\n\n::: {.incremental}\n* **Problem with p-values**: With large samples, tiny imbalances become \"significant\"\n* **Solution**: Standardized mean difference (SMD)\n:::\n\n$$SMD = \\frac{\\bar{X}_{treatment} - \\bar{X}_{control}}{\\sqrt{\\frac{s^2_{treatment} + s^2_{control}}{2}}}$$\n\n::: {.fragment}\n* Scale-free measure of imbalance\n* Independent of sample size\n* Rule of thumb: |SMD| < 0.1 is negligible imbalance\n:::\n\n## The \"Table 1\" Debate\n\n::: columns}\n::: {.column width=\"50%\"}\n### For Including\n* Transparency\n* Demonstrates randomization effectiveness\n* Provides context for readers\n* Shows extent of imbalance\n:::\n\n::: {.column width=\"50%\"}\n### Against Including\n* Randomization guarantees balance in expectation\n* Overemphasis on statistically significant differences\n* Can lead to inappropriate adjustments\n* Journal space limitations\n:::\n:::\n\n::: {.fragment}\n**Compromise**: Report balance without p-values, use standardized differences\n:::\n\n## Design-Based Inference\n\n::: {.incremental}\n* Randomization creates the foundation for inference\n* **Fisher's approach**: Test sharp null that treatment has no effect on any unit\n* **Randomization distribution**: Generate distribution of test statistics under all possible randomizations\n* **Permutation tests**: Compare observed statistic to randomization distribution\n:::\n\n## Complex Experimental Designs\n\n1. Units of Randomization & Spillovers\n2. Cluster Randomization\n3. Factorial Designs\n4. Fractional Factorial Designs  \n5. Within-Subject vs. Between-Subject\n6. Randomized Phase-in\n7. Adaptive Designs\n8. Variable Treatment Probabilities\n\n## Choosing the Unit of Randomization\n\n::: columns}\n::: {.column width=\"50%\"}\n### Key Considerations\n* Should match observational unit when possible\n* Must align with treatment delivery\n* Need to minimize spillovers\n* Consider statistical power\n:::\n\n::: {.column width=\"50%\"}\n### Common Units\n* **Individual**: Patients, students\n* **Cluster**: Villages, clinics, schools\n* **Time periods**: Days, weeks, shifts\n* **Networks**: Households, peer groups\n:::\n:::\n\n::: {.fragment}\n**Critical trade-off**: Statistical power vs. internal validity\n:::\n\n## The Spillover Problem\n\n::: {.incremental}\n* Spillovers occur when treatment affects untreated units\n* Types of spillovers:\n  * Direct interaction between units\n  * General equilibrium effects\n  * Information diffusion\n  * Resource competition\n:::\n\n::: {.fragment}\nRandomization at a higher level (clustering) can minimize unwanted spillovers.\n:::\n\n## Measuring Spillovers: Two-Stage Randomization\n\n![Two-Stage Randomization for Spillovers](/unit-2/media/two-stage-rand.png)\n\n::: {.notes}\nExplain how first randomizing clusters, then individuals within clusters allows for spillover measurement.\n:::\n\n## Cluster Randomization\n\n::: {.incremental}\n* **Definition**: Randomize groups (clusters) rather than individuals\n* **Common clusters**: Schools, clinics, villages, neighborhoods\n* **Key parameter**: Intraclass correlation coefficient (ICC)\n* **Design effect**: $DE = 1 + (m-1) \\times ICC$\n  * $m$ = average cluster size\n  * Increases required sample size\n:::\n\n::: {.fragment}\n**Analysis must account for clustering!**\n* Cluster-robust standard errors\n* Mixed-effects models\n* GEE approaches\n:::\n\n## Factorial Designs: Testing Multiple Treatments\n\n![2×2 Factorial Design](/unit-2/media/factorial-design.png)\n\n::: {.incremental}\n* Test multiple treatments simultaneously\n* Estimate main effects AND interactions\n* Efficient use of resources\n* Example: Two interventions with four groups\n  * No intervention (control)\n  * Intervention A only\n  * Intervention B only\n  * Both A and B\n:::\n\n## Randomized Phase-in Designs\n\n::: {.incremental}\n* All units eventually receive treatment\n* Randomize the **timing** of treatment\n* Advantages:\n  * Better compliance (everyone gets treatment eventually)\n  * Clear for partners with resource constraints\n  * Politically appealing compromise\n:::\n\n::: {.fragment}\n**But watch out for**:\n* Anticipation effects\n* Limited long-term impact measurement\n:::\n\n## Adaptive Randomization\n\n::: {.incremental}\n* Updates assignment probabilities based on accumulated data\n* Balances:\n  * **Exploration**: Learning which treatment works best\n  * **Exploitation**: Assigning more units to better treatments\n* Key ethical advantage: Fewer participants receive inferior treatments\n:::\n\n::: {.fragment}\n**Note**: We'll cover adaptive designs in more detail in a future lecture\n:::\n\n## Variable Treatment Probabilities\n\n::: {.incremental}\n* Units can have different probabilities of assignment\n* Requirements:\n  * Probabilities must be between 0 and 1\n  * Probabilities must be known\n* Analysis using inverse probability weighting:\n:::\n\n$$\\hat{\\tau}_{IPW} = \\frac{1}{N}\\sum_{i=1}^N \\frac{D_i Y_i}{p_i} - \\frac{(1-D_i)Y_i}{1-p_i}$$\n\n## Practical Implementation\n\n::: {.incremental}\n1. Create single entry per randomization unit\n2. Sort file in reproducible way\n3. Set and preserve random seed\n4. Assign treatments\n5. Save assignments securely\n6. Test balance extensively\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Basic randomization procedure\nset.seed(20250225)  # Always set and record seed\nN <- 1000\ndata <- data.frame(id = 1:N)\ndata$treatment <- sample(c(0,1), N, replace=TRUE, prob=c(0.5,0.5))\ntable(data$treatment)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  0   1 \n496 504 \n```\n\n\n:::\n:::\n\n\n\nAlways document your randomization procedure thoroughly!\n\n## Ethical Considerations\n\n::: {.incremental}\n* **Long-term benefits** vs. short-term resource distribution\n* **Equity** in who receives potentially beneficial treatments\n* **Transparency** with participants about randomization\n* **Minimize harm** from potentially ineffective interventions\n:::\n\n::: {.fragment}\nNo experiment exists in an ethical vacuum!\n:::\n\n## Combining Randomization Approaches\n\n::: {.incremental}\n* Stratify on discrete variables\n* Re-randomize on continuous variables within strata\n* Use matched pairs for important continuous variables\n* Adapt to your specific context and constraints\n:::\n\n::: {.fragment}\nThere is no one-size-fits-all approach!\n:::\n\n## Key Takeaways\n\n::: {.incremental}\n1. Choose randomization unit carefully (individual vs. cluster)\n2. Balance variables that strongly predict outcomes\n3. Use re-randomization, stratification, or matching when feasible\n4. Document your randomization procedure completely\n5. Test balance appropriately for your sample size\n6. Account for your randomization procedure in analysis\n:::\n\n## Which Method When?\n\n| Approach | When to Use | Key Consideration |\n|----------|-------------|-------------------|\n| Simple | Large samples | Simplicity |\n| Stratified | Strong predictors known | Number of strata |\n| Matched-Pair | Small samples | Finding good matches |\n| Re-randomization | Balance is critical | Complexity of inference |\n| Cluster | Group-level intervention | ICC and number of clusters |\n\n## Next Time: Machine Learning for Causal Inference\n\nWe'll explore how modern prediction algorithms can enhance our ability to:\n\n::: {.incremental}\n* Estimate average treatment effects more precisely\n* Discover heterogeneous treatment effects\n* Select optimal treatments for individuals\n:::\n\n## Questions?\n\n![](/unit-2/media/questions.png)",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}