{
  "hash": "5b33d2981717ea2f7273fefd951ccde7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 3: Hypothesis Testing & Sample Size\"\nsubtitle: \"Advanced Quantitative Methods for Health Policy and Management\"\nauthor: \"Sean Sylvia, Ph.D.\"\ndate: \"2025-02-11\"\nformat:\n  revealjs:\n    theme: default\n    slide-number: true\n    html-math-method:\n      method: mathjax\n      packages: [\"amsmath\"]\n    transition: fade\n    progress: true\n    incremental: false\n    toc: false\n    scrollable: false\n    smaller: false\n    footer: \"UNC HPM 883 - Advanced Quantitative Methods\"\n---\n\n\n\n## Analysis Basics\n\n-   Because we designed our experiment properly, analysis is EASY: Just compare the means in the treatment and control groups\n-   Results for intervention giving eyeglasses to primary school students:\n\n| 1\\. Average Test Score in Treatment Group | 2\\. Average Test Score in Control Group | Difference (1-2) |\n|----------------------------|--------------------------|------------------|\n| 75 | 68 | +7 |\n\n## But is this difference statistically significant?\n\n![](CleanShot%202025-04-15%20at%2004.22.07@2x.png)\n\n## We need to do a statistical test\n\n-   Remember from our previous discussions...\n-   What are we testing?\n-   What specifically is our Null Hypothesis for the eyeglasses program?\n\n## Hypothesis Testing\n\n-   In Impact Evaluation, we are interested in testing if the program had an effect\n-   In other words, we want to test a Null Hypothesis that our program had NO effect\n-   If it is not likely that our result was just due to chance/luck (e.g., because of our sample), we \"reject the Null Hypothesis\"\n    -   Usually this means \\<5% probability the result is because of luck\n-   If we reject the Null Hypothesis, this means our program had a \"statistically significant\" impact\n\n## We could do a t-test\n\nFormula for t-statistic:\n\n$$\n\\begin{aligned}\nt &= \\frac{\\bar{x}_t - \\bar{x}_c}{\\sqrt{\\frac{var_t}{n_t} + \\frac{var_c}{n_c}}} \\\\\n&= \\frac{\\overbrace{\\text{Difference between Group Means}}^{\\text{Signal}}}{\\underbrace{SE(\\bar{x}_t - \\bar{x}_c)}_{\\text{Noise}}}\n\\end{aligned}\n$$\n\nAnd see if this is large enough to \"reject the Null\"\n\n## Regression Form of the Test\n\nActually, we can do the SAME test in regression form:\n\nRun the regression:\n\n$$\n\\underbrace{Y_i}_{\\text{Outcome}} = \\underbrace{\\alpha}_{\\text{Constant}} + \\underbrace{\\beta}_{\\text{Effect}} \\underbrace{W_i}_{\\text{Treatment}} + \\underbrace{\\varepsilon_i}_{\\text{Error}}\n$$\n\n-   Here, $\\beta$ will give us the difference between treatment and control and tell us whether it is \"statistically significant\" or not.\n\n-   Our estimate will be unbiased because of random assignment.\n\n## Maximizing Precision\n\nBut remember, we also want to be as precise as possible?\n\n![Precision and Accuracy in Estimation](CleanShot%202025-04-15%20at%2004.22.33@2x.png)\n\nCan we increase precision even after we've run the experiment?\n\n## Using Covariates to Improve Precision\n\nYes! By adding \"covariates\"...\n\nWe can control for other baseline variables in the regression to \"suck up\" extra variation:\n\n$$\nY_i = \\alpha + \\beta W_i + \\gamma \\textcolor{red}{X_i} + \\varepsilon_i\n$$\n\nWhat covariates should we control for?\n\n-   If stratified randomization, add fixed effects for strata (e.g., if we stratify on county, add \"dummy\" variables for each county)\n-   The baseline of the outcome variable\n-   Other covariates strongly related to the outcome\n-   If cluster randomized: cluster level covariates can help a LOT...why?\n\nAlso report \"raw\" differences without covariates for transparency\n\n## Clustering\n\nWe need to be careful with \"clustered\" data\n\nRemember: Students in a school are similar...this makes our regular standard errors too small\n\nThis is easy to deal with: we use \"cluster-robust standard errors\" in the regression\n\nIn R, this is just a command:\n\n\n\n::: {.cell}\n\n:::\n\n\n\n## Assessing & Dealing with Threats\n\nIn the real world, things often don't go perfectly...\n\nWe spoke before about 2 kinds of \"threats\": - Attrition - Imperfect compliance\n\nWhen we analyze our data, we need to: 1. Assess whether these are problems, and see how big the problems are 2. Sometimes we can do things to address them\n\n## Attrition\n\nUsually, there will be some people that leave/cannot be found and are not in the endline survey\n\nThis is a problem if the proportion of \"attriters\" are different in the treatment and control group\n\n-   Why is this a problem?\n-   Why might this happen?\n-   Is it a problem if the rate of attrition is the same across groups, but is high? Say 30-40%?\n\n## Attrition Bias Example\n\nSuppose we were interested in testing the impact of giving students eyeglasses on test scores\n\nConsider these scenarios: - If everyone is in our data in the treatment and control group, what is the result? - How does this change if some people are missing from baseline only? From endline only? - What if under-performing children (e.g., scores \\<50) don't come to school when we give exams?\n\n## Preventing Attrition Problems\n\nBest to try to prevent this problem rather than \"deal with it\"\n\n-   Try to track down people who leave\n-   Can choose a random sample, and devote resources to tracking them down\n\nBut we always need to check after if this is a problem...\n\n## Assessing Attrition\n\nTo see how much of a problem this is in our experiment, we need to do two things:\n\n1.  Is there \"differential\" attrition? Run the regression:\n\n$$\nAttrit_i = \\alpha + \\beta W_i + \\varepsilon_i\n$$\n\n2.  How are those who \"attrit\" different from those who don't?\n\n$$\nAttrit_i = \\alpha + \\gamma X_i + \\varepsilon_i\n$$\n\n## What if I have attrition?\n\nThis is a difficult problem, but there are some things...\n\n\"Bounding Approaches\" can give you a range of effects under best case and worst case - Assume everyone that left got the lowest score...assume everyone that left got the best score...\n\n\\- Example: \"Lee Bounds\"\n\n\\- Often not very efficient\n\n## Imperfect Compliance\n\nAnother potential problem is \"Imperfect Compliance\"...\n\nImperfect compliance: some in the control group get treatment and some in the treatment group do not... - This introduces selection bias\n\nFour types of people:\n\n|                     | What actually happened: |               |\n|---------------------|-------------------------|---------------|\n|                     | Treated                 | Not Treated   |\n| **Treatment Group** | OK                      | Non-compliers |\n| **Control Group**   | Non-compliers           | OK            |\n\nWhat do we do with these non-compliers? Can we just drop/ignore them? NO!!! Why?\n\n## Selection Bias Example: Eyeglasses\n\nSuppose girls are more likely to wear their eyeglasses...\n\n::::: columns\n::: {.column width=\"50%\"}\n**Treatment Group**\n\n| Student | Treatment Group? (Given glasses) | Wore glasses? | Gender | Score |\n|---------------|---------------|---------------|---------------|---------------|\n| Student 1 | Yes | Yes | Girl | 80 |\n| Student 2 | Yes | No | Boy | 70 |\n| Student 3 | Yes | Yes | Girl | 80 |\n| Student 4 | Yes | Yes | Boy | 70 |\n| Student 5 | Yes | Yes | Girl | 80 |\n| Student 6 | Yes | No | Boy | 70 |\n| --------- | ---------------------------------- | --------------- | -------- | --------------- |\n| Full Sample |  |  | 3 girls, 3 boys | 75.0 |\n| --------- | ---------------------------------- | --------------- | -------- | --------------- |\n| Compliers |  |  | 3 girls, 1 boys | 72.5 |\n:::\n\n::: {.column width=\"50%\"}\n**Control Group**\n\n| Student | Treatment Group? (Given glasses) | Wore glasses? | Gender | Score |\n|---------------|---------------|---------------|---------------|---------------|\n| Student 1 | No | No | Boy | 70 |\n| Student 2 | No | No | Boy | 70 |\n| Student 3 | No | Yes | Girl | 80 |\n| Student 4 | No | No | Boy | 70 |\n| Student 5 | No | Yes | Girl | 80 |\n| Student 6 | No | No | Girl | 80 |\n| --------- | ---------------------------------- | --------------- | -------- | --------------- |\n| Full Sample |  |  | 3 girls, 3 boys | 75.0 |\n| --------- | ---------------------------------- | --------------- | -------- | --------------- |\n| Defiers |  |  | 3 girls, 1 boys | 72.5 |\n:::\n:::::\n\nIf we just compare based on who actually wore glasses (\"per-protocol analysis\"), the groups would be imbalanced!\n\n## Intention to Treat (ITT)\n\nWhat do we do?\n\n-   Compare individuals based on their ORIGINAL ASSIGNMENT to treatment or control group\n-   This is called the \"Intention to Treat\" estimate\n-   IGNORE who actually got treated\n\n$$ITT = E[Y_i|W_i = 1] - E[Y_i|W_i = 0]$$\n\n## Treatment on the Treated (TOT)\n\nWe can also estimate the effect of ACTUAL treatment - What would this be in eyeglasses example? - This is called the \"Treatment on the Treated\" (TOT) - The ITT effect may be \"too small\" because of non-compliance - But the proportion treated is also smaller - What can we do?\n\n## Re-scaling the ITT Estimate\n\nWe can \"re-scale\" the ITT estimate\n\nUse the probability of treatment in each group to \"re-scale\" the ITT:\n\n$$TOT = \\frac{E[Y_i|W_i = 1] - E[Y_i|W_i = 0]}{E[T_i|W_i = 1] - E[T_i|W_i = 0]}$$\n\nWhere: - Numerator is the ITT - Denominator is the difference in probability of actually being treated between treatment and control groups\n\n## Eyeglasses Example\n\n|   | Treatment Group (gave eyeglasses) | Control Group (Did not give eyeglasses) |\n|-----------------------------------|------------------|------------------|\n| \\% Actually Got Treatment (Actually wore glasses) | 70% | 10% |\n| E\\[Outcome\\] (Test Scores) | 95 | 82 |\n\n1.  Intention to Treat: 95 - 82 = 13\n\n2.  Treatment On the Treated (IV):\n\n$$\nTOT = \\frac{95-82}{70\\%-10\\%} = \\frac{13}{0.6} = 21.67\n$$\n\n## Assumptions?\n\nWhat are the Assumptions? What do we need for this to work?\n\n::: incremental\nWe need the same assumptions as we do for IV:\n\n1.  Relevance: $E[T_i|W_i = 1] - E[T_i|W_i = 0] \\neq 0$\n2.  Exclusion Restriction: $E[\\varepsilon_i|W_i = 1] = E[\\varepsilon_i|W_i = 0] = 0$\n:::\n\n## Instrumental Variables for TOT\n\nUsing Instrumental Variables to estimate TOT\n\nWe can calculate by hand like above, but: - Not efficient (remember we like to add covariates) - Harder to figure out standard errors for TOT\n\nEasier way: Use Instrumental Variables (IV) 1. \"First Stage\" Regression: $\\hat{T}_i = \\hat{\\alpha}_0 + \\hat{\\alpha}_1 W_i + \\hat{\\alpha}_i X_i$ 2. Predict Probability of Treatment using first stage 3. \"Second Stage\" regression using predicted treatment status: $Y_i = \\beta_0 + \\beta_1 \\hat{T}_i + \\beta_i X_i + \\varepsilon_i$\n\n$\\beta_1$ gives the TOT estimate\n\n## R Implementation\n\nIn R, this is simple:\n\n\n\n::: {.cell}\n\n:::\n\n\n\n## Secondary/Intermediate Outcomes\n\nUntil now, we have talked about just one outcome: Y, the primary outcome\n\nBut, in addition to the primary outcome(s), you should also consider HOW/WHY a program worked to improve the primary outcome or not\n\nTo figure out what other outcomes to consider, you need to lay out your \"Theory of Change\"\n\n## What is Theory of Change?\n\nA Theory of Change (ToC) documents the causal links between inputs, activities, outputs, intermediate and final outcomes, and identifies the underlying assumptions.\n\nAssumptions are what need to be true for the causal chain to operate.\n\n## Theory of Change Framework\n\n![Theory of Change Framework](CleanShot%202025-04-15%20at%2004.42.55@2x.png)\n\n## Theory of Change Example\n\n![Theory of Change Example](CleanShot%202025-04-15%20at%2004.45.13@2x.png)\n\n## Building a Theory of Change\n\nSteps for creating a ToC: 1. Define intervention, objectives, outcomes (even potential unintended ones!) 2. Lay out main steps in causal chain 3. Identify underlying assumptions 4. Add temporal dimension 5. Identify key evaluation questions 6. Validate and revise\n\n## Example: Iron Supplements\n\n:::::: columns\n::: {.column width=\"40%\"}\nVitamins provided to schools to give to children\n:::\n\n::: {.column width=\"20%\"}\n→ ???? → ???? →\n:::\n\n::: {.column width=\"40%\"}\nLearning outcomes improve\n:::\n::::::\n\nLet's develop this Theory of Change together...\n\n## Multiple Outcomes\n\nYou'll see that you often come up with MANY outcomes\n\n-   You can test many outcomes just as you did the primary outcomes\n-   But, this can complicate our statistical analysis...\n\n## Multiple Outcomes Problem\n\nThe problem:\n\nThe more outcomes to test, the higher the chance that at least one is significantly affected by the program just by chance\n\nWhy?\n\nWhat can we do?\n\n## Dealing with Multiple Outcomes\n\nThree ways to deal with multiple outcomes:\n\n1.  Pre-specify the outcomes you will examine, and report all results (even not significant)\n\n2.  Combine the variables into an index\n\n    -   Principal components, GLS Weighting\n    -   Advantage: Powerful\n    -   Disadvantage: You don't really know what the index means\n\n3.  Adjust your p-values for the number of tests\n\n    -   Several approaches...Romano and Wolf (2005) common in economics\n\n## Analysis Review\n\n-   Analysis Basics\n-   Clustering\n-   Assessing & Dealing with Threats\n    -   Attrition\n    -   Imperfect Compliance\n-   Choosing secondary outcomes\n    -   Theory of Change\n-   Multiple outcomes and hypothesis testing",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}