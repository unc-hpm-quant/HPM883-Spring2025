{
  "hash": "025a216d5a599868704e573ef0be9c6d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Power Simulation for a Randomized Experiment\"\nauthor: \"Your Name\"\ndate: \"2025-01-20\"\nformat: html\ndraft: true\n---\n\n\n\n\n\n# Power Simulation for a Randomized Experiment\n\nIn this document, we demonstrate how to conduct a power simulation for a randomized experiment with one treatment and one control group. The goal is to estimate the probability of detecting an effect of a specified size, assuming the effect exists.\n\n------------------------------------------------------------------------\n\n## Step 1: Define Parameters\n\nFirst, specify the parameters for the simulation, including the total sample size, the true effect size, the standard deviation of the outcome, and the significance level.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set seed for reproducibility\nset.seed(123)\n\n# Parameters\nn_total <- 100        # Total sample size\neffect_size <- 5      # True effect size (difference between means)\nsd_outcome <- 10      # Standard deviation of the outcome\nalpha <- 0.05         # Significance level\nn_simulations <- 1000 # Number of simulations\n```\n:::\n\n\n\n------------------------------------------------------------------------\n\n## Step 2: Run Simulations\n\nSimulate the experiment multiple times to estimate power. For each simulation: 1. Randomly assign participants to treatment or control groups. 2. Generate outcomes based on the specified effect size and standard deviation. 3. Perform a t-test. 4. Record whether the null hypothesis is rejected.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Initialize counter for significant results\nsignificant_results <- 0\n\nfor (i in 1:n_simulations) {\n  # Random assignment\n  treatment <- rbinom(n_total, 1, 0.5)\n  \n  # Generate outcomes\n  outcome <- rnorm(n_total, mean = effect_size * treatment, sd = sd_outcome)\n  \n  # Perform t-test\n  test_result <- t.test(outcome ~ treatment)\n  \n  # Check if p-value is less than alpha\n  if (test_result$p.value < alpha) {\n    significant_results <- significant_results + 1\n  }\n}\n\n# Estimate power\nestimated_power <- significant_results / n_simulations\ncat(\"Estimated Power:\", estimated_power, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEstimated Power: 0.696 \n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n## Step 3: Graph of Power vs Effect Size\n\nCreate a graph showing how power changes with varying effect sizes.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\n# Range of effect sizes to evaluate\neffect_sizes <- seq(0, 10, by = 0.5)\n\n# Function to calculate power for a given effect size\ncalculate_power <- function(effect_size, n_total, sd_outcome, alpha, n_simulations) {\n  significant_results <- 0\n  for (i in 1:n_simulations) {\n    treatment <- rbinom(n_total, 1, 0.5)\n    outcome <- rnorm(n_total, mean = effect_size * treatment, sd = sd_outcome)\n    test_result <- t.test(outcome ~ treatment)\n    if (test_result$p.value < alpha) {\n      significant_results <- significant_results + 1\n    }\n  }\n  return(significant_results / n_simulations)\n}\n\n# Calculate power for each effect size\npower_results <- sapply(effect_sizes, calculate_power, \n                        n_total = n_total, sd_outcome = sd_outcome, \n                        alpha = alpha, n_simulations = n_simulations)\n\n# Create a data frame for plotting\npower_data <- data.frame(EffectSize = effect_sizes, Power = power_results)\n\n# Plot the power curve\nggplot(power_data, aes(x = EffectSize, y = Power)) +\n  geom_line() +\n  geom_point() +\n  labs(\n    title = \"Power vs Effect Size\",\n    x = \"Effect Size\",\n    y = \"Power\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](example-powersim_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n## Step 4: Interpret Results\n\nThe `estimated_power` value represents the proportion of simulations in which the null hypothesis was rejected. This provides an estimate of the studys power given the specified parameters.\n\n### Adjustments\n\nIf the estimated power is lower than desired (commonly 0.80), consider: - Increasing the sample size (`n_total`). - Increasing the effect size (`effect_size`). - Reducing the standard deviation of the outcome (`sd_outcome`).\n\n------------------------------------------------------------------------\n\n## Extensions\n\n### 1. Assessing Effects of Noncompliance and Attrition on Power\n\nNoncompliance and attrition are common in real-world experiments and can reduce statistical power. Simulate these factors to assess their impact.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Parameters for noncompliance and attrition\ncompliance_rate <- 0.8  # Proportion of treated participants who comply\nattrition_rate <- 0.1   # Proportion of participants lost to follow-up\n\n# Initialize counter for significant results\nsignificant_results_nc <- 0\n\nfor (i in 1:n_simulations) {\n  # Random assignment\n  treatment <- rbinom(n_total, 1, 0.5)\n\n  # Simulate compliance\n  compliance <- ifelse(treatment == 1, rbinom(n_total, 1, compliance_rate), 0)\n\n  # Simulate attrition\n  retained <- rbinom(n_total, 1, 1 - attrition_rate)\n\n  # Generate outcomes for retained participants\n  outcome <- rnorm(n_total, mean = effect_size * compliance, sd = sd_outcome)\n  outcome <- outcome[retained == 1]\n  treatment <- treatment[retained == 1]\n\n  # Perform t-test\n  test_result <- t.test(outcome ~ treatment)\n\n  # Check if p-value is less than alpha\n  if (test_result$p.value < alpha) {\n    significant_results_nc <- significant_results_nc + 1\n  }\n}\n\n# Estimate power\nestimated_power_nc <- significant_results_nc / n_simulations\ncat(\"Estimated Power with Noncompliance and Attrition:\", estimated_power_nc, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEstimated Power with Noncompliance and Attrition: 0.486 \n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### 2. Power Simulation for Factorial Designs\n\nFactorial designs involve multiple interventions or factors. Simulate power for a 2x2 factorial design.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Parameters for factorial design\nn_total <- 200\nfactor1_effect <- 5\nfactor2_effect <- 3\ninteraction_effect <- 2\n\n# Initialize counter for significant results\nsignificant_results_fd <- 0\n\nfor (i in 1:n_simulations) {\n  # Random assignment to 2x2 design\n  factor1 <- rbinom(n_total, 1, 0.5)\n  factor2 <- rbinom(n_total, 1, 0.5)\n\n  # Generate outcomes\n  outcome <- rnorm(n_total, \n                   mean = factor1_effect * factor1 + \n                          factor2_effect * factor2 + \n                          interaction_effect * factor1 * factor2, \n                   sd = sd_outcome)\n\n  # Fit linear model\n  model <- lm(outcome ~ factor1 * factor2)\n\n  # Check significance of interaction\n  if (summary(model)$coefficients[\"factor1:factor2\", \"Pr(>|t|)\"] < alpha) {\n    significant_results_fd <- significant_results_fd + 1\n  }\n}\n\n# Estimate power\nestimated_power_fd <- significant_results_fd / n_simulations\ncat(\"Estimated Power for Factorial Design:\", estimated_power_fd, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEstimated Power for Factorial Design: 0.105 \n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### 3. Power Simulation for Clustered Randomized Controlled Trials\n\nClustered RCTs involve groups (e.g., schools, clinics) being randomized instead of individuals. Account for intraclass correlation (ICC) in the simulation.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Parameters for clustered design\nn_clusters <- 20     # Number of clusters\ncluster_size <- 10    # Number of individuals per cluster\nicc <- 0.1            # Intraclass correlation coefficient\n\n# Initialize counter for significant results\nsignificant_results_crt <- 0\n\nfor (i in 1:n_simulations) {\n  # Randomize clusters\n  cluster_assignment <- rbinom(n_clusters, 1, 0.5)\n\n  # Generate outcomes with ICC\n  cluster_effects <- rnorm(n_clusters, mean = 0, sd = sqrt(icc * sd_outcome^2))\n  individual_noise <- rnorm(n_clusters * cluster_size, mean = 0, sd = sqrt((1 - icc) * sd_outcome^2))\n  \n  treatment <- rep(cluster_assignment, each = cluster_size)\n  outcome <- effect_size * treatment + rep(cluster_effects, each = cluster_size) + individual_noise\n\n  # Fit linear model accounting for clustering\n  cluster_id <- rep(1:n_clusters, each = cluster_size)\n  model <- lm(outcome ~ treatment + factor(cluster_id))\n\n  # Check if p-value for treatment is significant\n  if (summary(model)$coefficients[\"treatment\", \"Pr(>|t|)\"] < alpha) {\n    significant_results_crt <- significant_results_crt + 1\n  }\n}\n\n# Estimate power\nestimated_power_crt <- significant_results_crt / n_simulations\ncat(\"Estimated Power for Clustered RCT:\", estimated_power_crt, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEstimated Power for Clustered RCT: 0.29 \n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\nFor more detailed examples and explanations, refer to the following resources:\n\n-   [Power Analysis by Data Simulation in R - Part II](https://julianquandt.com/post/power-analysis-by-data-simulation-in-r-part-ii/)\n-   [Simulating the Power of Statistical Tests: A Collection of R Examples](https://arxiv.org/abs/2110.09836)",
    "supporting": [
      "example-powersim_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}