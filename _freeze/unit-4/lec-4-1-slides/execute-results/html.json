{
  "hash": "d4dfe97b52638ecc05d319fc02ff0c4f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 4.1: EstimatingAverage Treatment Effects\"\nauthor: \"Sean Sylvia\"\nformat:\n  revealjs:\n    theme: default\n    slide-number: true\n    chalkboard: true\n    transition: fade\n    progress: true\n    incremental: false\n    toc: false\n    scrollable: false\n    smaller: true\n    footer: \"UNC HPM 883 - Advanced Quantitative Methods\"\ndraft: false\n---\n\n\n\n## Review: The Potential Outcomes Framework\n\n::: incremental\n- For each unit $i$, we define two potential outcomes:\n  - $Y_i(1)$: Outcome if unit receives treatment\n  - $Y_i(0)$: Outcome if unit does not receive treatment\n- The causal effect for unit $i$: $\\delta_i = Y_i(1) - Y_i(0)$\n- **Fundamental problem of causal inference**: We only observe one potential outcome for each unit\n- The observed outcome: $Y_i = Y_i(W_i)$ where $W_i \\in \\{0,1\\}$ is the treatment assignment\n:::\n\n::: fragment\nWe typically focus on the **Average Treatment Effect (ATE)**:\n$$\\tau = E[Y_i(1) - Y_i(0)]$$\n:::\n\n## Why Randomization Works\n\n::: incremental\n- Randomization makes treatment assignment **independent** of potential outcomes:\n  $$W_i \\perp\\!\\!\\!\\perp (Y_i(0), Y_i(1))$$\n- This means treatment and control groups are balanced on observable and unobservable characteristics\n- In expectation:\n  - $E[Y_i(1)|W_i=1] = E[Y_i(1)]$\n  - $E[Y_i(0)|W_i=0] = E[Y_i(0)]$\n- Thus, the difference in observed outcomes provides an unbiased estimate of the ATE\n:::\n\n## The Difference-in-Means Estimator\n\nThe simplest approach to estimate the ATE in an RCT is the difference in means:\n\n$$\\hat{\\tau}_{DM} = \\frac{1}{n_1}\\sum_{i:W_i=1}Y_i - \\frac{1}{n_0}\\sum_{i:W_i=0}Y_i$$\n\n::: incremental\n- $n_1$: Number of treated units\n- $n_0$: Number of control units\n- **Properties**:\n  - Unbiased for the ATE: $E[\\hat{\\tau}_{DM}] = \\tau$\n  - Variance depends on outcome variation\n  - Simple to calculate and understand\n:::\n\n## Room for Improvement\n\nDespite randomization, the difference-in-means estimator has limitations:\n\n::: incremental\n- May have high variance, especially with small samples\n- Does not leverage baseline information\n- Does not account for the design of the experiment (e.g., stratification)\n- Subject to chance imbalances between treatment and control\n:::\n\n::: fragment\n**Key Question**: How can we improve precision while maintaining unbiasedness?\n:::\n\n## Lecture Roadmap\n\nToday we'll explore three approaches to estimating the ATE:\n\n::: incremental\n1. **Standard Regression Approach**\n   - Controlling for baseline covariates in RCTs\n   - ANCOVA specification\n\n2. **Post-Double Selection Lasso**\n   - A principled approach to covariate selection\n   - Balancing precision and researcher degrees of freedom\n\n3. **Machine Learning Approaches**\n   - Using flexible methods to model treatment effects\n   - Addressing non-linearities in outcome relationships\n:::\n\n## Standard Approach to ATE Estimation in RCTs\n\n$$Y_{it} = \\alpha + \\theta T_i + \\beta Y_{i(t-1)} + \\sum\\beta_i X_i + \\sum\\delta_s + \\varepsilon_i$$\n\n::: incremental\n- The equation above represents the canonical specification for ATE estimation in RCTs\n- **Parameters of interest:**\n  - $Y_{it}$: Outcome variable for unit $i$ at follow-up time $t$\n  - $T_i$: Treatment indicator (1 = treated, 0 = control)\n  - $\\theta$: Average treatment effect (our target)\n  - $Y_{i(t-1)}$: Baseline value of the outcome\n  - $X_i$: Vector of baseline covariates\n  - $\\delta_s$: Strata fixed effects\n:::\n\n## Basic Specification: No Controls\n\n$$Y_{it} = \\alpha + \\theta T_i + \\varepsilon_i$$\n\n::: incremental\n- Simplest specification: regress outcome on treatment indicator only\n- Valid in expectation due to randomization\n- $\\theta$ is unbiased estimate of the ATE\n- **Critical note on inference:**\n  - Use robust standard errors to account for heteroskedasticity\n  - If clustered randomization, use cluster-robust standard errors\n  - $SE(\\hat{\\theta})_{robust} = \\sqrt{\\frac{\\hat{\\sigma}^2_1}{n_1} + \\frac{\\hat{\\sigma}^2_0}{n_0}}$\n- Often leaves substantial unexplained variation in the outcome\n:::\n\n::: fragment\nThis approach is equivalent to a simple difference in means between treatment and control groups.\n:::\n\n## Adding Strata Fixed Effects\n\n$$Y_{it} = \\alpha + \\theta T_i + \\sum\\delta_s + \\varepsilon_i$$\n\n::: incremental\n- When randomization is stratified, include fixed effects for each stratum\n- $\\sum\\delta_s$ represents indicator variables for each randomization stratum\n- **Benefits:**\n  - Accounts for the design of the experiment\n  - Improves precision by removing between-strata variation\n  - Ensures valid inference (failure to include can lead to incorrect standard errors)\n- **Implementation:**\n  - Include dummy variables for all but one stratum\n  - Or use factor variables in statistical software (e.g., in R: `factor(stratum)`)\n:::\n\n## Adding Baseline Controls\n\n$$Y_{it} = \\alpha + \\theta T_i + \\beta Y_{i(t-1)} + \\sum\\beta_i X_i + \\sum\\delta_s + \\varepsilon_i$$\n\n::: incremental\n- **Baseline outcome** ($Y_{i(t-1)}$):\n  - Usually provides largest precision gain\n  - Flexibly controls for autocorrelation\n  - Preferable to \"difference-in-differences\" in most RCTs\n  - Coefficient $\\beta$ need not equal 1 (unlike DiD)\n\n- **Additional covariates** ($X_i$):\n  - Must be measured pre-treatment\n  - Should predict residual variation in outcome\n  - Balance checks not necessary to justify inclusion\n  - Helps account for chance imbalances\n:::\n\n::: fragment\nThis approach (ANCOVA) is the gold standard for most RCTs with baseline data.\n:::\n\n## Considerations on Including Covariate Controls\n\n$$Y_{it} = \\alpha + \\theta T_i + \\beta Y_{i(t-1)} + \\sum\\beta_i X_i + \\sum\\delta_s + \\varepsilon_i$$\n\n::::: columns\n::: {.column width=\"50%\"}\n**Research Design Considerations:**\n- Pre-specify controls in analysis plan\n- Avoid \"fishing\" for significant results\n- Balance precision gains against complexity\n- Guard against researcher degrees of freedom\n:::\n\n::: {.column width=\"50%\"}\n**The Selection Problem:**\n- Which covariates should we include?\n- How many covariates are too many?\n- How do we handle many potential controls?\n- Can we automate control selection?\n:::\n:::::\n\n::: fragment\nThis is where Post-Double Selection Lasso can provide a principled solution.\n:::\n\n## PDS Lasso in Field Experiments\n\n**Post-Double Selection Lasso for Randomized Trials**\n\n::: incremental\n- **PDS Lasso**: A principled approach to selecting control variables in field experiments\n- Addresses the key question: *Which covariates should we include in our regression?*\n- Helps balance competing concerns:\n  - Including relevant controls improves precision\n  - Ad hoc selection creates researcher degrees of freedom (p-hacking concerns)\n  - Too many controls reduces power in small samples\n- Provides a data-driven alternative to traditional ANCOVA approaches\n- Originally developed for observational studies but increasingly applied to RCTs\n:::\n\n::: fragment\n**Key Question**: In a randomized experiment, why use a method designed for observational studies?\n:::\n\n## The PDS Lasso Method\n\n::::: columns\n::: {.column width=\"60%\"}\n**Three-Step Procedure:**\n\n1. **Step 1**: Use Lasso to select controls that predict the outcome\n   - Regress Y on covariates X (excluding treatment)\n   - Lasso penalty shrinks coefficients toward zero\n   - Set of selected variables: I₁\n\n2. **Step 2**: Use Lasso to select controls that predict treatment \n   - Regress T on covariates X\n   - Set of selected variables: I₂\n\n3. **Step 3**: Estimate treatment effect by OLS\n   - Regress Y on T and all selected controls (I = I₁ ∪ I₂)\n   - Optional \"amelioration set\" (I₃) of variables always included\n:::\n\n::: {.column width=\"40%\"}\n\n\n```{mermaid}\nflowchart TD\n    A[Potential Controls X] --> B[\"Lasso Step 1: <br> Predict Outcome\"]\n    A --> C[\"Lasso Step 2: <br> Predict Treatment\"]\n    B --> D[Selected Controls I₁]\n    C --> E[Selected Controls I₂]\n    D --> F[Union of Controls <br> I₁ ∪ I₂ ∪ I₃]\n    E --> F\n    G[Amelioration Set I₃] --> F\n    F --> H[Final OLS Regression <br> Y ~ T + Selected Controls]\n```\n\n\n:::\n:::::\n\n## Why Double Selection in RCTs?\n\n::::: columns\n::: {.column width=\"50%\"}\n**The Theoretical Paradox:**\n- In perfectly randomized experiments, treatment is orthogonal to all covariates\n- So why model treatment prediction at all?\n\n**Practical Justifications:**\n- Small sample sizes lead to chance imbalances\n- Attrition creates non-random final analysis samples\n- Field experiments often have both issues (average 15% attrition)\n:::\n\n::: {.column width=\"50%\"}\n**Key Insight**:\n\nLasso in Step 1 may miss variables with:\n- Moderate associations with outcomes (due to regularization)\n- Strong correlations with treatment\n\nStep 2 provides a \"second chance\" to capture these important variables, enhancing robustness against:\n- Chance imbalances\n- Selective attrition\n\nParticularly valuable when variables have moderate outcome correlations but strong treatment imbalances\n:::\n:::::\n\n## PDS Lasso in Practice\n\n::::: columns\n::: {.column width=\"60%\"}\n**Empirical Findings from 780 Treatment Estimates:**\n\n- Despite many potential controls (median 182), PDS Lasso selects few (median 2)\n- Step 1 (outcome prediction): Selects at least one variable in 71% of cases\n- Step 2 (treatment prediction): Selects no variables in 57% of cases\n- Almost no overlap between variables selected in Steps 1 and 2\n- **Impact relative to ANCOVA**:\n  - Very minimal changes in treatment estimates (median 0.01 SD)\n  - Slight reduction in standard errors (median ratio 0.992)\n  - Yields larger standard errors in about 25% of cases\n  - Implied MDE reduction: only 0.9% at median\n:::\n\n::: {.column width=\"40%\"}\n![Distribution of Selected Variables](media/pds_selected_vars.png)\n\n*Key finding: PDS Lasso offers limited precision gains compared to standard ANCOVA approaches in most field experiments*\n:::\n:::::\n\n## Implementation Considerations\n\n**Key Decisions When Using PDS Lasso:**\n\n::::: columns\n::: {.column width=\"50%\"}\n**Penalty Parameter λ:**\n- Controls degree of variable selection\n- **Default \"plug-in\" λ**: Increases with covariates and sample size\n  - Theoretically justified for causal inference\n  - Tends to select few variables\n- **Cross-validation**: Select λ to minimize prediction error\n  - Selects many more variables (often 5-7x more)\n  - Can be unstable and risks overfitting\n  - Limited theoretical justification for causal inference\n:::\n\n::: {.column width=\"50%\"}\n**Input Variable Selection:**\n- \"Kitchen sink\" approach common but problematic\n  - Penalty increases with number of potential controls\n  - Too many variables can lead to none being selected\n- **Amelioration Set (I₃):**\n  - Variables always included regardless of selection\n  - Recommended inclusions:\n    - Lagged dependent variable\n    - Randomization strata fixed effects\n  - Guards against underselection of important variables\n:::\n:::::\n\n## Best Practices for PDS Lasso\n\n**Checklist for Effective Implementation:**\n\n::: incremental\n1. **Be realistic about power gains**\n   - Expect very small reductions in standard errors compared to ANCOVA\n   - Don't rely on large improvements for power calculations\n\n2. **Include key variables in amelioration set**\n   - Lagged dependent variable\n   - Randomization strata or matched pair fixed effects\n\n3. **Be judicious with input controls**\n   - Avoid \"kitchen sink\" approach with hundreds of variables\n   - Focus on variables with potential outcome correlation\n\n4. **Handle missing values carefully**\n   - Ensure all input controls have no missing values (e.g., by dummying out)\n   - Missing values reduced final samples in many studies\n\n5. **Use as a robustness check**\n   - Provides a principled alternative to ad hoc control selection\n   - Large coefficient changes may signal concerns about randomization\n:::\n\n## The Modern Machine Learning Approach\n\nLet's now explore more flexible methods for estimating the ATE with covariates.\n\n## Covariates and Unconfoundedness\n\nFor a set of i.i.d. subjects i = 1, ..., n, we observe a tuple (X_i, Y_i, W_i), comprised of:\n\n- A feature vector X_i ∈ ℝᵖ\n- A response Y_i ∈ ℝ\n- A treatment assignment W_i ∈ {0, 1}\n\nWith potential outcomes Y_i(0) and Y_i(1) such that Y_i = Y_i(W_i).\n\n::: fragment\nControlling for X_i is sufficient for identifying average treatment effects if W_i is as good as random once we condition on X_i:\n\n$$[{Y_i(0), Y_i(1)} \\perp\\!\\!\\!\\perp W_i] \\mid X_i$$\n\nThis assumption is commonly referred to as **unconfoundedness** or **selection on observables**.\n:::\n\n## Regression Adjustments Under Unconfoundedness\n\nGiven unconfoundedness $[{Y_i(0), Y_i(1)} \\perp\\!\\!\\!\\perp W_i] \\mid X_i$, we can express the ATE in terms of conditional response surfaces:\n\n$$\n\\begin{align}\n\\tau &= E[Y_i(1) - Y_i(0)]\\\\\n&= E[E[Y_i(1) \\mid X_i] - E[Y_i(0) \\mid X_i]]\\\\\n&= E[E[Y_i \\mid X_i, W_i = 1] - E[Y_i \\mid X_i, W_i = 0]]\\\\\n&= E[\\mu^{(1)}(X_i) - \\mu^{(0)}(X_i)]\n\\end{align}\n$$\n\nWhere $\\mu^{(w)}(x) = E[Y_i \\mid X_i = x, W_i = w]$\n\n## Estimation Strategy\n\nGiven unconfoundedness, we know that:\n\n$$\\tau = E[\\mu^{(1)}(X_i) - \\mu^{(0)}(X_i)]$$\n\nThis suggests a three-step estimation strategy:\n\n::: incremental\n1. Learn $\\hat{\\mu}^{(0)}(x)$ by predicting Y from X on controls\n2. Learn $\\hat{\\mu}^{(1)}(x)$ by predicting Y from X on treated units\n3. Estimate $\\hat{\\tau} = \\frac{1}{n}\\sum_{i=1}^{n}[\\hat{\\mu}^{(1)}(X_i) - \\hat{\\mu}^{(0)}(X_i)]$\n:::\n\n::: fragment\nThis is \"obviously\" consistent if $\\hat{\\mu}^{(w)}(x)$ is consistent for $\\mu^{(w)}(x)$. But is this any good?\n:::\n\n## The Classical Approach: OLS\n\nA classical approach to the ATE involves estimating $\\mu^{(0)}(x)$ and $\\mu^{(1)}(x)$ via ordinary least-squares regression (OLS).\n\n::: incremental\n- First posit a linear model, $\\mu^{(w)}(x) = x\\beta^{(w)}$\n- Fit the model separately for each treatment group:\n  - $\\hat{\\beta}^{(0)} \\leftarrow$ lm(Y_i ~ X_i, subset W_i = 0)\n  - $\\hat{\\beta}^{(1)} \\leftarrow$ lm(Y_i ~ X_i, subset W_i = 1)\n- Make predictions $\\hat{\\mu}^{(w)}(x) = x\\hat{\\beta}^{(w)}$\n- Compute the ATE estimate: $\\hat{\\tau} = \\frac{1}{n}\\sum_{i=1}^{n}[\\hat{\\mu}^{(1)}(X_i) - \\hat{\\mu}^{(0)}(X_i)]$\n:::\n\n::: fragment\nNote that the ATE estimate simplifies to $\\hat{\\tau} = (\\hat{\\beta}^{(1)} - \\hat{\\beta}^{(0)})'\\bar{X}$, where $\\bar{X} = \\frac{1}{n}\\sum_{i=1}^{n}X_i$\n:::\n\n## OLS Implementation Example\n\n\n\n::: {.cell}\n\n:::\n\n\n\n## The Machine Learning Approach\n\nA modern, non-parametric approach seeks to avoid making assumptions about the functional form of $\\mu^{(0)}(x)$ and $\\mu^{(1)}(x)$.\n\n::: incremental\n- Pick your favorite machine learning method\n- Use it to predict Y_i from X_i separately for treated and control groups\n- Use these predictions as estimates for $\\mu^{(0)}(x)$ and $\\mu^{(1)}(x)$\n- Estimate $\\hat{\\tau} = \\frac{1}{n}\\sum_{i=1}^{n}[\\hat{\\mu}^{(1)}(X_i) - \\hat{\\mu}^{(0)}(X_i)]$\n:::\n\n::: fragment\nIn many settings, machine learning methods enable accurate prediction without needing to model the shape of $\\mu^{(0)}(x)$ and $\\mu^{(1)}(x)$.\n:::\n\n## Random Forest Implementation Example\n\n\n\n::: {.cell}\n\n:::\n\n\n\n## A Simulation Comparison\n\nLet's compare OLS and Random Forests in two settings:\n\n::::: columns\n::: {.column width=\"50%\"}\n**Linear Setting**:\n- X ~ N(0, I_{20×20})\n- P[W=1|X] = 1/(1+e^{X₁})\n- Y(0) = X₁ + X₂ + N(0, 4)\n- Y(1) = X₁ + X₃ + N(0, 4)\n- True ATE = 0\n:::\n\n::: {.column width=\"50%\"}\n**Non-linear Setting**:\n- X ~ N(0, I_{20×20})\n- P[W=1|X] = (1+sin(X₁))/2\n- Y(0) = 4·1({X₁ > 0}) + X₂²/2 + N(0, 4)\n- Y(1) = 4·1({X₁ > 0}) + X₃²/2 + N(0, 4)\n- True ATE = 0\n:::\n:::::\n\n## Linear Regression vs Random Forests\n\n::::: columns\n::: {.column width=\"50%\"}\n**Linear Regression (OLS)** bets everything on $\\hat{\\mu}^{(w)}(x)$ being linear:\n\n- If this assumption is valid, everything works perfectly\n- Parametric reasoning applies\n- No need to worry\n- If this assumption fails, everything is wrong\n- Not much subtlety in how to do inference\n:::\n\n::: {.column width=\"50%\"}\n**Machine Learning Methods** seek to fit potentially complicated functions $\\hat{\\mu}^{(w)}(x)$:\n\n- Never completely wrong: expect consistency as n → ∞\n- But even when a simple model is correct, converge slowly\n- Possible to extract useful insights\n- Must be robust to suboptimal finite sample performance\n:::\n:::::\n\n## Key Takeaways\n\n::: incremental\n1. **Regression adjustment improves precision**\n   - In randomized trials, it's not needed for unbiasedness but helps with efficiency\n   - The baseline outcome is typically the most important control\n\n2. **Standard ANCOVA is a robust approach**\n   - Pre-specify key controls (baseline outcome, strata)\n   - Works well in most field experiments\n\n3. **PDS Lasso provides a principled control selection method**\n   - But offers limited gains over ANCOVA in most cases\n   - Include key variables in the amelioration set\n\n4. **Machine learning methods can help with non-linear relationships**\n   - But may not offer large gains in typical field experiment settings\n   - Require careful implementation to maintain valid inference\n:::\n\n## Next Steps\n\nAdvanced methods that build on these approaches:\n\n::: incremental\n- **Double/Debiased Machine Learning**\n  - Combining machine learning with robust inference\n\n- **Causal Forests**\n  - Estimating heterogeneous treatment effects\n\n- **Doubly Robust Estimation**\n  - Protecting against model misspecification\n\n- **Experimental Design Considerations**\n  - Optimal sample allocation\n  - Stratification and blocking\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}