<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Sean Sylvia, Ph.D.">
<meta name="dcterms.date" content="2025-02-05">
<title>Unit 1-2: Statistical Conclusion Validity – HPM 883</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dece3bd051e391dd7205a6b15f93dc59.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-dece3bd051e391dd7205a6b15f93dc59.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-fd9528830c3bd10aadebefd30ea787ae.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-135ac4d113b30199e54d7437fe66c954.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Unit 1-2: Statistical Conclusion Validity</li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto"><div class="pt-lg-2 mt-2 text-center sidebar-header">
      <a href="../index.html" class="sidebar-logo-link">
      <img src="../images/logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none"></a>
      <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/hpm883" title="GitHub" class="quarto-navigation-tool px-1" aria-label="GitHub"><i class="bi bi-github"></i></a>
    <a href="https://rstudio.cloud/" title="Rstudio Cloud" class="quarto-navigation-tool px-1" aria-label="Rstudio Cloud"><i class="bi bi-code-square"></i></a>
    <div class="dropdown">
      <a href="" title="Support" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Support"><i class="bi bi-life-preserver"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
<li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://placeholder.link/office-hours">
              <i class="bi bi-person-raised-hand pe-1"></i>
            Office hours
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://placeholder.link/help-humans">
              <i class="bi bi-people-fill pe-1"></i>
            Help from humans
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://placeholder.link/chatbot">
              <i class="bi bi-robot pe-1"></i>
            Help from AI (Chatbot)
            </a>
          </li>
      </ul>
</div>
    <a href="https://hpm883.slack.com" title="Slack" class="quarto-navigation-tool px-1" aria-label="Slack"><i class="bi bi-slack"></i></a>
    <div class="dropdown">
      <a href="" title="Canvas" id="quarto-navigation-tool-dropdown-1" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Canvas"><i class="bi bi-file-check-fill"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-1">
<li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://placeholder.link/announcements">
              <i class="bi bi-megaphone-fill pe-1"></i>
            Announcements
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://placeholder.link/gradescope">
              <i class="bi bi-file-arrow-up-fill pe-1"></i>
            Gradescope
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://placeholder.link/gradebook">
              <i class="bi bi-alphabet-uppercase pe-1"></i>
            Gradebook
            </a>
          </li>
      </ul>
</div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course Schedule</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Course Information</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course-overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course-syllabus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Syllabus</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../instructors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Instructors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../course-communication.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Communication</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Semester Project</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../project.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project Description</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ex-simulate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Simulation Example</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Resources</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../computing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Computing</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Unit 0: Foundations</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../unit-0/unit-0-foundations-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 0.0: Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../unit-0/unit-0-foundations-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 0.1: A Field Experiment in Health Services Research</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../unit-0/unit-0-foundations-3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 0.2: Computing for Reproducible Research</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Unit 1: Internal Validity</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../unit-1/unit-1-internal-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 1.0: Internal Validity</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../labs/lab-1-InternalValidityPO.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 1: The Hospital of Uncertain Outcomes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../unit-1/unit-1-internal-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 1.1: Statistical Conclusion Validity</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../labs/lab-2-Power.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 2: Power by Simulation</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Unit 2: Design of Experiments</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../unit-2/unit-2-design-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Unit 2.0: Optimal Experimental Design</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../unit-2/unit-2-design-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">How to Randomize</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">On this page</h2>
   
  <ul class="collapse">
<li><a href="#summary" id="toc-summary" class="nav-link active" data-scroll-target="#summary">Summary</a></li>
  <li><a href="#learning-objectives" id="toc-learning-objectives" class="nav-link" data-scroll-target="#learning-objectives">Learning Objectives</a></li>
  <li>
<a href="#uncertainty-and-statistical-conclusion-validity" id="toc-uncertainty-and-statistical-conclusion-validity" class="nav-link" data-scroll-target="#uncertainty-and-statistical-conclusion-validity">Uncertainty and Statistical Conclusion Validity</a>
  <ul class="collapse">
<li><a href="#what-is-uncertainty" id="toc-what-is-uncertainty" class="nav-link" data-scroll-target="#what-is-uncertainty">What is Uncertainty?</a></li>
  <li><a href="#where-does-uncertainty-come-from-in-an-experimental-study" id="toc-where-does-uncertainty-come-from-in-an-experimental-study" class="nav-link" data-scroll-target="#where-does-uncertainty-come-from-in-an-experimental-study">Where Does Uncertainty Come From in an Experimental Study?</a></li>
  <li><a href="#statistical-conclusion-validity" id="toc-statistical-conclusion-validity" class="nav-link" data-scroll-target="#statistical-conclusion-validity">Statistical Conclusion Validity</a></li>
  </ul>
</li>
  <li>
<a href="#sampling-frameworks-understanding-the-foundations-of-estimation-in-experiments" id="toc-sampling-frameworks-understanding-the-foundations-of-estimation-in-experiments" class="nav-link" data-scroll-target="#sampling-frameworks-understanding-the-foundations-of-estimation-in-experiments"><strong>Sampling Frameworks: Understanding the Foundations of Estimation in Experiments</strong></a>
  <ul class="collapse">
<li><a href="#the-super-population-approach" id="toc-the-super-population-approach" class="nav-link" data-scroll-target="#the-super-population-approach"><strong>The Super-Population Approach</strong></a></li>
  <li><a href="#the-finite-population-approach" id="toc-the-finite-population-approach" class="nav-link" data-scroll-target="#the-finite-population-approach"><strong>The Finite-Population Approach</strong></a></li>
  <li><a href="#subpopulations-in-the-super-population-framework" id="toc-subpopulations-in-the-super-population-framework" class="nav-link" data-scroll-target="#subpopulations-in-the-super-population-framework"><strong>Subpopulations in the Super-Population Framework</strong></a></li>
  <li><a href="#choosing-between-the-two-approaches" id="toc-choosing-between-the-two-approaches" class="nav-link" data-scroll-target="#choosing-between-the-two-approaches"><strong>Choosing Between the Two Approaches</strong></a></li>
  </ul>
</li>
  <li>
<a href="#single-hypothesis-testing-and-statistical-power" id="toc-single-hypothesis-testing-and-statistical-power" class="nav-link" data-scroll-target="#single-hypothesis-testing-and-statistical-power">Single Hypothesis Testing and Statistical Power</a>
  <ul class="collapse">
<li><a href="#statistical-significance-and-the-t-statistic" id="toc-statistical-significance-and-the-t-statistic" class="nav-link" data-scroll-target="#statistical-significance-and-the-t-statistic">Statistical Significance and the t-Statistic</a></li>
  <li><a href="#type-i-and-type-ii-errors" id="toc-type-i-and-type-ii-errors" class="nav-link" data-scroll-target="#type-i-and-type-ii-errors">Type I and Type II Errors</a></li>
  <li><a href="#power-calculation-ensuring-detectability" id="toc-power-calculation-ensuring-detectability" class="nav-link" data-scroll-target="#power-calculation-ensuring-detectability">Power Calculation: Ensuring Detectability</a></li>
  </ul>
</li>
  <li>
<a href="#simulations-in-research-design" id="toc-simulations-in-research-design" class="nav-link" data-scroll-target="#simulations-in-research-design">Simulations in Research Design</a>
  <ul class="collapse">
<li><a href="#the-mida-framework-for-simulation" id="toc-the-mida-framework-for-simulation" class="nav-link" data-scroll-target="#the-mida-framework-for-simulation">The MIDA Framework for Simulation</a></li>
  <li><a href="#diagnosing-research-designs-with-simulation" id="toc-diagnosing-research-designs-with-simulation" class="nav-link" data-scroll-target="#diagnosing-research-designs-with-simulation">Diagnosing Research Designs with Simulation</a></li>
  </ul>
</li>
  <li>
<a href="#multiple-hypothesis-testing" id="toc-multiple-hypothesis-testing" class="nav-link" data-scroll-target="#multiple-hypothesis-testing">Multiple Hypothesis Testing</a>
  <ul class="collapse">
<li><a href="#the-challenge-of-multiple-hypothesis-testing" id="toc-the-challenge-of-multiple-hypothesis-testing" class="nav-link" data-scroll-target="#the-challenge-of-multiple-hypothesis-testing">The Challenge of Multiple Hypothesis Testing</a></li>
  <li><a href="#types-of-multiple-hypothesis-tests" id="toc-types-of-multiple-hypothesis-tests" class="nav-link" data-scroll-target="#types-of-multiple-hypothesis-tests">Types of Multiple Hypothesis Tests</a></li>
  <li><a href="#controlling-the-family-wise-error-rate-fwer" id="toc-controlling-the-family-wise-error-rate-fwer" class="nav-link" data-scroll-target="#controlling-the-family-wise-error-rate-fwer">Controlling the Family-Wise Error Rate (FWER)</a></li>
  <li><a href="#approaches-to-controlling-the-fwer" id="toc-approaches-to-controlling-the-fwer" class="nav-link" data-scroll-target="#approaches-to-controlling-the-fwer">Approaches to Controlling the FWER</a></li>
  <li><a href="#simulating-multiple-hypothesis-testing-in-r" id="toc-simulating-multiple-hypothesis-testing-in-r" class="nav-link" data-scroll-target="#simulating-multiple-hypothesis-testing-in-r">Simulating Multiple Hypothesis Testing in R</a></li>
  </ul>
</li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul><div class="toc-actions"><ul class="collapse"><li><a href="https://github.com/hpm883/edit/main/unit-1/lec-1-2.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/hpm883/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Unit 1-2: Statistical Conclusion Validity</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
<p class="subtitle lead">Lecture Notes</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Sean Sylvia, Ph.D. </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 5, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header><section id="summary" class="level1"><h1>Summary</h1>
<p>This lecture delves into statistical conclusion validity, exploring how we can assess the reliability and accuracy of estimated treatment effects in experimental research. As we have seen, due to the fundamental nature of potential outcomes, it is inherently impossible to recover individual treatment effects since each unit reveals only one potential outcome. However, under specific assumptions and with an appropriate assignment mechanism—such as random assignment—we can consistently estimate an average treatment effect (ATE). This lecture provides a brief, selective statistical background on how to estimate the ATE and quantify the uncertainty in these estimates, ensuring statistical conclusion validity. To streamline the presentation, we focus on settings with a binary treatment and largely ignore the role of covariates.</p>
</section><section id="learning-objectives" class="level1"><h1>Learning Objectives</h1>
<ol type="1">
<li>Explain the concept of statistical conclusion validity and its importance in ensuring that the estimated treatment effect reflects the true effect.</li>
<li>Identify the key sources of uncertainty in experimental studies, including sampling variation, variance in potential outcomes, and measurement error.</li>
<li>Review the principles of hypothesis testing, including the formulation of null and alternative hypotheses and the implications of Type I and Type II errors.</li>
<li>Explore the role of statistical power in determining the sample size needed to detect significant effects.</li>
<li>Explore the use of simulation techniques to conduct power calculations and assess the reliability of experimental designs.</li>
<li>Explore the role of multiple hypothesis testing and its implications in statistical inference.</li>
</ol></section><section id="uncertainty-and-statistical-conclusion-validity" class="level1"><h1>Uncertainty and Statistical Conclusion Validity</h1>
<section id="what-is-uncertainty" class="level2"><h2 class="anchored" data-anchor-id="what-is-uncertainty">What is Uncertainty?</h2>
<p>Uncertainty in empirical research refers to the inherent imprecision that arises when we attempt to infer quantities that cannot be directly observed. Whether we are engaged in descriptive, causal, or generalization inference, our estimates come with uncertainty that must be quantified and communicated.</p>
<p>Two primary frameworks exist for this purpose: the Bayesian and the frequentist approaches.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<section id="bayesian-approach" class="level3"><h3 class="anchored" data-anchor-id="bayesian-approach">Bayesian Approach</h3>
<p>The Bayesian framework uses Bayes’ rule to combine prior beliefs with the observed data, resulting in a posterior probability distribution over the parameter of interest, <span class="math inline">\(\theta\)</span>. Mathematically, this is expressed as:</p>
<p><span class="math display">\[
\Pr(\theta = \theta' \mid d = d') = \frac{\Pr(d = d' \mid \theta = \theta')\, \Pr(\theta = \theta')}{\sum_{\theta''} \Pr(d = d' \mid \theta = \theta'')\, \Pr(\theta = \theta'')},
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(d\)</span> represents data, and <span class="math inline">\(d'\)</span> represents the observed data (or an “observed realization of the data”)</p></li>
<li><p><span class="math inline">\(\theta'\)</span> and <span class="math inline">\(\theta''\)</span> represent particular values of the parameter <span class="math inline">\(\theta\)</span>.</p></li>
</ul>
<p>From this posterior distribution, the <strong>posterior mean</strong> serves as our best estimate of <span class="math inline">\(\theta\)</span>, and the <strong>posterior variance</strong> quantifies the uncertainty associated with that estimate.</p>
<p>By applying Bayes’ rule over different values of <span class="math inline">\(\theta\)</span>, we construct a complete probability distribution that represents all possible answers. This posterior distribution simultaneously provides our best estimate—often summarized by the posterior mean—and quantifies our uncertainty via the posterior variance.</p>
<p>While intuitive, a challenge is that specifying prior uncertainty (<span class="math inline">\(\Pr(\theta = \theta')\)</span>) is often a subjective choice, and the posterior distribution is often difficult to interpret and communicate.</p>
</section><section id="frequentist-approach" class="level3"><h3 class="anchored" data-anchor-id="frequentist-approach">Frequentist Approach</h3>
<p>In contrast, the frequentist approach avoids specifying prior beliefs and focuses on the likelihood function, <span class="math inline">\(\Pr(d = d' \mid \theta = \theta')\)</span>, which describes the probability of observing the data <span class="math inline">\(d'\)</span> given a specific value of <span class="math inline">\(\theta\)</span>.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> I.e. instead of thinking of the strength of beliefs, we consider that <span class="math inline">\(\theta\)</span> generates the actual probability distriubtion over possible data <span class="math inline">\(d\)</span>.</p>
<p>This approach yields useful quantities:</p>
<p><strong>P-value</strong>: The p-value for a null hypothesis, <span class="math inline">\(\theta = \theta_0\)</span>, is defined as the probability of observing data as extreme as <span class="math inline">\(d_{m*}\)</span> under the null hypothesis, or</p>
<p><span class="math display">\[
\Pr(d = d_{m*} \mid \theta = \theta_0).
\]</span></p>
<p>where <span class="math inline">\(d_{m*}\)</span> is the test statistic.</p>
<p><strong>Confidence Interval</strong>: A 95% confidence interval is constructed such that, if the experiment were repeated many times, 95% of the intervals would contain the true parameter value. This approach provides a framework to rule out parameter values that are inconsistent with the observed data, or <span class="math inline">\(Pr(d = d' \mid \theta = \theta') \leq 0.05\)</span>.</p>
</section></section><section id="where-does-uncertainty-come-from-in-an-experimental-study" class="level2"><h2 class="anchored" data-anchor-id="where-does-uncertainty-come-from-in-an-experimental-study">Where Does Uncertainty Come From in an Experimental Study?</h2>
<p>Before getting into estimation and the uncertainty of the estimate, we need to be precise about the source of uncertainty. In experimental studies, uncertainty is an inherent part of the inference process, arising from several key sources. Recognizing these sources is critical to designing robust experiments and correctly interpreting the results. The main contributors to uncertainty include:</p>
<ul>
<li><p><strong>Sampling Variation:</strong><br>
Uncertainty due to sampling variation stems from the fact that any sample drawn from a population is just one of many possible samples. Consequently, the same treatment might yield different results if applied to a different sample, reflecting random fluctuations in the selection process.</p></li>
<li><p><strong>Variance in Potential Outcomes:</strong><br>
The natural variability in the potential outcomes (i.e., the outcomes that would be observed under different treatment conditions) can lead to uncertainty. High variance makes it more challenging to detect a true treatment effect because the noise in the data can obscure the signal, thereby reducing the study’s power to reject a false null hypothesis.</p></li>
<li><p><strong>Measurement Error:</strong><br>
Measurement error occurs when there are inaccuracies in recording or assessing the potential outcomes. Such errors introduce additional variability and can bias the estimated treatment effect, further contributing to uncertainty in the experimental results.</p></li>
</ul>
<p>To vizualize this, the diagram below shows a “directed acyclic graph” (DAG) representation of the “data strategy” framework discussed in <a href="https://book.declaredesign.org/declaration-diagnosis-redesign/crafting-data-strategy.html">Chapter 8 of Research Design in the Social Sciences</a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="../unit-1/media/figure-8-1.svg" class="img-fluid figure-img"></p>
<figcaption>Data Strategy DAG, Source: Research Design in the Social Sciences</figcaption></figure>
</div>
<blockquote class="blockquote">
<p>In Figure 8.1, we illustrate these three elements of data strategies: sampling (S), treatment assignment (Z), and measurement (Q). These nodes are highlighted by blue boxes to emphasize that they are in the control of the researcher. No arrows go into the S, Z, or Q nodes; they are set by the researcher. In each case, the strategy selected by the researcher affects a corresponding endogenous variable. The sampling procedure causes changes in the endogenous response (R), which represents whether participants provide outcome data, for example responding to survey questions. R is not under the full control of the researchers: it is affected by S, the sampling procedure, but also by the idiosyncratic choices of participants who have higher and lower interest and ability to respond and participate in the study (U). Similarly, the endogenous variable treatment D represents whether participants actually receive the treatment, regardless of their assignment Z. D is affected by the treatment assignment procedure (Z) of course. But except in cases when Z fully determines D (no noncompliance), we are concerned that it will be affected by unobserved idiosyncratic features of individuals U. The third researcher node is Q, the measurement procedure. Q affects Y, the observed outcome, measured by the researcher. Y is also affected by a latent variable Y*, which cannot be directly observed. The measurement procedure provides an imperfect measurement of that latent variable, which is (potentially) affected by treatment D and unobserved heterogeneity U. In the robustness section at the end of the chapter, we explore further variations of this DAG that incorporate threats to inference from noncompliance, attrition, excludability violations, and interference.</p>
</blockquote>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Can you draw four arrows representing the four exclusion restrictions?</p>
</div>
</div>
</section><section id="statistical-conclusion-validity" class="level2"><h2 class="anchored" data-anchor-id="statistical-conclusion-validity">Statistical Conclusion Validity</h2>
<p>Given that our exclusion restrictions are satisfied, we can estimate the average treatment effect (ATE). The question is then: How can we ensure valid statistical conclusions from our estimate of the ATE?</p>
<p>We need to consider the uncertainty in our estimate, and whether we can reject the null hypothesis that the treatment has no effect.</p>
</section></section><section id="sampling-frameworks-understanding-the-foundations-of-estimation-in-experiments" class="level1"><h1><strong>Sampling Frameworks: Understanding the Foundations of Estimation in Experiments</strong></h1>
<p>When designing an experiment, we need to consider how the sample relates to the broader population of interest. This decision influences the <strong>statistical inference</strong> and generalizability of findings. Two main perspectives in sampling frameworks help frame this discussion: the <strong>super-population approach</strong> and the <strong>finite-population approach</strong>.</p>
<ul>
<li>
<strong>super-population approach</strong>: units are assumed an independent sample from some hypothetical infinite population.</li>
<li>
<strong>finite-population approach</strong>: inference is restricted to the specific individuals in the sample. Potential outcomes of the experimental units are fixed, and the randomness comes solely from the treatment assignment.</li>
</ul>
<section id="the-super-population-approach" class="level2"><h2 class="anchored" data-anchor-id="the-super-population-approach"><strong>The Super-Population Approach</strong></h2>
<p>The <strong>super-population approach</strong> assumes that the study sample is drawn from a larger, hypothetical <strong>infinite population</strong> represented by a probability distribution, <span class="math inline">\(Q\)</span>. This perspective views potential outcomes—both with and without treatment—as stochastic variables drawn from <span class="math inline">\(Q\)</span>. The primary goal in this framework is to estimate a <strong>feature of this distribution</strong>, typically the <strong>expected treatment effect</strong>:</p>
<p><span class="math display">\[
E[Y(1) - Y(0)]
\]</span></p>
<p>where <span class="math inline">\(Y(1)\)</span> and <span class="math inline">\(Y(0)\)</span> denote the potential outcomes under treatment and control conditions, respectively. Under this approach, each sample is considered an independent and identically distributed (i.i.d.) draw from the distribution <span class="math inline">\(Q\)</span>, meaning the researcher is interested in making <strong>generalizable inferences</strong> beyond the study sample.</p>
<p>A key implication of this framework is that <strong>two sources of variance</strong> affect our estimation of treatment effects: 1. <strong>Sampling variance</strong>—arising from differences between one sample and another. 2. <strong>Assignment mechanism variance</strong>—introduced by the randomness in treatment assignment.</p>
<p>The super-population approach is useful when researchers aim to extend their findings to a broader population, such as in <strong>policy recommendations</strong> or <strong>clinical trials</strong>. However, it requires strong assumptions about how well the study sample represents the population.</p>
</section><section id="the-finite-population-approach" class="level2"><h2 class="anchored" data-anchor-id="the-finite-population-approach"><strong>The Finite-Population Approach</strong></h2>
<p>In contrast, the <strong>finite-population approach</strong> considers the sample as a fixed, well-defined group rather than a subset of an infinite population. Here, the researcher is not making inferences beyond the observed sample but instead treating the units as the <strong>entire relevant population</strong>. This approach is common in <strong>evaluations of specific interventions</strong> where the focus is on estimating the <strong>finite-population average treatment effect (ATE)</strong> (also called the sample average treatemnt effect, or SATE):<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p><span class="math display">\[
\tau_{fp} = \frac{1}{N} \sum_{i=1}^{N} \left[Y_i(1) - Y_i(0)\right]
\]</span></p>
<p>where <span class="math inline">\(N\)</span> is the total number of units in the study. Unlike in the super-population approach, the potential outcomes in a finite population framework are <strong>fixed, not random</strong>. The treatment effect is then viewed as an empirical quantity to be estimated within the sample, rather than a parameter of an underlying distribution.</p>
<p>A <strong>practical distinction</strong> between the two approaches is in their implications for statistical inference:</p>
<ul>
<li><p>In the <strong>super-population approach</strong>, standard errors reflect both <strong>sampling variability</strong> and <strong>randomization-induced variation</strong>.</p></li>
<li><p>In the <strong>finite-population approach</strong>, standard errors are based only on the <strong>variation within the observed sample</strong>, without assuming a broader distribution.</p></li>
</ul>
<p>This framework is particularly relevant when researchers are concerned with <strong>internal validity</strong> over generalizability, such as in <strong>program evaluations or field experiments</strong>.</p>
</section><section id="subpopulations-in-the-super-population-framework" class="level2"><h2 class="anchored" data-anchor-id="subpopulations-in-the-super-population-framework"><strong>Subpopulations in the Super-Population Framework</strong></h2>
<p>Within the super-population framework, researchers often refine their analysis by considering <strong>subpopulations</strong> to account for <strong>heterogeneous treatment effects</strong>. One important example is the <strong>Conditional Average Treatment Effect (CATE)</strong>:</p>
<p><span class="math display">\[
E[Y(1, X) - Y(0, X) | X]
\]</span></p>
<p>where <span class="math inline">\(X\)</span> represents observed covariates that influence treatment effects. This approach allows for <strong>differentiated insights</strong> across groups, such as demographic segments in public health interventions.</p>
</section><section id="choosing-between-the-two-approaches" class="level2"><h2 class="anchored" data-anchor-id="choosing-between-the-two-approaches"><strong>Choosing Between the Two Approaches</strong></h2>
<p>The choice between these sampling frameworks depends on the <strong>research question</strong>:</p>
<ul>
<li>If the goal is to make <strong>generalizable claims</strong> about a broader population, the <strong>super-population approach</strong> is preferred.</li>
<li>If the study focuses on <strong>a specific, finite group of units</strong>, the <strong>finite-population approach</strong> is more appropriate.</li>
</ul>
<p>Both perspectives provide valuable insights, and many empirical studies incorporate elements of both frameworks, particularly when considering <strong>external validity and policy relevance</strong>.</p>
</section></section><section id="single-hypothesis-testing-and-statistical-power" class="level1"><h1>Single Hypothesis Testing and Statistical Power</h1>
<p>With our sampling framework in mind, we can now turn to <strong>single hypothesis testing</strong> and <strong>statistical power</strong>. The first thing we need to do is choose an <strong>estimator</strong> of interest. If the estimand is an <strong>Average Treatment Effect (ATE)</strong>, then a reasonable choice is the <strong>difference-in-means estimator</strong>. This estimator compares the mean outcome of the treated group (<span class="math inline">\(Y(1)\)</span>) and the control group (<span class="math inline">\(Y(0)\)</span>):</p>
<p><span class="math display">\[
\hat{\tau} = \bar{Y}_1 - \bar{Y}_0
\]</span></p>
<p>where <span class="math inline">\(\bar{Y}_1\)</span> and <span class="math inline">\(\bar{Y}_0\)</span> are the sample means of the treated and control groups, respectively. The difference-in-means estimator provides an unbiased estimate of the <strong>Average Treatment Effect (ATE)</strong> (the estimand) under the assumption of random assignment.</p>
<p>However, while the estimator provides a point estimate of the treatment effect, it does not convey <strong>uncertainty</strong>. To formally assess whether the estimated effect is significantly different from zero, we conduct a <strong>statistical hypothesis test</strong>.</p>
<p>The fundamental question we seek to answer is:<br><strong>Can we be confident in detecting the reported effect size in our experimental results?</strong></p>
<p>To do so, we frame our problem in terms of <strong>hypothesis testing</strong>:</p>
<ul>
<li><p>We begin by specifying a <strong>null hypothesis (</strong><span class="math inline">\(H_0\)</span>), which typically asserts that the treatment has no effect (<span class="math inline">\(\tau = 0\)</span>).</p></li>
<li><p>The <strong>alternative hypothesis (</strong><span class="math inline">\(H_A\)</span>) posits that there is a nonzero effect (<span class="math inline">\(\tau \neq 0\)</span>).</p></li>
<li><p>Hypothesis testing allows us to assess whether the observed difference-in-means provides sufficient evidence to reject <span class="math inline">\(H_0\)</span>.</p></li>
</ul>
<p>The hypothesis test is based on the <strong>sampling distribution</strong> of the estimator. Because we assume random assignment, the <strong>difference-in-means estimator follows a known distribution</strong>, and we use this fact to determine whether the observed effect is large enough to be statistically significant.</p>
<section id="statistical-significance-and-the-t-statistic" class="level2"><h2 class="anchored" data-anchor-id="statistical-significance-and-the-t-statistic">Statistical Significance and the t-Statistic</h2>
<p>To formally test the null hypothesis, we construct a <strong>t-statistic</strong>:</p>
<p><span class="math display">\[
t = \frac{\hat{\tau}}{\text{SE}(\hat{\tau})}
\]</span></p>
<p>where <strong>SE(</strong><span class="math inline">\(\hat{\tau}\)</span>) represents the standard error of the difference-in-means estimator. As the sample size grows, this t-statistic follows a standard normal distribution (or Student’s t-distribution for small samples). A large absolute value of $ t $ provides evidence against the null hypothesis.</p>
<p>To determine whether the result is <strong>statistically significant</strong>, we compare the t-statistic to a <strong>critical value</strong> determined by our chosen <strong>significance level</strong> (<span class="math inline">\(\alpha\)</span>, commonly set at 0.05). If the absolute value of the t-statistic exceeds this threshold, we reject the null hypothesis.</p>
</section><section id="type-i-and-type-ii-errors" class="level2"><h2 class="anchored" data-anchor-id="type-i-and-type-ii-errors">Type I and Type II Errors</h2>
<p>While hypothesis testing provides a structured approach to evaluating treatment effects, errors can still occur:</p>
<ol type="1">
<li>
<strong>Type I Error (</strong><span class="math inline">\(\alpha\)</span>): Rejecting the null hypothesis when it is actually true (false positive).
<ul>
<li>Controlled by setting the significance level (<span class="math inline">\(\alpha\)</span>), which determines the probability of mistakenly rejecting <span class="math inline">\(H_0\)</span>.</li>
<li>Lower <span class="math inline">\(\alpha\)</span> reduces false positives but increases the risk of missing real effects.</li>
</ul>
</li>
<li>
<strong>Type II Error (</strong><span class="math inline">\(\beta\)</span>): Failing to reject the null hypothesis when it is actually false (false negative).
<ul>
<li>Related to <strong>statistical power</strong>, which is the probability of detecting an effect when it truly exists.</li>
</ul>
</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="../unit-1/media/HypothesisTesting.png" class="img-fluid figure-img"></p>
<figcaption>Type 1 and Type 2 Errors</figcaption></figure>
</div>
</section><section id="power-calculation-ensuring-detectability" class="level2"><h2 class="anchored" data-anchor-id="power-calculation-ensuring-detectability">Power Calculation: Ensuring Detectability</h2>
<p><strong>Statistical power</strong> refers to the ability of a test to correctly reject the null hypothesis when a true effect exists. Mathematically:</p>
<p><span class="math display">\[
\text{Power} = 1 - \beta
\]</span></p>
<p>Factors influencing power:</p>
<ul>
<li>
<strong>Effect size (</strong><span class="math inline">\(\tau\)</span>): Larger effects are easier to detect.</li>
<li>
<strong>Sample size (</strong><span class="math inline">\(N\)</span>): Larger samples reduce variability, increasing power.</li>
<li>
<strong>Significance level (</strong><span class="math inline">\(\alpha\)</span>): Lowering <span class="math inline">\(\alpha\)</span> increases the risk of missing true effects.</li>
<li>
<strong>Standard deviation of outcomes</strong>: Higher variability in outcomes reduces power.</li>
</ul>
<p>To achieve a well-powered experiment, researchers conduct <strong>power calculations</strong> before data collection to determine the minimum sample size required to detect an effect with reasonable confidence.</p>
<section id="a-simple-example" class="level3"><h3 class="anchored" data-anchor-id="a-simple-example">A Simple Example</h3>
<p>Let’s consider a simple example of a power simulation using a simple random assignment to a treatment and control group, where the estimate is the <strong>difference-in-means estimator</strong>.</p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://r-datatable.com">data.table</a></span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="step-1-define-simulation-parameters" class="level4"><h4 class="anchored" data-anchor-id="step-1-define-simulation-parameters"><strong>Step 1: Define Simulation Parameters</strong></h4>
<ul>
<li>Let’s assume we have a total sample size of <span class="math inline">\(N = 200\)</span> individuals.</li>
<li>The treatment group receives an intervention, while the control group does not.</li>
<li>The true treatment effect is set to <span class="math inline">\(\tau = 2\)</span>.</li>
<li>The outcome variable follows a normal distribution with mean 10 and standard deviation 4.</li>
</ul>
<div class="cell">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">072111</span><span class="op">)</span>  <span class="co"># Ensures reproducibility</span></span>
<span></span>
<span><span class="co"># Define parameters</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">200</span>  <span class="co"># Total sample size</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">0.5</span>  <span class="co"># Probability of assignment to treatment</span></span>
<span><span class="va">true_tau</span> <span class="op">&lt;-</span> <span class="fl">2</span>  <span class="co"># True treatment effect</span></span>
<span><span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fl">4</span>  <span class="co"># Standard deviation of outcome</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="step-2-simulate-data" class="level4"><h4 class="anchored" data-anchor-id="step-2-simulate-data"><strong>Step 2: Simulate Data</strong></h4>
<p>Now we can simulate the data using data.table:</p>
<div class="cell">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Simulate data using data.table</span></span>
<span><span class="va">dt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/data.table/man/data.table.html">data.table</a></span><span class="op">(</span>id <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="va">N</span><span class="op">)</span></span>
<span><span class="va">dt</span><span class="op">[</span>, <span class="va">treatment</span> <span class="op">:=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">.N</span>, <span class="fl">1</span>, <span class="va">p</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">dt</span><span class="op">[</span>, <span class="va">outcome</span> <span class="op">:=</span> <span class="fl">10</span> <span class="op">+</span> <span class="va">true_tau</span> <span class="op">*</span> <span class="va">treatment</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">.N</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="co">#display first few rows</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">dt</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      id treatment  outcome
   &lt;int&gt;     &lt;int&gt;    &lt;num&gt;
1:     1         0 10.39758
2:     2         1 17.78058
3:     3         0 11.46925
4:     4         0 14.56752
5:     5         1 10.55347
6:     6         1 14.99933</code></pre>
</div>
</div>
</section><section id="step-3-estimate-treatment-effect" class="level4"><h4 class="anchored" data-anchor-id="step-3-estimate-treatment-effect"><strong>Step 3: Estimate Treatment Effect</strong></h4>
<div class="cell">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">diff_means</span> <span class="op">&lt;-</span> <span class="va">dt</span><span class="op">[</span><span class="va">treatment</span> <span class="op">==</span> <span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">outcome</span><span class="op">)</span><span class="op">]</span> <span class="op">-</span> <span class="va">dt</span><span class="op">[</span><span class="va">treatment</span> <span class="op">==</span> <span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">outcome</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">SE</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">dt</span><span class="op">[</span><span class="va">treatment</span> <span class="op">==</span> <span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">outcome</span><span class="op">)</span><span class="op">]</span> <span class="op">/</span> <span class="va">dt</span><span class="op">[</span><span class="va">treatment</span> <span class="op">==</span> <span class="fl">1</span>, <span class="va">.N</span><span class="op">]</span> <span class="op">+</span></span>
<span>           <span class="va">dt</span><span class="op">[</span><span class="va">treatment</span> <span class="op">==</span> <span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">outcome</span><span class="op">)</span><span class="op">]</span> <span class="op">/</span> <span class="va">dt</span><span class="op">[</span><span class="va">treatment</span> <span class="op">==</span> <span class="fl">0</span>, <span class="va">.N</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="va">t_stat</span> <span class="op">&lt;-</span> <span class="va">diff_means</span> <span class="op">/</span> <span class="va">SE</span>  <span class="co"># Compute t-statistic</span></span>
<span><span class="va">p_value</span> <span class="op">&lt;-</span> <span class="fl">2</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">pt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">t_stat</span><span class="op">)</span>, df <span class="op">=</span> <span class="va">N</span> <span class="op">-</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span>  <span class="co"># Two-tailed test</span></span>
<span></span>
<span><span class="co"># Display results</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Estimated Treatment Effect:"</span>, <span class="va">diff_means</span>, <span class="st">"\n"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Estimated Treatment Effect: 2.453868 </code></pre>
</div>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"p-value:"</span>, <span class="va">p_value</span>, <span class="st">"\n"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>p-value: 1.088986e-05 </code></pre>
</div>
</div>
</section><section id="step-4-power-simulation" class="level4"><h4 class="anchored" data-anchor-id="step-4-power-simulation"><strong>Step 4: Power Simulation</strong></h4>
<p>First, let’s consider how we will interpret the results:</p>
<ul>
<li>If the p-value is <strong>less than 0.05</strong>, we reject the null hypothesis and conclude that the treatment has a significant effect.</li>
<li>If the p-value is <strong>greater than 0.05</strong>, we fail to reject the null, meaning we do not have enough evidence to confirm a treatment effect.</li>
</ul>
<p>Now, let’s simulate a power simulation:</p>
<p>First, define the power simulation function:</p>
<div class="cell">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">simulate_power</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">N</span>, <span class="va">true_tau</span>, <span class="va">sigma</span>, <span class="va">p</span>, <span class="va">alpha</span>, <span class="va">reps</span> <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">rejections</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span>  </span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">reps</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">dt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/data.table/man/data.table.html">data.table</a></span><span class="op">(</span>id <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="va">N</span><span class="op">)</span></span>
<span>    <span class="va">dt</span><span class="op">[</span>, <span class="va">treatment</span> <span class="op">:=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">.N</span>, <span class="fl">1</span>, <span class="va">p</span><span class="op">)</span><span class="op">]</span></span>
<span>    <span class="va">dt</span><span class="op">[</span>, <span class="va">outcome</span> <span class="op">:=</span> <span class="fl">10</span> <span class="op">+</span> <span class="va">true_tau</span> <span class="op">*</span> <span class="va">treatment</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">.N</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span><span class="op">]</span></span>
<span>    <span class="va">diff_means</span> <span class="op">&lt;-</span> <span class="va">dt</span><span class="op">[</span><span class="va">treatment</span> <span class="op">==</span> <span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">outcome</span><span class="op">)</span><span class="op">]</span> <span class="op">-</span> <span class="va">dt</span><span class="op">[</span><span class="va">treatment</span> <span class="op">==</span> <span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">outcome</span><span class="op">)</span><span class="op">]</span></span>
<span>    <span class="va">SE</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">dt</span><span class="op">[</span><span class="va">treatment</span> <span class="op">==</span> <span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">outcome</span><span class="op">)</span><span class="op">]</span> <span class="op">/</span> <span class="va">dt</span><span class="op">[</span><span class="va">treatment</span> <span class="op">==</span> <span class="fl">1</span>, <span class="va">.N</span><span class="op">]</span> <span class="op">+</span></span>
<span>               <span class="va">dt</span><span class="op">[</span><span class="va">treatment</span> <span class="op">==</span> <span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">outcome</span><span class="op">)</span><span class="op">]</span> <span class="op">/</span> <span class="va">dt</span><span class="op">[</span><span class="va">treatment</span> <span class="op">==</span> <span class="fl">0</span>, <span class="va">.N</span><span class="op">]</span><span class="op">)</span></span>
<span>    <span class="va">t_stat</span> <span class="op">&lt;-</span> <span class="va">diff_means</span> <span class="op">/</span> <span class="va">SE</span></span>
<span>    <span class="va">p_value</span> <span class="op">&lt;-</span> <span class="fl">2</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">pt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">t_stat</span><span class="op">)</span>, df <span class="op">=</span> <span class="va">N</span> <span class="op">-</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="va">p_value</span> <span class="op">&lt;</span> <span class="va">alpha</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="va">rejections</span> <span class="op">&lt;-</span> <span class="va">rejections</span> <span class="op">+</span> <span class="fl">1</span></span>
<span>    <span class="op">}</span></span>
<span>  <span class="op">}</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">rejections</span> <span class="op">/</span> <span class="va">reps</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, simulate this experiment <strong>1,000 times</strong>:</p>
<div class="cell">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Run power simulation</span></span>
<span><span class="va">power</span> <span class="op">&lt;-</span> <span class="fu">simulate_power</span><span class="op">(</span>N <span class="op">=</span> <span class="fl">200</span>, true_tau <span class="op">=</span> <span class="fl">2</span>, sigma <span class="op">=</span> <span class="fl">4</span>, p <span class="op">=</span> <span class="fl">0.5</span>, alpha <span class="op">=</span> <span class="fl">0.05</span>, reps <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Estimated Power:"</span>, <span class="va">power</span>, <span class="st">"\n"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Estimated Power: 0.938 </code></pre>
</div>
</div>
</section></section><section id="step-5-interpreting-power-calculation" class="level3"><h3 class="anchored" data-anchor-id="step-5-interpreting-power-calculation"><strong>Step 5: Interpreting Power Calculation</strong></h3>
<ul>
<li>The <strong>power</strong> of the test is the proportion of simulations in which we correctly reject the null hypothesis when the treatment effect is truly <span class="math inline">\(\tau = 2\)</span>.</li>
<li>A power value close to <strong>0.80 or higher</strong> indicates that the experiment is well-powered.</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Try changing the sample size or effect size, to see how the power changes.</p>
</div>
</div>
</section></section></section><section id="simulations-in-research-design" class="level1"><h1>Simulations in Research Design</h1>
<p>To fix ideas of what we’re doing with simulations, it might be helpful to take a step back and view this in the context of an overall research design.</p>
<p>We aim to generate empirical answers that closely approximate the true treatment effect. However, because we never observe both potential outcomes for an individual, we rely on statistical methods and experimental design to make <strong>valid inferences</strong>. Simulation plays a crucial role in assessing research designs, allowing us to compare <strong>simulated answers</strong> to possible true answers across multiple realizations of a study.</p>
<p>In empirical research, a design consists of two halves:</p>
<ol type="1">
<li>
<strong>Theoretical Component</strong>: Defines the inquiry using a model <span class="math inline">\(M\)</span>.</li>
<li>
<strong>Empirical Component</strong>: Applies the data strategy <span class="math inline">\(D\)</span> to generate a dataset, then applies an estimation strategy <span class="math inline">\(A\)</span> to obtain the empirical answer <span class="math inline">\(a_d\)</span>.</li>
</ol>
<p>Simulation dissociates the design from reality, allowing researchers to assess how their chosen model performs across various possible scenarios, even when the true answer is unknown.</p>
<section id="the-mida-framework-for-simulation" class="level2"><h2 class="anchored" data-anchor-id="the-mida-framework-for-simulation">The MIDA Framework for Simulation</h2>
<p>A structured way to think about research design and simulation is the <strong>MIDA Framework</strong>,<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>(https://book.declaredesign.org/declaration-diagnosis-redesign/research-design.html)] which consists of:</p>
<ul>
<li>
<strong>M</strong>: The Model - The underlying data-generating process that defines the inquiry.</li>
<li>
<strong>I</strong>: The Inquiry - The specific research question we are trying to answer.</li>
<li>
<strong>D</strong>: The Data Strategy - The way we collect and structure data, including sampling and treatment assignment.</li>
<li>
<strong>A</strong>: The Answer Strategy - The statistical method we use to estimate the effect.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="../unit-1/media/MIDA.svg" class="img-fluid figure-img"></p>
<figcaption>MIDA Framework, Source: Declaration Design</figcaption></figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="../unit-1/media/RDElements.png" class="img-fluid figure-img"></p>
<figcaption>Elements of Research Design, Source: Declaration Design</figcaption></figure>
</div>
<p>In a real-world study, we can only observe a single realization of the design and generate one empirical answer <span class="math inline">\(a_d\)</span>. However, through <strong>simulation</strong>, we can consider many possible data realizations by repeatedly drawing from different models <span class="math inline">\(m_1, m_2, ..., m_k\)</span> within the model space <span class="math inline">\(M\)</span>. This allows us to assess how our research design performs across different scenarios.</p>
</section><section id="diagnosing-research-designs-with-simulation" class="level2"><h2 class="anchored" data-anchor-id="diagnosing-research-designs-with-simulation">Diagnosing Research Designs with Simulation</h2>
<p>When we simulate a research design, we evaluate its <strong>performance</strong> by considering:</p>
<ul>
<li>
<strong>Bias</strong>: How close is the empirical answer <span class="math inline">\(a_d\)</span> to the true answer <span class="math inline">\(a_m\)</span>?</li>
<li>
<strong>Variance</strong>: How much do the empirical answers fluctuate across different realizations?</li>
<li>
<strong>Coverage</strong>: How often do confidence intervals include the true effect?</li>
<li>
<strong>Power</strong>: How frequently does the study correctly reject the null hypothesis when a true effect exists?</li>
</ul>
<p>The bottom half of the figure below illustrates how simulation allows us to examine the research design across multiple models (<span class="math inline">\(m_1, ..., m_k\)</span>), generating different answers (<span class="math inline">\(a_{m_1}, a_{m_2}, ..., a_{m_k}\)</span>) and associated datasets (<span class="math inline">\(d_1, d_2, ..., d_k\)</span>). The simulated research design does not have direct access to the true answer but can assess performance across the models under consideration.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="../unit-1/media/MIDA-Simulation.svg" class="img-fluid figure-img"></p>
<figcaption>Simulations in the MIDA Framework</figcaption></figure>
</div>
</section></section><section id="multiple-hypothesis-testing" class="level1"><h1>Multiple Hypothesis Testing</h1>
<section id="the-challenge-of-multiple-hypothesis-testing" class="level2"><h2 class="anchored" data-anchor-id="the-challenge-of-multiple-hypothesis-testing">The Challenge of Multiple Hypothesis Testing</h2>
<p>In many empirical settings, researchers conduct <strong>multiple hypothesis tests</strong> rather than a single test. This introduces the risk of <strong>false positives</strong>, or mistakenly finding significant effects simply due to chance. Multiple hypothesis testing arises naturally in at least three key scenarios:</p>
<ol type="1">
<li>
<strong>Multiple Outcomes</strong>: When we examine several outcomes (<span class="math inline">\(Y_i\)</span>) to determine whether any are affected by the treatment.</li>
<li>
<strong>Heterogeneous Treatment Effects (CATEs)</strong>: When treatment effects vary across subgroups, and we want to assess which subgroups exhibit an effect.</li>
<li>
<strong>Multiple Treatments</strong>: When we compare multiple interventions (<span class="math inline">\(D_i\)</span>) and want to test their effects relative to a control group or to each other.</li>
</ol>
<p>To properly interpret results, we need statistical techniques that <strong>adjust for multiple comparisons</strong> and control the probability of <strong>false discoveries</strong>.</p>
<hr></section><section id="types-of-multiple-hypothesis-tests" class="level2"><h2 class="anchored" data-anchor-id="types-of-multiple-hypothesis-tests">Types of Multiple Hypothesis Tests</h2>
<p>There are two broad types of statistical hypothesis testing frameworks when dealing with multiple comparisons:</p>
<ul>
<li>
<strong>Joint Tests</strong>: These assess whether at least one hypothesis is true (e.g., “Is at least one treatment effective?”).</li>
<li>
<strong>Simultaneous Tests</strong>: These examine whether multiple hypotheses are true at the same time (e.g., “Are both Treatment A and Treatment B effective?”).</li>
</ul>
<p>When conducting multiple tests, researchers need to control for an increased <strong>family-wise error rate (FWER)</strong>, which is the probability of making at least one Type I error (false positive).</p>
<hr></section><section id="controlling-the-family-wise-error-rate-fwer" class="level2"><h2 class="anchored" data-anchor-id="controlling-the-family-wise-error-rate-fwer">Controlling the Family-Wise Error Rate (FWER)</h2>
<p>A single hypothesis test controls the probability of a <strong>Type I error</strong> at a given significance level (<span class="math inline">\(\alpha\)</span>). However, with multiple tests, the probability of making <strong>at least one false rejection</strong> increases:</p>
<p><span class="math display">\[
\text{FWER} = 1 - (1 - \alpha)^k
\]</span></p>
<p>where <span class="math inline">\(k\)</span> is the number of tests. For example, if we conduct <strong>5 tests at</strong> <span class="math inline">\(\alpha = 0.05\)</span>, the probability of making <strong>no Type I errors</strong> across all tests is:</p>
<p><span class="math display">\[
(1 - 0.05)^5 = 0.7738
\]</span></p>
<p>Thus, the probability of making <strong>at least one</strong> Type I error is:</p>
<p><span class="math display">\[
FWER = 1 - 0.7738 = 0.2262
\]</span></p>
<p>This means there is a <strong>22.62% chance</strong> of mistakenly rejecting at least one null hypothesis across the five tests. If we perform <strong>20 tests</strong>, the FWER increases to <strong>64%</strong>.</p>
<hr></section><section id="approaches-to-controlling-the-fwer" class="level2"><h2 class="anchored" data-anchor-id="approaches-to-controlling-the-fwer">Approaches to Controlling the FWER</h2>
<p>To mitigate this issue, researchers employ various <strong>multiple testing corrections</strong>, such as:</p>
<ul>
<li>
<strong>Bonferroni Correction</strong>: Adjusts the significance level by dividing <span class="math inline">\(\alpha\)</span> by the number of tests: <span class="math inline">\(\alpha^* = \alpha / k\)</span>. This is simple but conservative.</li>
<li>
<strong>Holm Method</strong>: A stepwise procedure that ranks p-values and adjusts them sequentially to control the FWER more efficiently.</li>
<li>
<strong>Modern Approaches (e.g., Westfall-Young, Benjamini-Hochberg FDR control)</strong>: These methods control for false discovery rates and are widely used in large-scale testing.</li>
</ul>
<hr></section><section id="simulating-multiple-hypothesis-testing-in-r" class="level2"><h2 class="anchored" data-anchor-id="simulating-multiple-hypothesis-testing-in-r">Simulating Multiple Hypothesis Testing in R</h2>
<p>To illustrate the impact of multiple testing and FWER correction, let’s do a simulation in R:</p>
<div class="cell">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://r-datatable.com">data.table</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">072111</span><span class="op">)</span>  <span class="co"># Ensures reproducibility</span></span>
<span></span>
<span><span class="co"># Define parameters</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">200</span>  <span class="co"># Sample size</span></span>
<span><span class="va">k</span> <span class="op">&lt;-</span> <span class="fl">10</span>  <span class="co"># Number of hypothesis tests</span></span>
<span><span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">0.05</span>  <span class="co"># Significance level</span></span>
<span></span>
<span><span class="co"># Simulate k independent hypothesis tests</span></span>
<span><span class="va">dt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/data.table/man/data.table.html">data.table</a></span><span class="op">(</span>test_id <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="va">k</span><span class="op">)</span></span>
<span><span class="va">dt</span><span class="op">[</span>, <span class="va">p_value</span> <span class="op">:=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">.N</span>, min <span class="op">=</span> <span class="fl">0</span>, max <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">]</span>  <span class="co"># Generate uniform random p-values</span></span>
<span></span>
<span><span class="va">dt</span><span class="op">[</span>, <span class="va">bonferroni</span> <span class="op">:=</span> <span class="va">p_value</span> <span class="op">&lt;</span> <span class="op">(</span><span class="va">alpha</span> <span class="op">/</span> <span class="va">k</span><span class="op">)</span><span class="op">]</span>  <span class="co"># Bonferroni correction</span></span>
<span><span class="va">dt</span><span class="op">[</span>, <span class="va">holm</span> <span class="op">:=</span> <span class="fu"><a href="https://rdrr.io/r/stats/p.adjust.html">p.adjust</a></span><span class="op">(</span><span class="va">p_value</span>, method <span class="op">=</span> <span class="st">"holm"</span><span class="op">)</span> <span class="op">&lt;</span> <span class="va">alpha</span><span class="op">]</span>  <span class="co"># Holm correction</span></span>
<span></span>
<span><span class="va">dt</span><span class="op">[</span>, <span class="va">naive_reject</span> <span class="op">:=</span> <span class="va">p_value</span> <span class="op">&lt;</span> <span class="va">alpha</span><span class="op">]</span>  <span class="co"># Standard test (without correction)</span></span>
<span></span>
<span><span class="co"># Count false positives</span></span>
<span><span class="va">false_discoveries</span> <span class="op">&lt;-</span> <span class="va">dt</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">naive_reject</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">adjusted_false_discoveries</span> <span class="op">&lt;-</span> <span class="va">dt</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">bonferroni</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">holm_false_discoveries</span> <span class="op">&lt;-</span> <span class="va">dt</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">holm</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"False positives (no correction):"</span>, <span class="va">false_discoveries</span>, <span class="st">"\n"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>False positives (no correction): 2 </code></pre>
</div>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"False positives (Bonferroni correction):"</span>, <span class="va">adjusted_false_discoveries</span>, <span class="st">"\n"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>False positives (Bonferroni correction): 0 </code></pre>
</div>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"False positives (Holm correction):"</span>, <span class="va">holm_false_discoveries</span>, <span class="st">"\n"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>False positives (Holm correction): 0 </code></pre>
</div>
</div>
<section id="interpreting-the-simulation" class="level3"><h3 class="anchored" data-anchor-id="interpreting-the-simulation"><strong>Interpreting the Simulation</strong></h3>
<ul>
<li>
<strong>Without correction</strong>, we expect around <span class="math inline">\(\alpha \times k\)</span> false discoveries.</li>
<li>
<strong>Bonferroni correction</strong> sharply reduces false positives but may be overly conservative.</li>
<li>
<strong>Holm correction</strong> provides a better balance, controlling FWER while maintaining statistical power.</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note: In the lab, we’ll cover some modern approaches that are more powerful but a bit more complex.</p>
</div>
</div>
</section></section></section><section id="references" class="level1"><h1>References</h1>
<ol type="1">
<li><a href="https://web.stanford.edu/~swager/causal_inf_book.pdf">Wager Chapter 1</a></li>
<li><a href="https://book.declaredesign.org/declaration-diagnosis-redesign/declaring-designs.html">Declare Design Book</a></li>
</ol>


<!-- -->

</section><div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>
<ol>
<li id="fn1"><p>Reference: <a href="https://book.declaredesign.org/declaration-diagnosis-redesign/choosing-answer-strategy.html#uncertainty">Research Design in the Social Sciences</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Can you explain in words how this differs from the Bayesian probability above?<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><a href="https://web.stanford.edu/~swager/causal_inf_book.pdf">Wager Chapter 1</a> refers to this as SATE.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Reference: Declaration Design<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></div></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/hpm883\.github\.io");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb18" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Unit 1-2: Statistical Conclusion Validity"</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "Lecture Notes"</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Sean Sylvia, Ph.D."</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> February 5, 2025</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-depth: 2</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="an">draft:</span><span class="co"> false</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="fu"># Summary</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>This lecture delves into statistical conclusion validity, exploring how we can assess the reliability and accuracy of estimated treatment effects in experimental research. As we have seen, due to the fundamental nature of potential outcomes, it is inherently impossible to recover individual treatment effects since each unit reveals only one potential outcome. However, under specific assumptions and with an appropriate assignment mechanism—such as random assignment—we can consistently estimate an average treatment effect (ATE). This lecture provides a brief, selective statistical background on how to estimate the ATE and quantify the uncertainty in these estimates, ensuring statistical conclusion validity. To streamline the presentation, we focus on settings with a binary treatment and largely ignore the role of covariates.</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="fu"># Learning Objectives</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>Explain the concept of statistical conclusion validity and its importance in ensuring that the estimated treatment effect reflects the true effect.</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>Identify the key sources of uncertainty in experimental studies, including sampling variation, variance in potential outcomes, and measurement error.</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>Review the principles of hypothesis testing, including the formulation of null and alternative hypotheses and the implications of Type I and Type II errors.</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>Explore the role of statistical power in determining the sample size needed to detect significant effects.</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="ss">5.  </span>Explore the use of simulation techniques to conduct power calculations and assess the reliability of experimental designs.</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a><span class="ss">6.  </span>Explore the role of multiple hypothesis testing and its implications in statistical inference.</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a><span class="fu"># Uncertainty and Statistical Conclusion Validity</span></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a><span class="fu">## What is Uncertainty?</span></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>Uncertainty in empirical research refers to the inherent imprecision that arises when we attempt to infer quantities that cannot be directly observed. Whether we are engaged in descriptive, causal, or generalization inference, our estimates come with uncertainty that must be quantified and communicated.</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>Two primary frameworks exist for this purpose: the Bayesian and the frequentist approaches.<span class="ot">[^1]</span></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a><span class="ot">[^1]: </span>Reference: <span class="co">[</span><span class="ot">Research Design in the Social Sciences</span><span class="co">](https://book.declaredesign.org/declaration-diagnosis-redesign/choosing-answer-strategy.html#uncertainty)</span></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a><span class="fu">### Bayesian Approach</span></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>The Bayesian framework uses Bayes’ rule to combine prior beliefs with the observed data, resulting in a posterior probability distribution over the parameter of interest, $\theta$. Mathematically, this is expressed as:</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>\Pr(\theta = \theta' \mid d = d') = \frac{\Pr(d = d' \mid \theta = \theta')\, \Pr(\theta = \theta')}{\sum_{\theta''} \Pr(d = d' \mid \theta = \theta'')\, \Pr(\theta = \theta'')},</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>where:</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$d$ represents data, and $d'$ represents the observed data (or an "observed realization of the data")</span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$\theta'$ and $\theta''$ represent particular values of the parameter $\theta$.</span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a>From this posterior distribution, the **posterior mean** serves as our best estimate of $\theta$, and the **posterior variance** quantifies the uncertainty associated with that estimate.</span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a>By applying Bayes’ rule over different values of $\theta$, we construct a complete probability distribution that represents all possible answers. This posterior distribution simultaneously provides our best estimate—often summarized by the posterior mean—and quantifies our uncertainty via the posterior variance.</span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a>While intuitive, a challenge is that specifying prior uncertainty ($\Pr(\theta = \theta')$) is often a subjective choice, and the posterior distribution is often difficult to interpret and communicate.</span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a><span class="fu">### Frequentist Approach</span></span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a>In contrast, the frequentist approach avoids specifying prior beliefs and focuses on the likelihood function, $\Pr(d = d' \mid \theta = \theta')$, which describes the probability of observing the data $d'$ given a specific value of $\theta$.<span class="ot">[^2]</span> I.e. instead of thinking of the strength of beliefs, we consider that $\theta$ generates the actual probability distriubtion over possible data $d$.</span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a><span class="ot">[^2]: </span>Can you explain in words how this differs from the Bayesian probability above?</span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a>This approach yields useful quantities:</span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a>**P-value**: The p-value for a null hypothesis, $\theta = \theta_0$, is defined as the probability of observing data as extreme as $d_{m*}$ under the null hypothesis, or</span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a>\Pr(d = d_{m*} \mid \theta = \theta_0).</span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a>where $d_{m*}$ is the test statistic.</span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a>**Confidence Interval**: A 95% confidence interval is constructed such that, if the experiment were repeated many times, 95% of the intervals would contain the true parameter value. This approach provides a framework to rule out parameter values that are inconsistent with the observed data, or $Pr(d = d' \mid \theta = \theta') \leq 0.05$.</span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a><span class="fu">## Where Does Uncertainty Come From in an Experimental Study?</span></span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-77"><a href="#cb18-77" aria-hidden="true" tabindex="-1"></a>Before getting into estimation and the uncertainty of the estimate, we need to be precise about the source of uncertainty. In experimental studies, uncertainty is an inherent part of the inference process, arising from several key sources. Recognizing these sources is critical to designing robust experiments and correctly interpreting the results. The main contributors to uncertainty include:</span>
<span id="cb18-78"><a href="#cb18-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-79"><a href="#cb18-79" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Sampling Variation:**\</span>
<span id="cb18-80"><a href="#cb18-80" aria-hidden="true" tabindex="-1"></a>    Uncertainty due to sampling variation stems from the fact that any sample drawn from a population is just one of many possible samples. Consequently, the same treatment might yield different results if applied to a different sample, reflecting random fluctuations in the selection process.</span>
<span id="cb18-81"><a href="#cb18-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-82"><a href="#cb18-82" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Variance in Potential Outcomes:**\</span>
<span id="cb18-83"><a href="#cb18-83" aria-hidden="true" tabindex="-1"></a>    The natural variability in the potential outcomes (i.e., the outcomes that would be observed under different treatment conditions) can lead to uncertainty. High variance makes it more challenging to detect a true treatment effect because the noise in the data can obscure the signal, thereby reducing the study's power to reject a false null hypothesis.</span>
<span id="cb18-84"><a href="#cb18-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-85"><a href="#cb18-85" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Measurement Error:**\</span>
<span id="cb18-86"><a href="#cb18-86" aria-hidden="true" tabindex="-1"></a>    Measurement error occurs when there are inaccuracies in recording or assessing the potential outcomes. Such errors introduce additional variability and can bias the estimated treatment effect, further contributing to uncertainty in the experimental results.</span>
<span id="cb18-87"><a href="#cb18-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-88"><a href="#cb18-88" aria-hidden="true" tabindex="-1"></a>To vizualize this, the diagram below shows a "directed acyclic graph" (DAG) representation of the "data strategy" framework discussed in <span class="co">[</span><span class="ot">Chapter 8 of Research Design in the Social Sciences</span><span class="co">](https://book.declaredesign.org/declaration-diagnosis-redesign/crafting-data-strategy.html)</span>.</span>
<span id="cb18-89"><a href="#cb18-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-90"><a href="#cb18-90" aria-hidden="true" tabindex="-1"></a><span class="al">![Data Strategy DAG, Source: Research Design in the Social Sciences](/unit-1/media/figure-8-1.svg)</span></span>
<span id="cb18-91"><a href="#cb18-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-92"><a href="#cb18-92" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; In Figure 8.1, we illustrate these three elements of data strategies: sampling (S), treatment assignment (Z), and measurement (Q). These nodes are highlighted by blue boxes to emphasize that they are in the control of the researcher. No arrows go into the S, Z, or Q nodes; they are set by the researcher. In each case, the strategy selected by the researcher affects a corresponding endogenous variable. The sampling procedure causes changes in the endogenous response (R), which represents whether participants provide outcome data, for example responding to survey questions. R is not under the full control of the researchers: it is affected by S, the sampling procedure, but also by the idiosyncratic choices of participants who have higher and lower interest and ability to respond and participate in the study (U). Similarly, the endogenous variable treatment D represents whether participants actually receive the treatment, regardless of their assignment Z. D is affected by the treatment assignment procedure (Z) of course. But except in cases when Z fully determines D (no noncompliance), we are concerned that it will be affected by unobserved idiosyncratic features of individuals U. The third researcher node is Q, the measurement procedure. Q affects Y, the observed outcome, measured by the researcher. Y is also affected by a latent variable Y</span><span class="sc">\*</span><span class="at">, which cannot be directly observed. The measurement procedure provides an imperfect measurement of that latent variable, which is (potentially) affected by treatment D and unobserved heterogeneity U. In the robustness section at the end of the chapter, we explore further variations of this DAG that incorporate threats to inference from noncompliance, attrition, excludability violations, and interference.</span></span>
<span id="cb18-93"><a href="#cb18-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-94"><a href="#cb18-94" aria-hidden="true" tabindex="-1"></a>::: callout-tip</span>
<span id="cb18-95"><a href="#cb18-95" aria-hidden="true" tabindex="-1"></a>Can you draw four arrows representing the four exclusion restrictions?</span>
<span id="cb18-96"><a href="#cb18-96" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-97"><a href="#cb18-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-98"><a href="#cb18-98" aria-hidden="true" tabindex="-1"></a><span class="fu">## Statistical Conclusion Validity</span></span>
<span id="cb18-99"><a href="#cb18-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-100"><a href="#cb18-100" aria-hidden="true" tabindex="-1"></a>Given that our exclusion restrictions are satisfied, we can estimate the average treatment effect (ATE). The question is then: How can we ensure valid statistical conclusions from our estimate of the ATE?</span>
<span id="cb18-101"><a href="#cb18-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-102"><a href="#cb18-102" aria-hidden="true" tabindex="-1"></a>We need to consider the uncertainty in our estimate, and whether we can reject the null hypothesis that the treatment has no effect.</span>
<span id="cb18-103"><a href="#cb18-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-104"><a href="#cb18-104" aria-hidden="true" tabindex="-1"></a><span class="fu"># **Sampling Frameworks: Understanding the Foundations of Estimation in Experiments**</span></span>
<span id="cb18-105"><a href="#cb18-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-106"><a href="#cb18-106" aria-hidden="true" tabindex="-1"></a>When designing an experiment, we need to consider how the sample relates to the broader population of interest. This decision influences the **statistical inference** and generalizability of findings. Two main perspectives in sampling frameworks help frame this discussion: the **super-population approach** and the **finite-population approach**.</span>
<span id="cb18-107"><a href="#cb18-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-108"><a href="#cb18-108" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**super-population approach**: units are assumed an independent sample from some hypothetical infinite population.</span>
<span id="cb18-109"><a href="#cb18-109" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**finite-population approach**: inference is restricted to the specific individuals in the sample. Potential outcomes of the experimental units are fixed, and the randomness comes solely from the treatment assignment.</span>
<span id="cb18-110"><a href="#cb18-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-111"><a href="#cb18-111" aria-hidden="true" tabindex="-1"></a><span class="fu">## **The Super-Population Approach**</span></span>
<span id="cb18-112"><a href="#cb18-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-113"><a href="#cb18-113" aria-hidden="true" tabindex="-1"></a>The **super-population approach** assumes that the study sample is drawn from a larger, hypothetical **infinite population** represented by a probability distribution, $Q$. This perspective views potential outcomes—both with and without treatment—as stochastic variables drawn from $Q$. The primary goal in this framework is to estimate a **feature of this distribution**, typically the **expected treatment effect**:</span>
<span id="cb18-114"><a href="#cb18-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-115"><a href="#cb18-115" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-116"><a href="#cb18-116" aria-hidden="true" tabindex="-1"></a>E<span class="co">[</span><span class="ot">Y(1) - Y(0)</span><span class="co">]</span></span>
<span id="cb18-117"><a href="#cb18-117" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-118"><a href="#cb18-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-119"><a href="#cb18-119" aria-hidden="true" tabindex="-1"></a>where $Y(1)$ and $Y(0)$ denote the potential outcomes under treatment and control conditions, respectively. Under this approach, each sample is considered an independent and identically distributed (i.i.d.) draw from the distribution $Q$, meaning the researcher is interested in making **generalizable inferences** beyond the study sample.</span>
<span id="cb18-120"><a href="#cb18-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-121"><a href="#cb18-121" aria-hidden="true" tabindex="-1"></a>A key implication of this framework is that **two sources of variance** affect our estimation of treatment effects: 1. **Sampling variance**—arising from differences between one sample and another. 2. **Assignment mechanism variance**—introduced by the randomness in treatment assignment.</span>
<span id="cb18-122"><a href="#cb18-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-123"><a href="#cb18-123" aria-hidden="true" tabindex="-1"></a>The super-population approach is useful when researchers aim to extend their findings to a broader population, such as in **policy recommendations** or **clinical trials**. However, it requires strong assumptions about how well the study sample represents the population.</span>
<span id="cb18-124"><a href="#cb18-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-125"><a href="#cb18-125" aria-hidden="true" tabindex="-1"></a><span class="fu">## **The Finite-Population Approach**</span></span>
<span id="cb18-126"><a href="#cb18-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-127"><a href="#cb18-127" aria-hidden="true" tabindex="-1"></a>In contrast, the **finite-population approach** considers the sample as a fixed, well-defined group rather than a subset of an infinite population. Here, the researcher is not making inferences beyond the observed sample but instead treating the units as the **entire relevant population**. This approach is common in **evaluations of specific interventions** where the focus is on estimating the **finite-population average treatment effect (ATE)** (also called the sample average treatemnt effect, or SATE):<span class="ot">[^3]</span></span>
<span id="cb18-128"><a href="#cb18-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-129"><a href="#cb18-129" aria-hidden="true" tabindex="-1"></a><span class="ot">[^3]: </span><span class="co">[</span><span class="ot">Wager Chapter 1</span><span class="co">](https://web.stanford.edu/~swager/causal_inf_book.pdf)</span> refers to this as SATE.</span>
<span id="cb18-130"><a href="#cb18-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-131"><a href="#cb18-131" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-132"><a href="#cb18-132" aria-hidden="true" tabindex="-1"></a>\tau_{fp} = \frac{1}{N} \sum_{i=1}^{N} \left<span class="co">[</span><span class="ot">Y_i(1) - Y_i(0)\right</span><span class="co">]</span></span>
<span id="cb18-133"><a href="#cb18-133" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-134"><a href="#cb18-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-135"><a href="#cb18-135" aria-hidden="true" tabindex="-1"></a>where $N$ is the total number of units in the study. Unlike in the super-population approach, the potential outcomes in a finite population framework are **fixed, not random**. The treatment effect is then viewed as an empirical quantity to be estimated within the sample, rather than a parameter of an underlying distribution.</span>
<span id="cb18-136"><a href="#cb18-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-137"><a href="#cb18-137" aria-hidden="true" tabindex="-1"></a>A **practical distinction** between the two approaches is in their implications for statistical inference:</span>
<span id="cb18-138"><a href="#cb18-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-139"><a href="#cb18-139" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>In the **super-population approach**, standard errors reflect both **sampling variability** and **randomization-induced variation**.</span>
<span id="cb18-140"><a href="#cb18-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-141"><a href="#cb18-141" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>In the **finite-population approach**, standard errors are based only on the **variation within the observed sample**, without assuming a broader distribution.</span>
<span id="cb18-142"><a href="#cb18-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-143"><a href="#cb18-143" aria-hidden="true" tabindex="-1"></a>This framework is particularly relevant when researchers are concerned with **internal validity** over generalizability, such as in **program evaluations or field experiments**.</span>
<span id="cb18-144"><a href="#cb18-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-145"><a href="#cb18-145" aria-hidden="true" tabindex="-1"></a><span class="fu">## **Subpopulations in the Super-Population Framework**</span></span>
<span id="cb18-146"><a href="#cb18-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-147"><a href="#cb18-147" aria-hidden="true" tabindex="-1"></a>Within the super-population framework, researchers often refine their analysis by considering **subpopulations** to account for **heterogeneous treatment effects**. One important example is the **Conditional Average Treatment Effect (CATE)**:</span>
<span id="cb18-148"><a href="#cb18-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-149"><a href="#cb18-149" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-150"><a href="#cb18-150" aria-hidden="true" tabindex="-1"></a>E<span class="co">[</span><span class="ot">Y(1, X) - Y(0, X) | X</span><span class="co">]</span></span>
<span id="cb18-151"><a href="#cb18-151" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-152"><a href="#cb18-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-153"><a href="#cb18-153" aria-hidden="true" tabindex="-1"></a>where $X$ represents observed covariates that influence treatment effects. This approach allows for **differentiated insights** across groups, such as demographic segments in public health interventions.</span>
<span id="cb18-154"><a href="#cb18-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-155"><a href="#cb18-155" aria-hidden="true" tabindex="-1"></a><span class="fu">## **Choosing Between the Two Approaches**</span></span>
<span id="cb18-156"><a href="#cb18-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-157"><a href="#cb18-157" aria-hidden="true" tabindex="-1"></a>The choice between these sampling frameworks depends on the **research question**:</span>
<span id="cb18-158"><a href="#cb18-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-159"><a href="#cb18-159" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If the goal is to make **generalizable claims** about a broader population, the **super-population approach** is preferred.</span>
<span id="cb18-160"><a href="#cb18-160" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If the study focuses on **a specific, finite group of units**, the **finite-population approach** is more appropriate.</span>
<span id="cb18-161"><a href="#cb18-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-162"><a href="#cb18-162" aria-hidden="true" tabindex="-1"></a>Both perspectives provide valuable insights, and many empirical studies incorporate elements of both frameworks, particularly when considering **external validity and policy relevance**.</span>
<span id="cb18-163"><a href="#cb18-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-164"><a href="#cb18-164" aria-hidden="true" tabindex="-1"></a><span class="fu"># Single Hypothesis Testing and Statistical Power</span></span>
<span id="cb18-165"><a href="#cb18-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-166"><a href="#cb18-166" aria-hidden="true" tabindex="-1"></a>With our sampling framework in mind, we can now turn to **single hypothesis testing** and **statistical power**. The first thing we need to do is choose an **estimator** of interest. If the estimand is an **Average Treatment Effect (ATE)**, then a reasonable choice is the **difference-in-means estimator**. This estimator compares the mean outcome of the treated group ($Y(1)$) and the control group ($Y(0)$):</span>
<span id="cb18-167"><a href="#cb18-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-168"><a href="#cb18-168" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-169"><a href="#cb18-169" aria-hidden="true" tabindex="-1"></a>\hat{\tau} = \bar{Y}_1 - \bar{Y}_0</span>
<span id="cb18-170"><a href="#cb18-170" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-171"><a href="#cb18-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-172"><a href="#cb18-172" aria-hidden="true" tabindex="-1"></a>where $\bar{Y}_1$ and $\bar{Y}_0$ are the sample means of the treated and control groups, respectively. The difference-in-means estimator provides an unbiased estimate of the **Average Treatment Effect (ATE)** (the estimand) under the assumption of random assignment.</span>
<span id="cb18-173"><a href="#cb18-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-174"><a href="#cb18-174" aria-hidden="true" tabindex="-1"></a>However, while the estimator provides a point estimate of the treatment effect, it does not convey **uncertainty**. To formally assess whether the estimated effect is significantly different from zero, we conduct a **statistical hypothesis test**.</span>
<span id="cb18-175"><a href="#cb18-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-176"><a href="#cb18-176" aria-hidden="true" tabindex="-1"></a>The fundamental question we seek to answer is:\</span>
<span id="cb18-177"><a href="#cb18-177" aria-hidden="true" tabindex="-1"></a>**Can we be confident in detecting the reported effect size in our experimental results?**</span>
<span id="cb18-178"><a href="#cb18-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-179"><a href="#cb18-179" aria-hidden="true" tabindex="-1"></a>To do so, we frame our problem in terms of **hypothesis testing**:</span>
<span id="cb18-180"><a href="#cb18-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-181"><a href="#cb18-181" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>We begin by specifying a **null hypothesis (**$H_0$), which typically asserts that the treatment has no effect ($\tau = 0$).</span>
<span id="cb18-182"><a href="#cb18-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-183"><a href="#cb18-183" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The **alternative hypothesis (**$H_A$) posits that there is a nonzero effect ($\tau \neq 0$).</span>
<span id="cb18-184"><a href="#cb18-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-185"><a href="#cb18-185" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Hypothesis testing allows us to assess whether the observed difference-in-means provides sufficient evidence to reject $H_0$.</span>
<span id="cb18-186"><a href="#cb18-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-187"><a href="#cb18-187" aria-hidden="true" tabindex="-1"></a>The hypothesis test is based on the **sampling distribution** of the estimator. Because we assume random assignment, the **difference-in-means estimator follows a known distribution**, and we use this fact to determine whether the observed effect is large enough to be statistically significant.</span>
<span id="cb18-188"><a href="#cb18-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-189"><a href="#cb18-189" aria-hidden="true" tabindex="-1"></a><span class="fu">## Statistical Significance and the t-Statistic</span></span>
<span id="cb18-190"><a href="#cb18-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-191"><a href="#cb18-191" aria-hidden="true" tabindex="-1"></a>To formally test the null hypothesis, we construct a **t-statistic**:</span>
<span id="cb18-192"><a href="#cb18-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-193"><a href="#cb18-193" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-194"><a href="#cb18-194" aria-hidden="true" tabindex="-1"></a>t = \frac{\hat{\tau}}{\text{SE}(\hat{\tau})}</span>
<span id="cb18-195"><a href="#cb18-195" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-196"><a href="#cb18-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-197"><a href="#cb18-197" aria-hidden="true" tabindex="-1"></a>where **SE(**$\hat{\tau}$) represents the standard error of the difference-in-means estimator. As the sample size grows, this t-statistic follows a standard normal distribution (or Student's t-distribution for small samples). A large absolute value of \$ t \$ provides evidence against the null hypothesis.</span>
<span id="cb18-198"><a href="#cb18-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-199"><a href="#cb18-199" aria-hidden="true" tabindex="-1"></a>To determine whether the result is **statistically significant**, we compare the t-statistic to a **critical value** determined by our chosen **significance level** ($\alpha$, commonly set at 0.05). If the absolute value of the t-statistic exceeds this threshold, we reject the null hypothesis.</span>
<span id="cb18-200"><a href="#cb18-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-201"><a href="#cb18-201" aria-hidden="true" tabindex="-1"></a><span class="fu">## Type I and Type II Errors</span></span>
<span id="cb18-202"><a href="#cb18-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-203"><a href="#cb18-203" aria-hidden="true" tabindex="-1"></a>While hypothesis testing provides a structured approach to evaluating treatment effects, errors can still occur:</span>
<span id="cb18-204"><a href="#cb18-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-205"><a href="#cb18-205" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>**Type I Error (**$\alpha$): Rejecting the null hypothesis when it is actually true (false positive).</span>
<span id="cb18-206"><a href="#cb18-206" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Controlled by setting the significance level ($\alpha$), which determines the probability of mistakenly rejecting $H_0$.</span>
<span id="cb18-207"><a href="#cb18-207" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Lower $\alpha$ reduces false positives but increases the risk of missing real effects.</span>
<span id="cb18-208"><a href="#cb18-208" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>**Type II Error (**$\beta$): Failing to reject the null hypothesis when it is actually false (false negative).</span>
<span id="cb18-209"><a href="#cb18-209" aria-hidden="true" tabindex="-1"></a><span class="ss">    -   </span>Related to **statistical power**, which is the probability of detecting an effect when it truly exists.</span>
<span id="cb18-210"><a href="#cb18-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-211"><a href="#cb18-211" aria-hidden="true" tabindex="-1"></a><span class="al">![Type 1 and Type 2 Errors](/unit-1/media/HypothesisTesting.png)</span></span>
<span id="cb18-212"><a href="#cb18-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-213"><a href="#cb18-213" aria-hidden="true" tabindex="-1"></a><span class="fu">## Power Calculation: Ensuring Detectability</span></span>
<span id="cb18-214"><a href="#cb18-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-215"><a href="#cb18-215" aria-hidden="true" tabindex="-1"></a>**Statistical power** refers to the ability of a test to correctly reject the null hypothesis when a true effect exists. Mathematically:</span>
<span id="cb18-216"><a href="#cb18-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-217"><a href="#cb18-217" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-218"><a href="#cb18-218" aria-hidden="true" tabindex="-1"></a>\text{Power} = 1 - \beta</span>
<span id="cb18-219"><a href="#cb18-219" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-220"><a href="#cb18-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-221"><a href="#cb18-221" aria-hidden="true" tabindex="-1"></a>Factors influencing power:</span>
<span id="cb18-222"><a href="#cb18-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-223"><a href="#cb18-223" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Effect size (**$\tau$): Larger effects are easier to detect.</span>
<span id="cb18-224"><a href="#cb18-224" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Sample size (**$N$): Larger samples reduce variability, increasing power.</span>
<span id="cb18-225"><a href="#cb18-225" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Significance level (**$\alpha$): Lowering $\alpha$ increases the risk of missing true effects.</span>
<span id="cb18-226"><a href="#cb18-226" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Standard deviation of outcomes**: Higher variability in outcomes reduces power.</span>
<span id="cb18-227"><a href="#cb18-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-228"><a href="#cb18-228" aria-hidden="true" tabindex="-1"></a>To achieve a well-powered experiment, researchers conduct **power calculations** before data collection to determine the minimum sample size required to detect an effect with reasonable confidence.</span>
<span id="cb18-229"><a href="#cb18-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-230"><a href="#cb18-230" aria-hidden="true" tabindex="-1"></a><span class="fu">### A Simple Example</span></span>
<span id="cb18-231"><a href="#cb18-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-232"><a href="#cb18-232" aria-hidden="true" tabindex="-1"></a>Let's consider a simple example of a power simulation using a simple random assignment to a treatment and control group, where the estimate is the **difference-in-means estimator**.</span>
<span id="cb18-233"><a href="#cb18-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-236"><a href="#cb18-236" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-237"><a href="#cb18-237" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb18-238"><a href="#cb18-238" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-239"><a href="#cb18-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-240"><a href="#cb18-240" aria-hidden="true" tabindex="-1"></a><span class="fu">#### **Step 1: Define Simulation Parameters**</span></span>
<span id="cb18-241"><a href="#cb18-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-242"><a href="#cb18-242" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Let’s assume we have a total sample size of $N = 200$ individuals.</span>
<span id="cb18-243"><a href="#cb18-243" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The treatment group receives an intervention, while the control group does not.</span>
<span id="cb18-244"><a href="#cb18-244" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The true treatment effect is set to $\tau = 2$.</span>
<span id="cb18-245"><a href="#cb18-245" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The outcome variable follows a normal distribution with mean 10 and standard deviation 4.</span>
<span id="cb18-246"><a href="#cb18-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-249"><a href="#cb18-249" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-250"><a href="#cb18-250" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">072111</span>)  <span class="co"># Ensures reproducibility</span></span>
<span id="cb18-251"><a href="#cb18-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-252"><a href="#cb18-252" aria-hidden="true" tabindex="-1"></a><span class="co"># Define parameters</span></span>
<span id="cb18-253"><a href="#cb18-253" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">200</span>  <span class="co"># Total sample size</span></span>
<span id="cb18-254"><a href="#cb18-254" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fl">0.5</span>  <span class="co"># Probability of assignment to treatment</span></span>
<span id="cb18-255"><a href="#cb18-255" aria-hidden="true" tabindex="-1"></a>true_tau <span class="ot">&lt;-</span> <span class="dv">2</span>  <span class="co"># True treatment effect</span></span>
<span id="cb18-256"><a href="#cb18-256" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">4</span>  <span class="co"># Standard deviation of outcome</span></span>
<span id="cb18-257"><a href="#cb18-257" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-258"><a href="#cb18-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-259"><a href="#cb18-259" aria-hidden="true" tabindex="-1"></a><span class="fu">#### **Step 2: Simulate Data**</span></span>
<span id="cb18-260"><a href="#cb18-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-261"><a href="#cb18-261" aria-hidden="true" tabindex="-1"></a>Now we can simulate the data using data.table:</span>
<span id="cb18-262"><a href="#cb18-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-265"><a href="#cb18-265" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-266"><a href="#cb18-266" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate data using data.table</span></span>
<span id="cb18-267"><a href="#cb18-267" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">id =</span> <span class="dv">1</span><span class="sc">:</span>N)</span>
<span id="cb18-268"><a href="#cb18-268" aria-hidden="true" tabindex="-1"></a>dt[, treatment <span class="sc">:</span><span class="er">=</span> <span class="fu">rbinom</span>(.N, <span class="dv">1</span>, p)]</span>
<span id="cb18-269"><a href="#cb18-269" aria-hidden="true" tabindex="-1"></a>dt[, outcome <span class="sc">:</span><span class="er">=</span> <span class="dv">10</span> <span class="sc">+</span> true_tau <span class="sc">*</span> treatment <span class="sc">+</span> <span class="fu">rnorm</span>(.N, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> sigma)]</span>
<span id="cb18-270"><a href="#cb18-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-271"><a href="#cb18-271" aria-hidden="true" tabindex="-1"></a><span class="co">#display first few rows</span></span>
<span id="cb18-272"><a href="#cb18-272" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(dt)</span>
<span id="cb18-273"><a href="#cb18-273" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-274"><a href="#cb18-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-275"><a href="#cb18-275" aria-hidden="true" tabindex="-1"></a><span class="fu">#### **Step 3: Estimate Treatment Effect**</span></span>
<span id="cb18-276"><a href="#cb18-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-279"><a href="#cb18-279" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-280"><a href="#cb18-280" aria-hidden="true" tabindex="-1"></a>diff_means <span class="ot">&lt;-</span> dt[treatment <span class="sc">==</span> <span class="dv">1</span>, <span class="fu">mean</span>(outcome)] <span class="sc">-</span> dt[treatment <span class="sc">==</span> <span class="dv">0</span>, <span class="fu">mean</span>(outcome)]</span>
<span id="cb18-281"><a href="#cb18-281" aria-hidden="true" tabindex="-1"></a>SE <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(dt[treatment <span class="sc">==</span> <span class="dv">1</span>, <span class="fu">var</span>(outcome)] <span class="sc">/</span> dt[treatment <span class="sc">==</span> <span class="dv">1</span>, .N] <span class="sc">+</span></span>
<span id="cb18-282"><a href="#cb18-282" aria-hidden="true" tabindex="-1"></a>           dt[treatment <span class="sc">==</span> <span class="dv">0</span>, <span class="fu">var</span>(outcome)] <span class="sc">/</span> dt[treatment <span class="sc">==</span> <span class="dv">0</span>, .N])</span>
<span id="cb18-283"><a href="#cb18-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-284"><a href="#cb18-284" aria-hidden="true" tabindex="-1"></a>t_stat <span class="ot">&lt;-</span> diff_means <span class="sc">/</span> SE  <span class="co"># Compute t-statistic</span></span>
<span id="cb18-285"><a href="#cb18-285" aria-hidden="true" tabindex="-1"></a>p_value <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">pt</span>(<span class="fu">abs</span>(t_stat), <span class="at">df =</span> N <span class="sc">-</span> <span class="dv">2</span>))  <span class="co"># Two-tailed test</span></span>
<span id="cb18-286"><a href="#cb18-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-287"><a href="#cb18-287" aria-hidden="true" tabindex="-1"></a><span class="co"># Display results</span></span>
<span id="cb18-288"><a href="#cb18-288" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Estimated Treatment Effect:"</span>, diff_means, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb18-289"><a href="#cb18-289" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"p-value:"</span>, p_value, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb18-290"><a href="#cb18-290" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-291"><a href="#cb18-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-292"><a href="#cb18-292" aria-hidden="true" tabindex="-1"></a><span class="fu">#### **Step 4: Power Simulation**</span></span>
<span id="cb18-293"><a href="#cb18-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-294"><a href="#cb18-294" aria-hidden="true" tabindex="-1"></a>First, let's consider how we will interpret the results:</span>
<span id="cb18-295"><a href="#cb18-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-296"><a href="#cb18-296" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If the p-value is **less than 0.05**, we reject the null hypothesis and conclude that the treatment has a significant effect.</span>
<span id="cb18-297"><a href="#cb18-297" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>If the p-value is **greater than 0.05**, we fail to reject the null, meaning we do not have enough evidence to confirm a treatment effect.</span>
<span id="cb18-298"><a href="#cb18-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-299"><a href="#cb18-299" aria-hidden="true" tabindex="-1"></a>Now, let's simulate a power simulation:</span>
<span id="cb18-300"><a href="#cb18-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-301"><a href="#cb18-301" aria-hidden="true" tabindex="-1"></a>First, define the power simulation function:</span>
<span id="cb18-302"><a href="#cb18-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-305"><a href="#cb18-305" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-306"><a href="#cb18-306" aria-hidden="true" tabindex="-1"></a>simulate_power <span class="ot">&lt;-</span> <span class="cf">function</span>(N, true_tau, sigma, p, alpha, <span class="at">reps =</span> <span class="dv">1000</span>) {</span>
<span id="cb18-307"><a href="#cb18-307" aria-hidden="true" tabindex="-1"></a>  rejections <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb18-308"><a href="#cb18-308" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb18-309"><a href="#cb18-309" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>reps) {</span>
<span id="cb18-310"><a href="#cb18-310" aria-hidden="true" tabindex="-1"></a>    dt <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">id =</span> <span class="dv">1</span><span class="sc">:</span>N)</span>
<span id="cb18-311"><a href="#cb18-311" aria-hidden="true" tabindex="-1"></a>    dt[, treatment <span class="sc">:</span><span class="er">=</span> <span class="fu">rbinom</span>(.N, <span class="dv">1</span>, p)]</span>
<span id="cb18-312"><a href="#cb18-312" aria-hidden="true" tabindex="-1"></a>    dt[, outcome <span class="sc">:</span><span class="er">=</span> <span class="dv">10</span> <span class="sc">+</span> true_tau <span class="sc">*</span> treatment <span class="sc">+</span> <span class="fu">rnorm</span>(.N, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> sigma)]</span>
<span id="cb18-313"><a href="#cb18-313" aria-hidden="true" tabindex="-1"></a>    diff_means <span class="ot">&lt;-</span> dt[treatment <span class="sc">==</span> <span class="dv">1</span>, <span class="fu">mean</span>(outcome)] <span class="sc">-</span> dt[treatment <span class="sc">==</span> <span class="dv">0</span>, <span class="fu">mean</span>(outcome)]</span>
<span id="cb18-314"><a href="#cb18-314" aria-hidden="true" tabindex="-1"></a>    SE <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(dt[treatment <span class="sc">==</span> <span class="dv">1</span>, <span class="fu">var</span>(outcome)] <span class="sc">/</span> dt[treatment <span class="sc">==</span> <span class="dv">1</span>, .N] <span class="sc">+</span></span>
<span id="cb18-315"><a href="#cb18-315" aria-hidden="true" tabindex="-1"></a>               dt[treatment <span class="sc">==</span> <span class="dv">0</span>, <span class="fu">var</span>(outcome)] <span class="sc">/</span> dt[treatment <span class="sc">==</span> <span class="dv">0</span>, .N])</span>
<span id="cb18-316"><a href="#cb18-316" aria-hidden="true" tabindex="-1"></a>    t_stat <span class="ot">&lt;-</span> diff_means <span class="sc">/</span> SE</span>
<span id="cb18-317"><a href="#cb18-317" aria-hidden="true" tabindex="-1"></a>    p_value <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">pt</span>(<span class="fu">abs</span>(t_stat), <span class="at">df =</span> N <span class="sc">-</span> <span class="dv">2</span>))</span>
<span id="cb18-318"><a href="#cb18-318" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-319"><a href="#cb18-319" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (p_value <span class="sc">&lt;</span> alpha) {</span>
<span id="cb18-320"><a href="#cb18-320" aria-hidden="true" tabindex="-1"></a>      rejections <span class="ot">&lt;-</span> rejections <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb18-321"><a href="#cb18-321" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb18-322"><a href="#cb18-322" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb18-323"><a href="#cb18-323" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(rejections <span class="sc">/</span> reps)</span>
<span id="cb18-324"><a href="#cb18-324" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-325"><a href="#cb18-325" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-326"><a href="#cb18-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-327"><a href="#cb18-327" aria-hidden="true" tabindex="-1"></a>Now, simulate this experiment **1,000 times**:</span>
<span id="cb18-328"><a href="#cb18-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-331"><a href="#cb18-331" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-332"><a href="#cb18-332" aria-hidden="true" tabindex="-1"></a><span class="co"># Run power simulation</span></span>
<span id="cb18-333"><a href="#cb18-333" aria-hidden="true" tabindex="-1"></a>power <span class="ot">&lt;-</span> <span class="fu">simulate_power</span>(<span class="at">N =</span> <span class="dv">200</span>, <span class="at">true_tau =</span> <span class="dv">2</span>, <span class="at">sigma =</span> <span class="dv">4</span>, <span class="at">p =</span> <span class="fl">0.5</span>, <span class="at">alpha =</span> <span class="fl">0.05</span>, <span class="at">reps =</span> <span class="dv">1000</span>)</span>
<span id="cb18-334"><a href="#cb18-334" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Estimated Power:"</span>, power, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb18-335"><a href="#cb18-335" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-336"><a href="#cb18-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-337"><a href="#cb18-337" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Step 5: Interpreting Power Calculation**</span></span>
<span id="cb18-338"><a href="#cb18-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-339"><a href="#cb18-339" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The **power** of the test is the proportion of simulations in which we correctly reject the null hypothesis when the treatment effect is truly $\tau = 2$.</span>
<span id="cb18-340"><a href="#cb18-340" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>A power value close to **0.80 or higher** indicates that the experiment is well-powered.</span>
<span id="cb18-341"><a href="#cb18-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-342"><a href="#cb18-342" aria-hidden="true" tabindex="-1"></a>::: callout-tip</span>
<span id="cb18-343"><a href="#cb18-343" aria-hidden="true" tabindex="-1"></a>Try changing the sample size or effect size, to see how the power changes.</span>
<span id="cb18-344"><a href="#cb18-344" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-345"><a href="#cb18-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-346"><a href="#cb18-346" aria-hidden="true" tabindex="-1"></a><span class="fu"># Simulations in Research Design</span></span>
<span id="cb18-347"><a href="#cb18-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-348"><a href="#cb18-348" aria-hidden="true" tabindex="-1"></a>To fix ideas of what we're doing with simulations, it might be helpful to take a step back and view this in the context of an overall research design.</span>
<span id="cb18-349"><a href="#cb18-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-350"><a href="#cb18-350" aria-hidden="true" tabindex="-1"></a>We aim to generate empirical answers that closely approximate the true treatment effect. However, because we never observe both potential outcomes for an individual, we rely on statistical methods and experimental design to make **valid inferences**. Simulation plays a crucial role in assessing research designs, allowing us to compare **simulated answers** to possible true answers across multiple realizations of a study.</span>
<span id="cb18-351"><a href="#cb18-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-352"><a href="#cb18-352" aria-hidden="true" tabindex="-1"></a>In empirical research, a design consists of two halves:</span>
<span id="cb18-353"><a href="#cb18-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-354"><a href="#cb18-354" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>**Theoretical Component**: Defines the inquiry using a model $M$.</span>
<span id="cb18-355"><a href="#cb18-355" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>**Empirical Component**: Applies the data strategy $D$ to generate a dataset, then applies an estimation strategy $A$ to obtain the empirical answer $a_d$.</span>
<span id="cb18-356"><a href="#cb18-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-357"><a href="#cb18-357" aria-hidden="true" tabindex="-1"></a>Simulation dissociates the design from reality, allowing researchers to assess how their chosen model performs across various possible scenarios, even when the true answer is unknown.</span>
<span id="cb18-358"><a href="#cb18-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-359"><a href="#cb18-359" aria-hidden="true" tabindex="-1"></a><span class="fu">## The MIDA Framework for Simulation</span></span>
<span id="cb18-360"><a href="#cb18-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-361"><a href="#cb18-361" aria-hidden="true" tabindex="-1"></a>A structured way to think about research design and simulation is the **MIDA Framework**,<span class="ot">[^4]</span>(https://book.declaredesign.org/declaration-diagnosis-redesign/research-design.html)<span class="sc">\]</span> which consists of:</span>
<span id="cb18-362"><a href="#cb18-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-363"><a href="#cb18-363" aria-hidden="true" tabindex="-1"></a><span class="ot">[^4]: </span>Reference: Declaration Design</span>
<span id="cb18-364"><a href="#cb18-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-365"><a href="#cb18-365" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**M**: The Model - The underlying data-generating process that defines the inquiry.</span>
<span id="cb18-366"><a href="#cb18-366" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**I**: The Inquiry - The specific research question we are trying to answer.</span>
<span id="cb18-367"><a href="#cb18-367" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**D**: The Data Strategy - The way we collect and structure data, including sampling and treatment assignment.</span>
<span id="cb18-368"><a href="#cb18-368" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**A**: The Answer Strategy - The statistical method we use to estimate the effect.</span>
<span id="cb18-369"><a href="#cb18-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-370"><a href="#cb18-370" aria-hidden="true" tabindex="-1"></a><span class="al">![MIDA Framework, Source: Declaration Design](/unit-1/media/MIDA.svg)</span></span>
<span id="cb18-371"><a href="#cb18-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-372"><a href="#cb18-372" aria-hidden="true" tabindex="-1"></a><span class="al">![Elements of Research Design, Source: Declaration Design](/unit-1/media/RDElements.png)</span></span>
<span id="cb18-373"><a href="#cb18-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-374"><a href="#cb18-374" aria-hidden="true" tabindex="-1"></a>In a real-world study, we can only observe a single realization of the design and generate one empirical answer $a_d$. However, through **simulation**, we can consider many possible data realizations by repeatedly drawing from different models $m_1, m_2, ..., m_k$ within the model space $M$. This allows us to assess how our research design performs across different scenarios.</span>
<span id="cb18-375"><a href="#cb18-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-376"><a href="#cb18-376" aria-hidden="true" tabindex="-1"></a><span class="fu">## Diagnosing Research Designs with Simulation</span></span>
<span id="cb18-377"><a href="#cb18-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-378"><a href="#cb18-378" aria-hidden="true" tabindex="-1"></a>When we simulate a research design, we evaluate its **performance** by considering:</span>
<span id="cb18-379"><a href="#cb18-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-380"><a href="#cb18-380" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Bias**: How close is the empirical answer $a_d$ to the true answer $a_m$?</span>
<span id="cb18-381"><a href="#cb18-381" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Variance**: How much do the empirical answers fluctuate across different realizations?</span>
<span id="cb18-382"><a href="#cb18-382" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Coverage**: How often do confidence intervals include the true effect?</span>
<span id="cb18-383"><a href="#cb18-383" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Power**: How frequently does the study correctly reject the null hypothesis when a true effect exists?</span>
<span id="cb18-384"><a href="#cb18-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-385"><a href="#cb18-385" aria-hidden="true" tabindex="-1"></a>The bottom half of the figure below illustrates how simulation allows us to examine the research design across multiple models ($m_1, ..., m_k$), generating different answers ($a_{m_1}, a_{m_2}, ..., a_{m_k}$) and associated datasets ($d_1, d_2, ..., d_k$). The simulated research design does not have direct access to the true answer but can assess performance across the models under consideration.</span>
<span id="cb18-386"><a href="#cb18-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-387"><a href="#cb18-387" aria-hidden="true" tabindex="-1"></a><span class="al">![Simulations in the MIDA Framework](/unit-1/media/MIDA-Simulation.svg)</span></span>
<span id="cb18-388"><a href="#cb18-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-389"><a href="#cb18-389" aria-hidden="true" tabindex="-1"></a><span class="fu"># Multiple Hypothesis Testing</span></span>
<span id="cb18-390"><a href="#cb18-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-391"><a href="#cb18-391" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Challenge of Multiple Hypothesis Testing</span></span>
<span id="cb18-392"><a href="#cb18-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-393"><a href="#cb18-393" aria-hidden="true" tabindex="-1"></a>In many empirical settings, researchers conduct **multiple hypothesis tests** rather than a single test. This introduces the risk of **false positives**, or mistakenly finding significant effects simply due to chance. Multiple hypothesis testing arises naturally in at least three key scenarios:</span>
<span id="cb18-394"><a href="#cb18-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-395"><a href="#cb18-395" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>**Multiple Outcomes**: When we examine several outcomes ($Y_i$) to determine whether any are affected by the treatment.</span>
<span id="cb18-396"><a href="#cb18-396" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>**Heterogeneous Treatment Effects (CATEs)**: When treatment effects vary across subgroups, and we want to assess which subgroups exhibit an effect.</span>
<span id="cb18-397"><a href="#cb18-397" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>**Multiple Treatments**: When we compare multiple interventions ($D_i$) and want to test their effects relative to a control group or to each other.</span>
<span id="cb18-398"><a href="#cb18-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-399"><a href="#cb18-399" aria-hidden="true" tabindex="-1"></a>To properly interpret results, we need statistical techniques that **adjust for multiple comparisons** and control the probability of **false discoveries**.</span>
<span id="cb18-400"><a href="#cb18-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-401"><a href="#cb18-401" aria-hidden="true" tabindex="-1"></a>------------------------------------------------------------------------</span>
<span id="cb18-402"><a href="#cb18-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-403"><a href="#cb18-403" aria-hidden="true" tabindex="-1"></a><span class="fu">## Types of Multiple Hypothesis Tests</span></span>
<span id="cb18-404"><a href="#cb18-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-405"><a href="#cb18-405" aria-hidden="true" tabindex="-1"></a>There are two broad types of statistical hypothesis testing frameworks when dealing with multiple comparisons:</span>
<span id="cb18-406"><a href="#cb18-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-407"><a href="#cb18-407" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Joint Tests**: These assess whether at least one hypothesis is true (e.g., "Is at least one treatment effective?").</span>
<span id="cb18-408"><a href="#cb18-408" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Simultaneous Tests**: These examine whether multiple hypotheses are true at the same time (e.g., "Are both Treatment A and Treatment B effective?").</span>
<span id="cb18-409"><a href="#cb18-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-410"><a href="#cb18-410" aria-hidden="true" tabindex="-1"></a>When conducting multiple tests, researchers need to control for an increased **family-wise error rate (FWER)**, which is the probability of making at least one Type I error (false positive).</span>
<span id="cb18-411"><a href="#cb18-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-412"><a href="#cb18-412" aria-hidden="true" tabindex="-1"></a>------------------------------------------------------------------------</span>
<span id="cb18-413"><a href="#cb18-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-414"><a href="#cb18-414" aria-hidden="true" tabindex="-1"></a><span class="fu">## Controlling the Family-Wise Error Rate (FWER)</span></span>
<span id="cb18-415"><a href="#cb18-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-416"><a href="#cb18-416" aria-hidden="true" tabindex="-1"></a>A single hypothesis test controls the probability of a **Type I error** at a given significance level ($\alpha$). However, with multiple tests, the probability of making **at least one false rejection** increases:</span>
<span id="cb18-417"><a href="#cb18-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-418"><a href="#cb18-418" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-419"><a href="#cb18-419" aria-hidden="true" tabindex="-1"></a>\text{FWER} = 1 - (1 - \alpha)^k</span>
<span id="cb18-420"><a href="#cb18-420" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-421"><a href="#cb18-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-422"><a href="#cb18-422" aria-hidden="true" tabindex="-1"></a>where $k$ is the number of tests. For example, if we conduct **5 tests at** $\alpha = 0.05$, the probability of making **no Type I errors** across all tests is:</span>
<span id="cb18-423"><a href="#cb18-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-424"><a href="#cb18-424" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-425"><a href="#cb18-425" aria-hidden="true" tabindex="-1"></a>(1 - 0.05)^5 = 0.7738</span>
<span id="cb18-426"><a href="#cb18-426" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-427"><a href="#cb18-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-428"><a href="#cb18-428" aria-hidden="true" tabindex="-1"></a>Thus, the probability of making **at least one** Type I error is:</span>
<span id="cb18-429"><a href="#cb18-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-430"><a href="#cb18-430" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-431"><a href="#cb18-431" aria-hidden="true" tabindex="-1"></a>FWER = 1 - 0.7738 = 0.2262</span>
<span id="cb18-432"><a href="#cb18-432" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb18-433"><a href="#cb18-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-434"><a href="#cb18-434" aria-hidden="true" tabindex="-1"></a>This means there is a **22.62% chance** of mistakenly rejecting at least one null hypothesis across the five tests. If we perform **20 tests**, the FWER increases to **64%**.</span>
<span id="cb18-435"><a href="#cb18-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-436"><a href="#cb18-436" aria-hidden="true" tabindex="-1"></a>------------------------------------------------------------------------</span>
<span id="cb18-437"><a href="#cb18-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-438"><a href="#cb18-438" aria-hidden="true" tabindex="-1"></a><span class="fu">## Approaches to Controlling the FWER</span></span>
<span id="cb18-439"><a href="#cb18-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-440"><a href="#cb18-440" aria-hidden="true" tabindex="-1"></a>To mitigate this issue, researchers employ various **multiple testing corrections**, such as:</span>
<span id="cb18-441"><a href="#cb18-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-442"><a href="#cb18-442" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Bonferroni Correction**: Adjusts the significance level by dividing $\alpha$ by the number of tests: $\alpha^* = \alpha / k$. This is simple but conservative.</span>
<span id="cb18-443"><a href="#cb18-443" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Holm Method**: A stepwise procedure that ranks p-values and adjusts them sequentially to control the FWER more efficiently.</span>
<span id="cb18-444"><a href="#cb18-444" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Modern Approaches (e.g., Westfall-Young, Benjamini-Hochberg FDR control)**: These methods control for false discovery rates and are widely used in large-scale testing.</span>
<span id="cb18-445"><a href="#cb18-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-446"><a href="#cb18-446" aria-hidden="true" tabindex="-1"></a>------------------------------------------------------------------------</span>
<span id="cb18-447"><a href="#cb18-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-448"><a href="#cb18-448" aria-hidden="true" tabindex="-1"></a><span class="fu">## Simulating Multiple Hypothesis Testing in R</span></span>
<span id="cb18-449"><a href="#cb18-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-450"><a href="#cb18-450" aria-hidden="true" tabindex="-1"></a>To illustrate the impact of multiple testing and FWER correction, let's do a simulation in R:</span>
<span id="cb18-451"><a href="#cb18-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-454"><a href="#cb18-454" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb18-455"><a href="#cb18-455" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb18-456"><a href="#cb18-456" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">072111</span>)  <span class="co"># Ensures reproducibility</span></span>
<span id="cb18-457"><a href="#cb18-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-458"><a href="#cb18-458" aria-hidden="true" tabindex="-1"></a><span class="co"># Define parameters</span></span>
<span id="cb18-459"><a href="#cb18-459" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">200</span>  <span class="co"># Sample size</span></span>
<span id="cb18-460"><a href="#cb18-460" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">10</span>  <span class="co"># Number of hypothesis tests</span></span>
<span id="cb18-461"><a href="#cb18-461" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span>  <span class="co"># Significance level</span></span>
<span id="cb18-462"><a href="#cb18-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-463"><a href="#cb18-463" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate k independent hypothesis tests</span></span>
<span id="cb18-464"><a href="#cb18-464" aria-hidden="true" tabindex="-1"></a>dt <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">test_id =</span> <span class="dv">1</span><span class="sc">:</span>k)</span>
<span id="cb18-465"><a href="#cb18-465" aria-hidden="true" tabindex="-1"></a>dt[, p_value <span class="sc">:</span><span class="er">=</span> <span class="fu">runif</span>(.N, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">1</span>)]  <span class="co"># Generate uniform random p-values</span></span>
<span id="cb18-466"><a href="#cb18-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-467"><a href="#cb18-467" aria-hidden="true" tabindex="-1"></a>dt[, bonferroni <span class="sc">:</span><span class="er">=</span> p_value <span class="sc">&lt;</span> (alpha <span class="sc">/</span> k)]  <span class="co"># Bonferroni correction</span></span>
<span id="cb18-468"><a href="#cb18-468" aria-hidden="true" tabindex="-1"></a>dt[, holm <span class="sc">:</span><span class="er">=</span> <span class="fu">p.adjust</span>(p_value, <span class="at">method =</span> <span class="st">"holm"</span>) <span class="sc">&lt;</span> alpha]  <span class="co"># Holm correction</span></span>
<span id="cb18-469"><a href="#cb18-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-470"><a href="#cb18-470" aria-hidden="true" tabindex="-1"></a>dt[, naive_reject <span class="sc">:</span><span class="er">=</span> p_value <span class="sc">&lt;</span> alpha]  <span class="co"># Standard test (without correction)</span></span>
<span id="cb18-471"><a href="#cb18-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-472"><a href="#cb18-472" aria-hidden="true" tabindex="-1"></a><span class="co"># Count false positives</span></span>
<span id="cb18-473"><a href="#cb18-473" aria-hidden="true" tabindex="-1"></a>false_discoveries <span class="ot">&lt;-</span> dt[, <span class="fu">sum</span>(naive_reject)]</span>
<span id="cb18-474"><a href="#cb18-474" aria-hidden="true" tabindex="-1"></a>adjusted_false_discoveries <span class="ot">&lt;-</span> dt[, <span class="fu">sum</span>(bonferroni)]</span>
<span id="cb18-475"><a href="#cb18-475" aria-hidden="true" tabindex="-1"></a>holm_false_discoveries <span class="ot">&lt;-</span> dt[, <span class="fu">sum</span>(holm)]</span>
<span id="cb18-476"><a href="#cb18-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-477"><a href="#cb18-477" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"False positives (no correction):"</span>, false_discoveries, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb18-478"><a href="#cb18-478" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"False positives (Bonferroni correction):"</span>, adjusted_false_discoveries, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb18-479"><a href="#cb18-479" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"False positives (Holm correction):"</span>, holm_false_discoveries, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb18-480"><a href="#cb18-480" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb18-481"><a href="#cb18-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-482"><a href="#cb18-482" aria-hidden="true" tabindex="-1"></a><span class="fu">### **Interpreting the Simulation**</span></span>
<span id="cb18-483"><a href="#cb18-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-484"><a href="#cb18-484" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Without correction**, we expect around $\alpha \times k$ false discoveries.</span>
<span id="cb18-485"><a href="#cb18-485" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Bonferroni correction** sharply reduces false positives but may be overly conservative.</span>
<span id="cb18-486"><a href="#cb18-486" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Holm correction** provides a better balance, controlling FWER while maintaining statistical power.</span>
<span id="cb18-487"><a href="#cb18-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-488"><a href="#cb18-488" aria-hidden="true" tabindex="-1"></a>::: callout-tip</span>
<span id="cb18-489"><a href="#cb18-489" aria-hidden="true" tabindex="-1"></a>Note: In the lab, we'll cover some modern approaches that are more powerful but a bit more complex.</span>
<span id="cb18-490"><a href="#cb18-490" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb18-491"><a href="#cb18-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-492"><a href="#cb18-492" aria-hidden="true" tabindex="-1"></a><span class="fu"># References</span></span>
<span id="cb18-493"><a href="#cb18-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-494"><a href="#cb18-494" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span><span class="co">[</span><span class="ot">Wager Chapter 1</span><span class="co">](https://web.stanford.edu/~swager/causal_inf_book.pdf)</span></span>
<span id="cb18-495"><a href="#cb18-495" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span><span class="co">[</span><span class="ot">Declare Design Book</span><span class="co">](https://book.declaredesign.org/declaration-diagnosis-redesign/declaring-designs.html)</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>© Copyright 2024, Sean Sylvia</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/hpm883/edit/main/unit-1/lec-1-2.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/hpm883/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>


</body></html>